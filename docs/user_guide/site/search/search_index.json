{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Locomotion Data Standardization","text":"<p>Transform biomechanical datasets into a unified, quality-assured format for reproducible research.</p> <ul> <li> <p> Quick Start</p> <p>Get up and running in minutes with our step-by-step guide</p> <p> Start Here</p> </li> <li> <p> Tutorials</p> <p>Learn with hands-on examples in Python and MATLAB</p> <p> View Tutorials</p> </li> <li> <p> Contributor Guide</p> <p>Add your dataset to the standardized collection</p> <p> Contribute Data</p> </li> <li> <p> Reference</p> <p>Complete documentation of data formats and validation</p> <p> View Reference</p> </li> </ul>"},{"location":"#what-is-locomotion-data-standardization","title":"What is Locomotion Data Standardization?","text":"<p>This project provides a unified framework for biomechanical datasets, addressing the challenge of inconsistent data formats across research labs. By standardizing variable names, units, and data structures, we enable:</p> <ul> <li>Reproducible Research: Consistent data formats across studies</li> <li>Quality Assurance: Automated validation of biomechanical plausibility</li> <li>Easy Analysis: Standardized tools for common biomechanics tasks</li> <li>Cross-Study Comparison: Compatible datasets from multiple sources</li> </ul>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#standardized-data-format","title":"Standardized Data Format","text":"<ul> <li>Consistent naming: <code>knee_flexion_angle_ipsi_rad</code>, <code>hip_moment_contra_Nm</code></li> <li>Two formats: Time-indexed (original frequency) and phase-indexed (150 points per cycle)</li> <li>Quality validation: Automated biomechanical plausibility checks</li> </ul>"},{"location":"#analysis-tools","title":"Analysis Tools","text":"<ul> <li>Python library: Load, analyze, and visualize standardized datasets</li> <li>MATLAB support: Native MATLAB functions for biomechanics workflows</li> <li>Validation reports: Comprehensive quality assessment with visualizations</li> </ul>"},{"location":"#quality-datasets","title":"Quality Datasets","text":"<ul> <li>Multi-lab sources: Georgia Tech, University of Michigan, AddBiomechanics</li> <li>Diverse tasks: Level walking, stairs, inclines, running, jumping</li> <li>Validated quality: All datasets pass biomechanical plausibility checks</li> </ul>"},{"location":"#who-should-use-this","title":"Who Should Use This?","text":"Researchers &amp; StudentsDataset ContributorsTool Developers <p>Use quality-assured datasets for your research</p> <ul> <li>Download standardized datasets from multiple labs</li> <li>Focus on analysis rather than data cleaning</li> <li>Reproduce published results with confidence</li> </ul> <p>Start with: Quick Start Guide</p> <p>Add your datasets to the standardized collection</p> <ul> <li>Convert your lab's data to standard format</li> <li>Validate quality with automated checks</li> <li>Share data with the research community</li> </ul> <p>Start with: Contributor Guide</p> <p>Build on standardized data infrastructure</p> <ul> <li>Access consistent data formats across studies</li> <li>Integrate with validation and analysis tools</li> <li>Extend functionality for specific use cases</li> </ul> <p>Start with: API Reference</p>"},{"location":"#quick-example","title":"Quick Example","text":"<p>Here's how easy it is to work with standardized data:</p> PythonMATLAB <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load standardized dataset\ndata = pd.read_parquet('gtech_2023_phase.parquet')\n\n# Filter for level walking\nwalking = data[data['task'] == 'level_walking']\n\n# Plot average knee angle across gait cycle\navg_knee = walking.groupby('phase_percent')['knee_flexion_angle_ipsi_rad'].mean()\nplt.plot(avg_knee.index, avg_knee.values)\nplt.xlabel('Gait Cycle (%)')\nplt.ylabel('Knee Flexion (rad)')\nplt.title('Average Knee Angle - Level Walking')\nplt.show()\n</code></pre> <pre><code>% Load standardized dataset\ndata = readtable('gtech_2023_phase.parquet');\n\n% Filter for level walking\nwalking = data(strcmp(data.task, 'level_walking'), :);\n\n% Plot average knee angle across gait cycle\navg_knee = groupsummary(walking, 'phase_percent', 'mean', 'knee_flexion_angle_ipsi_rad');\nplot(avg_knee.phase_percent, avg_knee.mean_knee_flexion_angle_ipsi_rad);\nxlabel('Gait Cycle (%)');\nylabel('Knee Flexion (rad)');\ntitle('Average Knee Angle - Level Walking');\n</code></pre>"},{"location":"#available-datasets","title":"Available Datasets","text":"Dataset Tasks Subjects Gait Cycles Status Georgia Tech 2023 Level walking, stairs, inclines 10 ~500 \u2705 Available University of Michigan 2021 Level walking, inclines, declines 12 ~600 \u2705 Available AddBiomechanics Walking, running, jumping 50+ ~2000 \ud83d\udea7 In Progress"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Install Python or MATLAB support</li> <li>Quick Start with a sample dataset</li> <li>Follow Tutorials for hands-on learning</li> <li>Contribute your own datasets</li> </ol>"},{"location":"#support-community","title":"Support &amp; Community","text":"<ul> <li>Questions? Check our Troubleshooting Guide</li> <li>Bug reports? Open an issue on GitHub</li> <li>Want to contribute? See our Contributor Guide</li> </ul> <p>This project is maintained by a community of biomechanics researchers and software developers committed to reproducible science.</p>"},{"location":"contributor_guide/overview/","title":"Contributor Guide Overview","text":"<p>Welcome to the Locomotion Data Standardization project! This guide helps you contribute high-quality biomechanical datasets to our standardized collection.</p>"},{"location":"contributor_guide/overview/#why-contribute","title":"Why Contribute?","text":"<p>Your contribution helps advance biomechanics research by:</p> <ul> <li>Increasing dataset diversity - More tasks, populations, and conditions</li> <li>Enabling meta-analyses - Standardized format allows cross-study comparisons  </li> <li>Accelerating research - Researchers can focus on analysis vs. data cleaning</li> <li>Building community - Shared resources benefit the entire field</li> </ul>"},{"location":"contributor_guide/overview/#who-can-contribute","title":"Who Can Contribute?","text":"<p>We welcome contributions from:</p> <ul> <li>Research laboratories with locomotion datasets</li> <li>Clinical centers with patient movement data</li> <li>Sports science groups with athlete performance data</li> <li>Individual researchers with specialized task datasets</li> </ul>"},{"location":"contributor_guide/overview/#contribution-process-overview","title":"Contribution Process Overview","text":"<pre><code>graph TD\n    A[Prepare Dataset] --&gt; B[Convert Format]\n    B --&gt; C[Validate Quality]\n    C --&gt; D{Quality Check}\n    D --&gt;|Pass| E[Submit Dataset]\n    D --&gt;|Issues| F[Address Issues]\n    F --&gt; C\n    E --&gt; G[Community Review]\n    G --&gt; H[Publication]\n\n    style A fill:#e1f5fe\n    style E fill:#e8f5e8\n    style H fill:#f3e5f5</code></pre>"},{"location":"contributor_guide/overview/#phase-1-preparation","title":"Phase 1: Preparation","text":"<ol> <li>Dataset Assessment - Verify your data meets requirements</li> <li>Format Conversion - Transform to standardized structure</li> <li>Quality Validation - Ensure biomechanical plausibility</li> </ol>"},{"location":"contributor_guide/overview/#phase-2-submission","title":"Phase 2: Submission","text":"<ol> <li>Documentation - Create dataset description and metadata</li> <li>Community Review - Peer validation of quality and documentation</li> <li>Publication - Integration into public collection</li> </ol>"},{"location":"contributor_guide/overview/#dataset-requirements","title":"Dataset Requirements","text":""},{"location":"contributor_guide/overview/#minimum-data-requirements","title":"Minimum Data Requirements","text":"<p>Essential Variables (at least one side): - Hip flexion angle - Knee flexion angle - Ankle flexion angle</p> <p>Recommended Variables: - Joint moments (hip, knee, ankle) - Ground reaction forces - Additional joint angles (abduction, rotation)</p> <p>Metadata Requirements: - Subject demographics (age, sex, height, weight) - Task descriptions and conditions - Data collection protocols - Equipment specifications</p>"},{"location":"contributor_guide/overview/#data-quality-standards","title":"Data Quality Standards","text":"<p>Temporal Requirements: - Minimum 5 complete gait cycles per task per subject - Consistent sampling frequency (\u2265100 Hz recommended) - Clear gait event identification (heel strikes)</p> <p>Biomechanical Plausibility: - Joint angles within physiological ranges - Consistent movement patterns across cycles - Minimal missing data (&lt;5% per variable)</p> <p>Documentation Standards: - Clear variable definitions - Units and coordinate systems specified - Data collection procedures documented</p>"},{"location":"contributor_guide/overview/#format-conversion","title":"Format Conversion","text":""},{"location":"contributor_guide/overview/#supported-input-formats","title":"Supported Input Formats","text":"<p>We provide conversion tools for common formats:</p> <ul> <li>C3D files (motion capture standard)</li> <li>MATLAB .mat files (lab-specific structures)</li> <li>CSV/Excel files (tabular data)</li> <li>Custom formats (with conversion script development)</li> </ul>"},{"location":"contributor_guide/overview/#target-format","title":"Target Format","text":"<p>Phase-Indexed Dataset (<code>dataset_phase.parquet</code>): - 150 points per gait cycle (0-100%) - Standardized variable names - Consistent units and coordinate systems</p> <p>Time-Indexed Dataset (<code>dataset_time.parquet</code>): - Original sampling frequency preserved - Time-series structure maintained - Raw temporal data for specialized analysis</p>"},{"location":"contributor_guide/overview/#conversion-tools","title":"Conversion Tools","text":"Automated ConversionCustom Conversion <pre><code># Use our conversion pipeline\npython convert_dataset.py \\\n    --input \"your_data_directory/\" \\\n    --format \"c3d\" \\\n    --output \"standardized_dataset.parquet\"\n</code></pre> <pre><code># Adapt our conversion template\nfrom locomotion_standardization import DatasetConverter\n\nconverter = DatasetConverter()\nconverter.load_custom_format(\"your_data.format\")\nconverter.apply_naming_convention()\nconverter.validate_biomechanics()\nconverter.save_parquet(\"output.parquet\")\n</code></pre>"},{"location":"contributor_guide/overview/#quality-validation","title":"Quality Validation","text":""},{"location":"contributor_guide/overview/#automated-validation","title":"Automated Validation","text":"<p>Our validation system checks:</p> <p>Structural Validation: - Correct number of points per cycle (150 for phase data) - Required columns present - Data types and units correct</p> <p>Biomechanical Validation: - Joint angles within expected ranges - Movement patterns physiologically plausible - Consistency across gait cycles</p> <p>Statistical Validation: - Outlier detection and flagging - Cross-cycle variability assessment - Task-appropriate movement characteristics</p>"},{"location":"contributor_guide/overview/#validation-report","title":"Validation Report","text":"<p>Every dataset receives a comprehensive quality report:</p> <pre><code># Generate validation report\npython validate_dataset.py \\\n    --dataset \"your_dataset.parquet\" \\\n    --generate-plots \\\n    --output-report \"validation_report.html\"\n</code></pre> <p>Report Contents: - Data completeness summary - Biomechanical plausibility scores - Visualization of gait patterns - Outlier identification - Recommendations for improvement</p>"},{"location":"contributor_guide/overview/#review-process","title":"Review Process","text":""},{"location":"contributor_guide/overview/#peer-review","title":"Peer Review","text":"<p>Technical Review: - Data quality assessment - Format compliance verification - Documentation completeness</p> <p>Scientific Review: - Biomechanical plausibility evaluation - Experimental design assessment - Contribution significance</p>"},{"location":"contributor_guide/overview/#review-criteria","title":"Review Criteria","text":"<p>Data Quality (40%): - Completeness and consistency - Biomechanical plausibility - Technical standards compliance</p> <p>Documentation Quality (30%): - Clear methodology description - Complete metadata - Reproducible procedures</p> <p>Scientific Value (30%): - Novel tasks or populations - Methodological innovations - Community research potential</p>"},{"location":"contributor_guide/overview/#documentation-standards","title":"Documentation Standards","text":""},{"location":"contributor_guide/overview/#dataset-documentation-template","title":"Dataset Documentation Template","text":"<pre><code># Dataset: [Your Dataset Name]\n\n## Overview\n- **Laboratory**: [Your Institution]\n- **Principal Investigator**: [Name]\n- **Data Collection Period**: [Dates]\n- **Publication Status**: [Published/Unpublished]\n\n## Participants\n- **Sample Size**: N subjects\n- **Demographics**: Age, sex, anthropometrics\n- **Inclusion/Exclusion Criteria**: [Criteria]\n\n## Experimental Protocol\n- **Tasks Performed**: [List and describe]\n- **Equipment**: [Motion capture system, force plates]\n- **Sampling Frequency**: [Hz]\n- **Data Processing**: [Filtering, event detection]\n\n## Variables Included\n- **Kinematics**: Joint angles (hip, knee, ankle)\n- **Kinetics**: Moments and forces (if available)\n- **Coordinate System**: [Convention used]\n- **Units**: [Specify for each variable]\n\n## Quality Assessment\n- **Validation Results**: [Summary of quality scores]\n- **Known Limitations**: [Any data quality issues]\n- **Recommended Use Cases**: [Suggested applications]\n</code></pre>"},{"location":"contributor_guide/overview/#metadata-schema","title":"Metadata Schema","text":"<p>Required Metadata: <pre><code>{\n  \"dataset_info\": {\n    \"name\": \"dataset_name\",\n    \"version\": \"1.0\",\n    \"doi\": \"10.xxxx/xxxxx\",\n    \"license\": \"CC-BY-4.0\"\n  },\n  \"experimental_design\": {\n    \"tasks\": [\"level_walking\", \"incline_walking\"],\n    \"subjects\": {\n      \"count\": 20,\n      \"age_range\": [18, 65],\n      \"demographics\": \"detailed_description\"\n    }\n  },\n  \"technical_details\": {\n    \"sampling_frequency\": 200,\n    \"equipment\": \"Vicon motion capture\",\n    \"coordinate_system\": \"ISB_recommendations\"\n  }\n}\n</code></pre></p>"},{"location":"contributor_guide/overview/#support-and-resources","title":"Support and Resources","text":""},{"location":"contributor_guide/overview/#getting-started","title":"Getting Started","text":"<ol> <li>Dataset Conversion Guide - Step-by-step conversion process</li> <li>Validation Tutorial - Understanding quality assessment</li> <li>Best Practices - Tips for successful contribution</li> </ol>"},{"location":"contributor_guide/overview/#community-support","title":"Community Support","text":"<ul> <li>Discussion Forum: Ask questions and share experiences</li> <li>Office Hours: Weekly virtual meetings with core team</li> <li>Documentation Wiki: Community-maintained guides and examples</li> </ul>"},{"location":"contributor_guide/overview/#technical-support","title":"Technical Support","text":"<ul> <li>GitHub Issues: Report bugs or request features</li> <li>Email Support: Direct assistance for complex issues</li> <li>Video Tutorials: Visual guides for common procedures</li> </ul>"},{"location":"contributor_guide/overview/#recognition-and-citation","title":"Recognition and Citation","text":""},{"location":"contributor_guide/overview/#contributor-recognition","title":"Contributor Recognition","text":"<p>Dataset Citation: - DOI assignment for each contributed dataset - Co-authorship on dataset descriptor publications - Recognition in project acknowledgments</p> <p>Community Contributions: - Contributor listing on project website - Annual contributor recognition awards - Conference presentation opportunities</p>"},{"location":"contributor_guide/overview/#dataset-licensing","title":"Dataset Licensing","text":"<p>Recommended License: Creative Commons Attribution 4.0 (CC-BY) - Allows broad use with appropriate attribution - Enables research reproducibility - Maintains contributor recognition</p> <p>Data Usage Tracking: - Download statistics and usage metrics - Citation tracking and impact assessment - Research outcome documentation</p>"},{"location":"contributor_guide/overview/#success-stories","title":"Success Stories","text":""},{"location":"contributor_guide/overview/#example-contributions","title":"Example Contributions","text":"<p>Georgia Tech 2023 Dataset: - 10 subjects, 3 locomotion tasks - High-quality kinematics and kinetics - Used in 15+ published studies</p> <p>University of Michigan 2021: - Incline/decline walking focus - Novel terrain conditions - Enabled meta-analysis of slope effects</p> <p>Clinical Gait Dataset 2022: - Pathological gait patterns - Diverse patient populations - Advanced clinical research applications</p>"},{"location":"contributor_guide/overview/#next-steps","title":"Next Steps","text":"<p>Ready to contribute? Follow these guides:</p> <ol> <li>Dataset Conversion - Transform your data format</li> <li>Validation Process - Ensure data quality</li> <li>Best Practices - Optimize your contribution</li> </ol> <p>Questions? Contact us at contribute@locomotion-standardization.org</p> <p>Your contribution helps build the future of biomechanics research. Thank you for joining our community!</p>"},{"location":"getting_started/first_dataset/","title":"Your First Dataset Analysis","text":"<p>Complete walkthrough of analyzing a standardized locomotion dataset from start to finish.</p> <p>What You'll Learn</p> <ul> <li>Load and explore a real biomechanical dataset</li> <li>Perform quality checks and data validation</li> <li>Conduct a comprehensive gait analysis</li> <li>Generate publication-ready visualizations</li> <li>Export results for further analysis</li> </ul>"},{"location":"getting_started/first_dataset/#dataset-overview","title":"Dataset Overview","text":"<p>We'll use the Georgia Tech 2023 dataset, which contains:</p> <ul> <li>10 subjects performing various locomotion tasks</li> <li>3 tasks: Level walking, incline walking, stair climbing</li> <li>~500 gait cycles with complete kinematic and kinetic data</li> <li>Phase-indexed format: 150 points per gait cycle (0-100%)</li> </ul>"},{"location":"getting_started/first_dataset/#step-1-load-and-explore","title":"Step 1: Load and Explore","text":"PythonMATLAB <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns\n\n# Set up plotting style\nplt.style.use('seaborn-v0_8')\nsns.set_palette(\"husl\")\n\n# Load the dataset\ndata = pd.read_parquet('gtech_2023_phase.parquet')\n\n# Initial exploration\nprint(\"=== Dataset Overview ===\")\nprint(f\"Shape: {data.shape}\")\nprint(f\"Memory usage: {data.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\nprint(f\"Date range: {data.index.min()} to {data.index.max()}\")\n\n# Check for missing data\nmissing_pct = (data.isnull().sum() / len(data)) * 100\nprint(f\"\\nMissing data:\")\nprint(missing_pct[missing_pct &gt; 0])\n\n# Basic statistics\nprint(f\"\\n=== Data Composition ===\")\nprint(f\"Subjects: {data['subject'].nunique()}\")\nprint(f\"Tasks: {', '.join(data['task'].unique())}\")\nprint(f\"Total gait cycles: {data['step'].nunique()}\")\nprint(f\"Average cycles per subject: {data.groupby('subject')['step'].nunique().mean():.1f}\")\n</code></pre> <pre><code>% Load the dataset\ndata = readtable('gtech_2023_phase.parquet');\n\n% Initial exploration\nfprintf('=== Dataset Overview ===\\n');\nfprintf('Shape: %d rows, %d columns\\n', height(data), width(data));\n\n% Check data types and basic info\nfprintf('Variables: %s\\n', strjoin(data.Properties.VariableNames, ', '));\n\n% Check for missing data\nfprintf('\\n=== Missing Data Check ===\\n');\nfor i = 1:width(data)\n    var_name = data.Properties.VariableNames{i};\n    missing_count = sum(ismissing(data.(var_name)));\n    if missing_count &gt; 0\n        fprintf('%s: %d missing (%.1f%%)\\n', var_name, missing_count, ...\n            (missing_count/height(data))*100);\n    end\nend\n\n% Basic statistics\nfprintf('\\n=== Data Composition ===\\n');\nfprintf('Subjects: %d\\n', length(unique(data.subject)));\nfprintf('Tasks: %s\\n', strjoin(unique(data.task), ', '));\nfprintf('Total gait cycles: %d\\n', length(unique(data.step)));\n\n% Average cycles per subject\ncycles_per_subject = groupcounts(data, 'subject', 'GroupingVariables', 'step');\nfprintf('Average cycles per subject: %.1f\\n', mean(cycles_per_subject.GroupCount));\n</code></pre>"},{"location":"getting_started/first_dataset/#step-2-quality-assessment","title":"Step 2: Quality Assessment","text":"<p>Before analysis, verify data quality:</p> PythonMATLAB <pre><code># Check phase indexing (should be exactly 150 points per cycle)\nprint(\"=== Phase Indexing Quality Check ===\")\nphase_counts = data.groupby(['subject', 'task', 'step']).size()\n\nif all(phase_counts == 150):\n    print(\"\u2705 Phase indexing: PASS (all cycles have 150 points)\")\nelse:\n    print(\"\u26a0\ufe0f  Phase indexing: ISSUES FOUND\")\n    print(f\"Cycles with \u2260150 points: {sum(phase_counts != 150)}\")\n\n# Check phase values (should be 0 to 100)\nphase_range = data.groupby(['subject', 'task', 'step'])['phase_percent'].agg(['min', 'max'])\n\nif all(phase_range['min'] == 0) and all(phase_range['max'] == 100):\n    print(\"\u2705 Phase range: PASS (0-100% for all cycles)\")\nelse:\n    print(\"\u26a0\ufe0f  Phase range: ISSUES FOUND\")\n\n# Check biomechanical plausibility\nprint(\"\\n=== Biomechanical Range Check ===\")\n\n# Knee flexion should be within reasonable range\nknee_angle = data['knee_flexion_angle_ipsi_rad']\nknee_deg = np.degrees(knee_angle)\n\nprint(f\"Knee flexion range: {knee_deg.min():.1f}\u00b0 to {knee_deg.max():.1f}\u00b0\")\n\nif knee_deg.min() &gt;= -10 and knee_deg.max() &lt;= 120:\n    print(\"\u2705 Knee angles: PASS (within expected range)\")\nelse:\n    print(\"\u26a0\ufe0f  Knee angles: CHECK NEEDED\")\n\n# Check for outliers (values beyond 3 standard deviations)\noutliers = np.abs(knee_deg - knee_deg.mean()) &gt; 3 * knee_deg.std()\nprint(f\"Outliers: {outliers.sum()}/{len(knee_deg)} points ({outliers.mean()*100:.1f}%)\")\n</code></pre> <pre><code>% Check phase indexing (should be exactly 150 points per cycle)\nfprintf('=== Phase Indexing Quality Check ===\\n');\n\n% Count points per cycle\nphase_counts = groupcounts(data, {'subject', 'task', 'step'});\n\nif all(phase_counts.GroupCount == 150)\n    fprintf('\u2705 Phase indexing: PASS (all cycles have 150 points)\\n');\nelse\n    fprintf('\u26a0\ufe0f  Phase indexing: ISSUES FOUND\\n');\n    fprintf('Cycles with \u2260150 points: %d\\n', sum(phase_counts.GroupCount ~= 150));\nend\n\n% Check phase values (should be 0 to 100)\nphase_summary = groupsummary(data, {'subject', 'task', 'step'}, {'min', 'max'}, 'phase_percent');\n\nif all(phase_summary.min_phase_percent == 0) &amp;&amp; all(phase_summary.max_phase_percent == 100)\n    fprintf('\u2705 Phase range: PASS (0-100%% for all cycles)\\n');\nelse\n    fprintf('\u26a0\ufe0f  Phase range: ISSUES FOUND\\n');\nend\n\n% Check biomechanical plausibility\nfprintf('\\n=== Biomechanical Range Check ===\\n');\n\n% Knee flexion should be within reasonable range\nknee_angle = data.knee_flexion_angle_ipsi_rad;\nknee_deg = rad2deg(knee_angle);\n\nfprintf('Knee flexion range: %.1f\u00b0 to %.1f\u00b0\\n', min(knee_deg), max(knee_deg));\n\nif min(knee_deg) &gt;= -10 &amp;&amp; max(knee_deg) &lt;= 120\n    fprintf('\u2705 Knee angles: PASS (within expected range)\\n');\nelse\n    fprintf('\u26a0\ufe0f  Knee angles: CHECK NEEDED\\n');\nend\n\n% Check for outliers (values beyond 3 standard deviations)\noutliers = abs(knee_deg - mean(knee_deg)) &gt; 3 * std(knee_deg);\nfprintf('Outliers: %d/%d points (%.1f%%)\\n', sum(outliers), length(knee_deg), mean(outliers)*100);\n</code></pre>"},{"location":"getting_started/first_dataset/#step-3-comprehensive-gait-analysis","title":"Step 3: Comprehensive Gait Analysis","text":"<p>Analyze gait patterns across different conditions:</p> PythonMATLAB <pre><code># Create comprehensive analysis\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\nfig.suptitle('Comprehensive Gait Analysis - Georgia Tech 2023 Dataset', fontsize=16)\n\n# 1. Average gait patterns by task\nax1 = axes[0, 0]\nfor task in data['task'].unique():\n    task_data = data[data['task'] == task]\n    avg_pattern = task_data.groupby('phase_percent')['knee_flexion_angle_ipsi_rad'].mean()\n    ax1.plot(avg_pattern.index, np.degrees(avg_pattern.values), \n            label=task.replace('_', ' ').title(), linewidth=2)\n\nax1.set_xlabel('Gait Cycle (%)')\nax1.set_ylabel('Knee Flexion (degrees)')\nax1.set_title('Average Knee Angle by Task')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# 2. Subject variability\nax2 = axes[0, 1]\nlevel_walking = data[data['task'] == 'level_walking']\n\nfor subject in level_walking['subject'].unique()[:5]:  # Show first 5 subjects\n    subj_data = level_walking[level_walking['subject'] == subject]\n    avg_pattern = subj_data.groupby('phase_percent')['knee_flexion_angle_ipsi_rad'].mean()\n    ax2.plot(avg_pattern.index, np.degrees(avg_pattern.values), \n            alpha=0.7, label=subject)\n\nax2.set_xlabel('Gait Cycle (%)')\nax2.set_ylabel('Knee Flexion (degrees)')\nax2.set_title('Inter-Subject Variability (Level Walking)')\nax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nax2.grid(True, alpha=0.3)\n\n# 3. Range of motion comparison\nax3 = axes[0, 2]\nrom_data = []\nfor task in data['task'].unique():\n    task_data = data[data['task'] == task]\n    rom_by_cycle = task_data.groupby(['subject', 'step'])['knee_flexion_angle_ipsi_rad'].apply(\n        lambda x: np.degrees(x.max() - x.min())\n    )\n    rom_data.extend([(task, rom) for rom in rom_by_cycle])\n\nrom_df = pd.DataFrame(rom_data, columns=['Task', 'ROM'])\nsns.boxplot(data=rom_df, x='Task', y='ROM', ax=ax3)\nax3.set_ylabel('Knee ROM (degrees)')\nax3.set_title('Range of Motion by Task')\nax3.tick_params(axis='x', rotation=45)\n\n# 4. Peak knee flexion timing\nax4 = axes[1, 0]\npeak_timing = []\nfor task in data['task'].unique():\n    task_data = data[data['task'] == task]\n    for (subject, step), group in task_data.groupby(['subject', 'step']):\n        peak_idx = group['knee_flexion_angle_ipsi_rad'].idxmax()\n        peak_phase = group.loc[peak_idx, 'phase_percent']\n        peak_timing.append((task, peak_phase))\n\ntiming_df = pd.DataFrame(peak_timing, columns=['Task', 'Peak_Phase'])\nsns.boxplot(data=timing_df, x='Task', y='Peak_Phase', ax=ax4)\nax4.set_ylabel('Peak Knee Flexion Phase (%)')\nax4.set_title('Peak Flexion Timing')\nax4.tick_params(axis='x', rotation=45)\n\n# 5. Gait cycle consistency\nax5 = axes[1, 1]\nconsistency_data = []\nfor subject in data['subject'].unique():\n    subj_data = data[(data['subject'] == subject) &amp; (data['task'] == 'level_walking')]\n    if len(subj_data) &gt; 0:\n        # Calculate coefficient of variation across cycles\n        cv_by_phase = subj_data.groupby('phase_percent')['knee_flexion_angle_ipsi_rad'].apply(\n            lambda x: np.std(x) / np.abs(np.mean(x)) if np.mean(x) != 0 else 0\n        )\n        consistency_data.append(cv_by_phase.mean())\n\nax5.hist(consistency_data, bins=10, alpha=0.7, edgecolor='black')\nax5.set_xlabel('Coefficient of Variation')\nax5.set_ylabel('Number of Subjects')\nax5.set_title('Gait Consistency (Level Walking)')\nax5.grid(True, alpha=0.3)\n\n# 6. Data quality summary\nax6 = axes[1, 2]\nquality_metrics = {\n    'Complete Cycles': sum(data.groupby(['subject', 'step']).size() == 150),\n    'Valid Phase Range': sum((data.groupby(['subject', 'step'])['phase_percent'].min() == 0) &amp; \n                            (data.groupby(['subject', 'step'])['phase_percent'].max() == 100)),\n    'No Missing Data': sum(~data.groupby(['subject', 'step'])['knee_flexion_angle_ipsi_rad'].apply(\n        lambda x: x.isnull().any())),\n    'Plausible Range': sum(data.groupby(['subject', 'step'])['knee_flexion_angle_ipsi_rad'].apply(\n        lambda x: (np.degrees(x.min()) &gt;= -10) &amp; (np.degrees(x.max()) &lt;= 120)))\n}\n\ntotal_cycles = data['step'].nunique()\nquality_pct = {k: (v/total_cycles)*100 for k, v in quality_metrics.items()}\n\nbars = ax6.bar(range(len(quality_pct)), list(quality_pct.values()))\nax6.set_xticks(range(len(quality_pct)))\nax6.set_xticklabels(list(quality_pct.keys()), rotation=45, ha='right')\nax6.set_ylabel('Percentage of Cycles (%)')\nax6.set_title('Data Quality Metrics')\nax6.set_ylim(0, 105)\n\n# Add percentage labels on bars\nfor bar, pct in zip(bars, quality_pct.values()):\n    ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n            f'{pct:.1f}%', ha='center', va='bottom')\n\nplt.tight_layout()\nplt.savefig('comprehensive_gait_analysis.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"Comprehensive analysis saved as 'comprehensive_gait_analysis.png'\")\n</code></pre> <pre><code>% Create comprehensive analysis\nfigure('Position', [100, 100, 1200, 800]);\n\n% 1. Average gait patterns by task\nsubplot(2, 3, 1);\ntasks = unique(data.task);\ncolors = lines(length(tasks));\n\nfor i = 1:length(tasks)\n    task = tasks{i};\n    task_data = data(strcmp(data.task, task), :);\n    avg_pattern = groupsummary(task_data, 'phase_percent', 'mean', 'knee_flexion_angle_ipsi_rad');\n\n    plot(avg_pattern.phase_percent, rad2deg(avg_pattern.mean_knee_flexion_angle_ipsi_rad), ...\n        'Color', colors(i,:), 'LineWidth', 2, 'DisplayName', strrep(task, '_', ' '));\n    hold on;\nend\n\nxlabel('Gait Cycle (%)');\nylabel('Knee Flexion (degrees)');\ntitle('Average Knee Angle by Task');\nlegend('show');\ngrid on;\nhold off;\n\n% 2. Subject variability\nsubplot(2, 3, 2);\nlevel_walking = data(strcmp(data.task, 'level_walking'), :);\nsubjects = unique(level_walking.subject);\n\nfor i = 1:min(5, length(subjects))  % Show first 5 subjects\n    subject = subjects{i};\n    subj_data = level_walking(strcmp(level_walking.subject, subject), :);\n    avg_pattern = groupsummary(subj_data, 'phase_percent', 'mean', 'knee_flexion_angle_ipsi_rad');\n\n    plot(avg_pattern.phase_percent, rad2deg(avg_pattern.mean_knee_flexion_angle_ipsi_rad), ...\n        'LineWidth', 1.5, 'DisplayName', subject);\n    hold on;\nend\n\nxlabel('Gait Cycle (%)');\nylabel('Knee Flexion (degrees)');\ntitle('Inter-Subject Variability (Level Walking)');\nlegend('show');\ngrid on;\nhold off;\n\n% 3. Range of motion comparison\nsubplot(2, 3, 3);\nrom_by_task = cell(length(tasks), 1);\n\nfor i = 1:length(tasks)\n    task = tasks{i};\n    task_data = data(strcmp(data.task, task), :);\n\n    % Calculate ROM for each cycle\n    rom_summary = groupsummary(task_data, {'subject', 'step'}, {'min', 'max'}, 'knee_flexion_angle_ipsi_rad');\n    rom_values = rad2deg(rom_summary.max_knee_flexion_angle_ipsi_rad - rom_summary.min_knee_flexion_angle_ipsi_rad);\n\n    rom_by_task{i} = rom_values;\nend\n\nboxplot([rom_by_task{:}], 'Labels', strrep(tasks, '_', ' '));\nylabel('Knee ROM (degrees)');\ntitle('Range of Motion by Task');\nxtickangle(45);\n\n% 4. Peak knee flexion timing\nsubplot(2, 3, 4);\npeak_timing_by_task = cell(length(tasks), 1);\n\nfor i = 1:length(tasks)\n    task = tasks{i};\n    task_data = data(strcmp(data.task, task), :);\n\n    % Find peak timing for each cycle\n    cycle_groups = findgroups(task_data.subject, task_data.step);\n    peak_phases = splitapply(@(angle, phase) phase(angle == max(angle)), ...\n        task_data.knee_flexion_angle_ipsi_rad, task_data.phase_percent, cycle_groups);\n\n    peak_timing_by_task{i} = peak_phases;\nend\n\nboxplot([peak_timing_by_task{:}], 'Labels', strrep(tasks, '_', ' '));\nylabel('Peak Knee Flexion Phase (%)');\ntitle('Peak Flexion Timing');\nxtickangle(45);\n\n% 5. Gait cycle consistency\nsubplot(2, 3, 5);\nsubjects = unique(data.subject);\nconsistency_values = zeros(length(subjects), 1);\n\nfor i = 1:length(subjects)\n    subject = subjects{i};\n    subj_data = data(strcmp(data.subject, subject) &amp; strcmp(data.task, 'level_walking'), :);\n\n    if ~isempty(subj_data)\n        % Calculate coefficient of variation by phase\n        cv_by_phase = groupsummary(subj_data, 'phase_percent', {'mean', 'std'}, 'knee_flexion_angle_ipsi_rad');\n        cv_values = cv_by_phase.std_knee_flexion_angle_ipsi_rad ./ abs(cv_by_phase.mean_knee_flexion_angle_ipsi_rad);\n        consistency_values(i) = mean(cv_values(~isnan(cv_values) &amp; ~isinf(cv_values)));\n    end\nend\n\nhistogram(consistency_values(consistency_values &gt; 0), 10, 'EdgeColor', 'black');\nxlabel('Coefficient of Variation');\nylabel('Number of Subjects');\ntitle('Gait Consistency (Level Walking)');\ngrid on;\n\n% 6. Data quality summary\nsubplot(2, 3, 6);\n\n% Calculate quality metrics\ncycle_groups = findgroups(data.subject, data.task, data.step);\npoints_per_cycle = splitapply(@height, data, cycle_groups);\ncomplete_cycles = sum(points_per_cycle == 150);\n\nphase_ranges = splitapply(@(p) [min(p), max(p)], data.phase_percent, cycle_groups);\nvalid_ranges = sum(phase_ranges(:,1) == 0 &amp; phase_ranges(:,2) == 100);\n\nknee_ranges = splitapply(@(k) [min(k), max(k)], data.knee_flexion_angle_ipsi_rad, cycle_groups);\nplausible_ranges = sum(rad2deg(knee_ranges(:,1)) &gt;= -10 &amp; rad2deg(knee_ranges(:,2)) &lt;= 120);\n\ntotal_cycles = length(unique(data.step));\n\nquality_metrics = [complete_cycles, valid_ranges, total_cycles, plausible_ranges];\nquality_labels = {'Complete Cycles', 'Valid Phase Range', 'No Missing Data', 'Plausible Range'};\nquality_pct = (quality_metrics / total_cycles) * 100;\n\nb = bar(quality_pct);\nset(gca, 'XTickLabel', quality_labels);\nxtickangle(45);\nylabel('Percentage of Cycles (%)');\ntitle('Data Quality Metrics');\nylim([0, 105]);\n\n% Add percentage labels\nfor i = 1:length(quality_pct)\n    text(i, quality_pct(i) + 2, sprintf('%.1f%%', quality_pct(i)), ...\n        'HorizontalAlignment', 'center');\nend\n\nsgtitle('Comprehensive Gait Analysis - Georgia Tech 2023 Dataset');\n\n% Save the figure\nsaveas(gcf, 'comprehensive_gait_analysis.png');\n\nfprintf('Comprehensive analysis saved as ''comprehensive_gait_analysis.png''\\n');\n</code></pre>"},{"location":"getting_started/first_dataset/#step-4-statistical-analysis","title":"Step 4: Statistical Analysis","text":"<p>Perform statistical comparisons between conditions:</p> PythonMATLAB <pre><code>from scipy import stats\n\n# Compare peak knee flexion between tasks\nprint(\"=== Statistical Analysis ===\")\n\n# Extract peak knee flexion for each cycle\npeak_flexion_data = []\nfor task in data['task'].unique():\n    task_data = data[data['task'] == task]\n    for (subject, step), group in task_data.groupby(['subject', 'step']):\n        peak_angle = np.degrees(group['knee_flexion_angle_ipsi_rad'].max())\n        peak_flexion_data.append({\n            'task': task, \n            'subject': subject, \n            'step': step, \n            'peak_knee_flexion': peak_angle\n        })\n\npeak_df = pd.DataFrame(peak_flexion_data)\n\n# Descriptive statistics\nprint(\"\\nPeak Knee Flexion by Task (degrees):\")\nprint(peak_df.groupby('task')['peak_knee_flexion'].agg(['count', 'mean', 'std', 'min', 'max']).round(1))\n\n# Statistical comparison (ANOVA)\nif len(data['task'].unique()) &gt; 2:\n    groups = [peak_df[peak_df['task'] == task]['peak_knee_flexion'].values \n             for task in data['task'].unique()]\n    f_stat, p_value = stats.f_oneway(*groups)\n\n    print(f\"\\nOne-way ANOVA:\")\n    print(f\"F-statistic: {f_stat:.3f}\")\n    print(f\"p-value: {p_value:.3e}\")\n\n    if p_value &lt; 0.05:\n        print(\"\u2705 Significant differences between tasks (p &lt; 0.05)\")\n\n        # Post-hoc pairwise comparisons\n        from itertools import combinations\n        tasks = data['task'].unique()\n\n        print(\"\\nPairwise t-tests (with Bonferroni correction):\")\n        alpha_corrected = 0.05 / len(list(combinations(tasks, 2)))\n\n        for task1, task2 in combinations(tasks, 2):\n            group1 = peak_df[peak_df['task'] == task1]['peak_knee_flexion']\n            group2 = peak_df[peak_df['task'] == task2]['peak_knee_flexion']\n\n            t_stat, p_val = stats.ttest_ind(group1, group2)\n            significant = p_val &lt; alpha_corrected\n\n            print(f\"{task1} vs {task2}: t={t_stat:.3f}, p={p_val:.3e} {'*' if significant else ''}\")\n    else:\n        print(\"No significant differences between tasks (p &gt;= 0.05)\")\n</code></pre> <pre><code>% Statistical Analysis\nfprintf('=== Statistical Analysis ===\\n');\n\n% Extract peak knee flexion for each cycle\ncycle_groups = findgroups(data.subject, data.task, data.step);\npeak_flexion = splitapply(@max, data.knee_flexion_angle_ipsi_rad, cycle_groups);\n[subjects, tasks, steps] = splitapply(@(s,t,st) {s{1}, t{1}, st(1)}, ...\n    data.subject, data.task, data.step, cycle_groups);\n\n% Create summary table\npeak_data = table(subjects, tasks, steps, rad2deg(peak_flexion), ...\n    'VariableNames', {'subject', 'task', 'step', 'peak_knee_flexion'});\n\n% Descriptive statistics\nfprintf('\\nPeak Knee Flexion by Task (degrees):\\n');\ntask_stats = groupsummary(peak_data, 'task', {'count', 'mean', 'std', 'min', 'max'}, 'peak_knee_flexion');\ndisp(task_stats);\n\n% Statistical comparison (ANOVA)\nunique_tasks = unique(data.task);\nif length(unique_tasks) &gt; 2\n    [p, tbl, stats] = anova1(peak_data.peak_knee_flexion, peak_data.task, 'off');\n\n    fprintf('\\nOne-way ANOVA:\\n');\n    fprintf('F-statistic: %.3f\\n', tbl{2,5});\n    fprintf('p-value: %.3e\\n', p);\n\n    if p &lt; 0.05\n        fprintf('\u2705 Significant differences between tasks (p &lt; 0.05)\\n');\n\n        % Post-hoc multiple comparisons\n        fprintf('\\nPost-hoc multiple comparisons:\\n');\n        [c, m, h, nms] = multcompare(stats, 'Display', 'off');\n\n        for i = 1:size(c, 1)\n            task1 = nms{c(i,1)};\n            task2 = nms{c(i,2)};\n            p_val = c(i,6);\n            significant = p_val &lt; 0.05;\n\n            fprintf('%s vs %s: p=%.3e %s\\n', task1, task2, p_val, ...\n                char(42 * significant)); % Print * if significant\n        end\n    else\n        fprintf('No significant differences between tasks (p &gt;= 0.05)\\n');\n    end\nend\n</code></pre>"},{"location":"getting_started/first_dataset/#step-5-export-results","title":"Step 5: Export Results","text":"<p>Save your analysis results for further use:</p> PythonMATLAB <pre><code># Create summary report\nsummary_results = {\n    'dataset_info': {\n        'name': 'Georgia Tech 2023',\n        'subjects': int(data['subject'].nunique()),\n        'tasks': list(data['task'].unique()),\n        'total_cycles': int(data['step'].nunique()),\n        'total_datapoints': len(data)\n    },\n    'quality_metrics': {\n        'complete_cycles_pct': (sum(data.groupby(['subject', 'step']).size() == 150) / data['step'].nunique()) * 100,\n        'missing_data_pct': (data.isnull().sum().sum() / data.size) * 100,\n        'outlier_pct': (outliers.sum() / len(outliers)) * 100\n    },\n    'biomechanical_summary': {\n        'knee_flexion_mean_deg': float(np.degrees(data['knee_flexion_angle_ipsi_rad'].mean())),\n        'knee_flexion_std_deg': float(np.degrees(data['knee_flexion_angle_ipsi_rad'].std())),\n        'knee_flexion_range_deg': [\n            float(np.degrees(data['knee_flexion_angle_ipsi_rad'].min())),\n            float(np.degrees(data['knee_flexion_angle_ipsi_rad'].max()))\n        ]\n    }\n}\n\n# Save as JSON\nimport json\nwith open('analysis_summary.json', 'w') as f:\n    json.dump(summary_results, f, indent=2)\n\n# Save processed data for further analysis\n# Create cycle-level summary\ncycle_summary = data.groupby(['subject', 'task', 'step']).agg({\n    'knee_flexion_angle_ipsi_rad': ['min', 'max', 'mean'],\n    'hip_flexion_angle_ipsi_rad': ['min', 'max', 'mean'],\n    'ankle_flexion_angle_ipsi_rad': ['min', 'max', 'mean']\n}).round(4)\n\n# Flatten column names\ncycle_summary.columns = ['_'.join(col).strip() for col in cycle_summary.columns]\ncycle_summary = cycle_summary.reset_index()\n\n# Add range of motion columns\ncycle_summary['knee_rom_rad'] = (cycle_summary['knee_flexion_angle_ipsi_rad_max'] - \n                                cycle_summary['knee_flexion_angle_ipsi_rad_min'])\ncycle_summary['hip_rom_rad'] = (cycle_summary['hip_flexion_angle_ipsi_rad_max'] - \n                               cycle_summary['hip_flexion_angle_ipsi_rad_min'])\ncycle_summary['ankle_rom_rad'] = (cycle_summary['ankle_flexion_angle_ipsi_rad_max'] - \n                                 cycle_summary['ankle_flexion_angle_ipsi_rad_min'])\n\ncycle_summary.to_csv('cycle_level_summary.csv', index=False)\n\nprint(\"=== Analysis Complete ===\")\nprint(\"Files generated:\")\nprint(\"- comprehensive_gait_analysis.png (6-panel analysis)\")\nprint(\"- analysis_summary.json (key metrics)\")\nprint(\"- cycle_level_summary.csv (cycle-by-cycle data)\")\nprint(f\"\\nCycles analyzed: {len(cycle_summary)}\")\nprint(f\"Average knee ROM: {np.degrees(cycle_summary['knee_rom_rad'].mean()):.1f}\u00b0 \u00b1 {np.degrees(cycle_summary['knee_rom_rad'].std()):.1f}\u00b0\")\n</code></pre> <pre><code>% Create cycle-level summary\ncycle_summary = groupsummary(data, {'subject', 'task', 'step'}, ...\n    {'min', 'max', 'mean'}, {'knee_flexion_angle_ipsi_rad', ...\n    'hip_flexion_angle_ipsi_rad', 'ankle_flexion_angle_ipsi_rad'});\n\n% Add range of motion columns\ncycle_summary.knee_rom_rad = cycle_summary.max_knee_flexion_angle_ipsi_rad - ...\n    cycle_summary.min_knee_flexion_angle_ipsi_rad;\ncycle_summary.hip_rom_rad = cycle_summary.max_hip_flexion_angle_ipsi_rad - ...\n    cycle_summary.min_hip_flexion_angle_ipsi_rad;\ncycle_summary.ankle_rom_rad = cycle_summary.max_ankle_flexion_angle_ipsi_rad - ...\n    cycle_summary.min_ankle_flexion_angle_ipsi_rad;\n\n% Save results\nwritetable(cycle_summary, 'cycle_level_summary.csv');\n\n% Create summary structure\nsummary_results = struct();\nsummary_results.dataset_info.name = 'Georgia Tech 2023';\nsummary_results.dataset_info.subjects = length(unique(data.subject));\nsummary_results.dataset_info.tasks = unique(data.task);\nsummary_results.dataset_info.total_cycles = length(unique(data.step));\nsummary_results.dataset_info.total_datapoints = height(data);\n\nsummary_results.biomechanical_summary.knee_flexion_mean_deg = ...\n    rad2deg(mean(data.knee_flexion_angle_ipsi_rad));\nsummary_results.biomechanical_summary.knee_flexion_std_deg = ...\n    rad2deg(std(data.knee_flexion_angle_ipsi_rad));\nsummary_results.biomechanical_summary.knee_rom_mean_deg = ...\n    rad2deg(mean(cycle_summary.knee_rom_rad));\n\n% Save as MAT file\nsave('analysis_summary.mat', 'summary_results');\n\nfprintf('=== Analysis Complete ===\\n');\nfprintf('Files generated:\\n');\nfprintf('- comprehensive_gait_analysis.png (6-panel analysis)\\n');\nfprintf('- analysis_summary.mat (key metrics)\\n');\nfprintf('- cycle_level_summary.csv (cycle-by-cycle data)\\n');\nfprintf('\\nCycles analyzed: %d\\n', height(cycle_summary));\nfprintf('Average knee ROM: %.1f\u00b0 \u00b1 %.1f\u00b0\\n', ...\n    rad2deg(mean(cycle_summary.knee_rom_rad)), ...\n    rad2deg(std(cycle_summary.knee_rom_rad)));\n</code></pre>"},{"location":"getting_started/first_dataset/#what-youve-accomplished","title":"What You've Accomplished","text":"<p>Congratulations! You've completed a comprehensive analysis including:</p> <ul> <li>\u2705 Data loading and exploration - Understanding dataset structure</li> <li>\u2705 Quality assessment - Validating data integrity</li> <li>\u2705 Comprehensive visualization - 6-panel analysis figure</li> <li>\u2705 Statistical analysis - Comparing conditions with ANOVA</li> <li>\u2705 Results export - Saving analysis for future use</li> </ul>"},{"location":"getting_started/first_dataset/#key-findings-template","title":"Key Findings Template","text":"<p>Use this template to summarize your results:</p> <p>Analysis Summary</p> <p>Dataset: Georgia Tech 2023 (N=10 subjects, 3 tasks, ~500 cycles)</p> <p>Data Quality:  - \u2705 Phase indexing: 100% cycles have 150 points - \u2705 Biomechanical range: All values within expected limits - \u2705 Missing data: &lt;1% of total datapoints</p> <p>Key Findings: - Average knee ROM: XX\u00b0 \u00b1 XX\u00b0 (level walking) - Peak knee flexion: Level walking &lt; Incline walking &lt; Stair climbing - Inter-subject variability: CV = XX%</p> <p>Statistical Results: - ANOVA: F(2,XXX) = XX.XX, p &lt; 0.001 - Post-hoc: All pairwise comparisons significant (p &lt; 0.05)</p>"},{"location":"getting_started/first_dataset/#next-steps","title":"Next Steps","text":""},{"location":"getting_started/first_dataset/#advanced-analysis","title":"Advanced Analysis","text":"<ul> <li>Working with Data - Advanced analysis techniques</li> <li>API Reference - Complete function documentation</li> </ul>"},{"location":"getting_started/first_dataset/#multiple-datasets","title":"Multiple Datasets","text":"<ul> <li>Combine datasets from different sources</li> <li>Cross-lab validation and comparison</li> <li>Meta-analysis across studies</li> </ul>"},{"location":"getting_started/first_dataset/#contribute-back","title":"Contribute Back","text":"<ul> <li>Contributor Guide - Share your datasets</li> <li>Validation Tuning - Improve quality standards</li> </ul> <p>This analysis template can be adapted for any standardized dataset. Questions? Check our Troubleshooting Guide.</p>"},{"location":"getting_started/installation/","title":"Installation","text":"<p>Get set up to work with standardized locomotion data in just a few minutes.</p>"},{"location":"getting_started/installation/#choose-your-environment","title":"Choose Your Environment","text":"Python UsersMATLAB Users"},{"location":"getting_started/installation/#system-requirements","title":"System Requirements","text":"<ul> <li>Python 3.8 or newer</li> <li>8GB RAM recommended (4GB minimum)</li> <li>2GB disk space for datasets</li> </ul>"},{"location":"getting_started/installation/#quick-install","title":"Quick Install","text":"<pre><code># Install required packages\npip install pandas matplotlib numpy pyarrow\n\n# Verify installation\npython -c \"import pandas, matplotlib, numpy; print('Ready to go!')\"\n</code></pre>"},{"location":"getting_started/installation/#conda-environment-recommended","title":"Conda Environment (Recommended)","text":"<pre><code># Create dedicated environment\nconda create -n locomotion python=3.10 pandas matplotlib numpy pyarrow\nconda activate locomotion\n\n# Verify installation\npython -c \"import pandas, matplotlib, numpy; print('Environment ready!')\"\n</code></pre>"},{"location":"getting_started/installation/#system-requirements_1","title":"System Requirements","text":"<ul> <li>MATLAB R2019b or newer</li> <li>Statistics and Machine Learning Toolbox (recommended)</li> <li>8GB RAM recommended (4GB minimum)</li> <li>2GB disk space for datasets</li> </ul>"},{"location":"getting_started/installation/#required-toolboxes","title":"Required Toolboxes","text":"<p>Check if you have the required toolboxes: <pre><code>% Check available toolboxes\nver\n\n% Look for these (recommended but not required):\n% - Statistics and Machine Learning Toolbox\n% - Signal Processing Toolbox\n</code></pre></p>"},{"location":"getting_started/installation/#verify-installation","title":"Verify Installation","text":"<pre><code>% Test basic functionality\ndata = table([1; 2; 3], [0.1; 0.2; 0.3], 'VariableNames', {'step', 'angle'});\ndisp('MATLAB ready for locomotion data analysis!')\n</code></pre>"},{"location":"getting_started/installation/#download-sample-data","title":"Download Sample Data","text":"<p>Get started with a small sample dataset:</p> Command LinePython Script <pre><code># Create workspace directory\nmkdir locomotion_analysis\ncd locomotion_analysis\n\n# Download sample dataset (placeholder - will be updated with actual URLs)\ncurl -O https://example.com/sample_gtech_2023_phase.parquet\n\n# Verify download\nls -la *.parquet\n</code></pre> <pre><code>import os\nimport urllib.request\n\n# Create workspace\nos.makedirs('locomotion_analysis', exist_ok=True)\nos.chdir('locomotion_analysis')\n\n# Download sample dataset\nurl = 'https://example.com/sample_gtech_2023_phase.parquet'\nurllib.request.urlretrieve(url, 'sample_data.parquet')\n\nprint(\"Sample data downloaded successfully!\")\n</code></pre>"},{"location":"getting_started/installation/#verify-your-setup","title":"Verify Your Setup","text":"<p>Test that everything works correctly:</p> Python TestMATLAB Test <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Test data loading (using built-in sample data)\n# This creates a minimal test dataset\ntest_data = pd.DataFrame({\n    'subject': ['SUB01'] * 150,\n    'task': ['level_walking'] * 150,\n    'step': [1] * 150,\n    'phase_percent': np.linspace(0, 100, 150),\n    'knee_flexion_angle_ipsi_rad': np.sin(np.linspace(0, 2*np.pi, 150)) * 0.5 + 0.3\n})\n\n# Test basic operations\nprint(f\"Dataset shape: {test_data.shape}\")\nprint(f\"Available columns: {list(test_data.columns)}\")\n\n# Test plotting\nplt.figure(figsize=(8, 4))\nplt.plot(test_data['phase_percent'], test_data['knee_flexion_angle_ipsi_rad'])\nplt.xlabel('Gait Cycle (%)')\nplt.ylabel('Knee Flexion (rad)')\nplt.title('Test Plot - Installation Successful!')\nplt.grid(True)\nplt.savefig('installation_test.png')\nprint(\"\u2705 Python setup verified! Test plot saved as 'installation_test.png'\")\n</code></pre> <pre><code>% Test data loading and basic operations\n% Create test dataset\nphase_percent = linspace(0, 100, 150)';\nknee_angle = sin(linspace(0, 2*pi, 150))' * 0.5 + 0.3;\n\ntest_data = table(...\n    repmat({'SUB01'}, 150, 1), ...\n    repmat({'level_walking'}, 150, 1), ...\n    ones(150, 1), ...\n    phase_percent, ...\n    knee_angle, ...\n    'VariableNames', {'subject', 'task', 'step', 'phase_percent', 'knee_flexion_angle_ipsi_rad'});\n\n% Test basic operations\nfprintf('Dataset size: %d rows, %d columns\\n', height(test_data), width(test_data));\nfprintf('Available columns: %s\\n', strjoin(test_data.Properties.VariableNames, ', '));\n\n% Test plotting\nfigure;\nplot(test_data.phase_percent, test_data.knee_flexion_angle_ipsi_rad);\nxlabel('Gait Cycle (%)');\nylabel('Knee Flexion (rad)');\ntitle('Test Plot - Installation Successful!');\ngrid on;\nsaveas(gcf, 'installation_test.png');\n\nfprintf('\u2705 MATLAB setup verified! Test plot saved as ''installation_test.png''\\n');\n</code></pre>"},{"location":"getting_started/installation/#common-installation-issues","title":"Common Installation Issues","text":""},{"location":"getting_started/installation/#python-issues","title":"Python Issues","text":"<p>ImportError: No module named 'pandas'</p> <p>Solution: Install pandas <pre><code>pip install pandas\n</code></pre></p> <p>Memory Error when loading large datasets</p> <p>Solution: Use chunked loading <pre><code># For large datasets, load in chunks\nchunk_size = 10000\ndata_chunks = pd.read_parquet('large_dataset.parquet', chunksize=chunk_size)\n</code></pre></p>"},{"location":"getting_started/installation/#matlab-issues","title":"MATLAB Issues","text":"<p>Error using readtable: Unable to interpret file</p> <p>Solution: Check MATLAB version and file format <pre><code>% Check MATLAB version\nversion\n\n% For older MATLAB versions, convert parquet to CSV first\n% (conversion instructions in troubleshooting guide)\n</code></pre></p> <p>Out of memory errors</p> <p>Solution: Clear workspace and increase memory <pre><code>clear all\nclose all\n\n% Check available memory\nfeature('memstats')\n</code></pre></p>"},{"location":"getting_started/installation/#next-steps","title":"Next Steps","text":"<p>Once your installation is verified:</p> <ol> <li>Quick Start - Load and analyze your first dataset</li> <li>First Dataset - Work through a complete analysis example</li> <li>Python Tutorial - Comprehensive Python guide</li> <li>MATLAB Tutorial - Comprehensive MATLAB guide</li> </ol>"},{"location":"getting_started/installation/#need-help","title":"Need Help?","text":"<ul> <li>Installation problems? Check our Troubleshooting Guide</li> <li>Environment issues? See platform-specific guides below</li> <li>Still stuck? Open an issue on GitHub</li> </ul>"},{"location":"getting_started/installation/#platform-specific-notes","title":"Platform-Specific Notes","text":"WindowsmacOSLinux <ul> <li>Use Anaconda for Python package management</li> <li>MATLAB path issues: Add toolbox directories manually</li> <li>Recommended: Use Windows Subsystem for Linux (WSL) for command-line tools</li> </ul> <ul> <li>Use Homebrew for system dependencies</li> <li>Python: Install via <code>brew install python</code> or Anaconda</li> <li>MATLAB: Standard installation works well</li> </ul> <ul> <li>Install Python via package manager or conda</li> <li>Ensure you have build tools: <code>sudo apt-get install build-essential</code></li> <li>For MATLAB: May need to install additional libraries</li> </ul> <p>Ready to start analyzing locomotion data? Continue to the Quick Start Guide.</p>"},{"location":"getting_started/quick_start/","title":"Quick Start Guide","text":"<p>Get up and running with standardized locomotion data in 10 minutes.</p> <p>Prerequisites</p> <p>Make sure you've completed the Installation first.</p>"},{"location":"getting_started/quick_start/#what-youll-learn","title":"What You'll Learn","text":"<p>In this quick start, you'll:</p> <ol> <li>Load a standardized dataset</li> <li>Explore the data structure</li> <li>Filter data for specific tasks</li> <li>Create your first visualization</li> <li>Calculate basic biomechanical metrics</li> </ol>"},{"location":"getting_started/quick_start/#load-your-first-dataset","title":"Load Your First Dataset","text":"PythonMATLAB <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Load a standardized dataset\n# Note: Replace with actual dataset path\ndata = pd.read_parquet('sample_gtech_2023_phase.parquet')\n\n# Explore the dataset\nprint(f\"Dataset shape: {data.shape}\")\nprint(f\"Columns: {list(data.columns)}\")\nprint(f\"Unique tasks: {data['task'].unique()}\")\nprint(f\"Unique subjects: {data['subject'].unique()}\")\n</code></pre> <pre><code>% Load a standardized dataset\ndata = readtable('sample_gtech_2023_phase.parquet');\n\n% Explore the dataset\nfprintf('Dataset size: %d rows, %d columns\\n', height(data), width(data));\nfprintf('Columns: %s\\n', strjoin(data.Properties.VariableNames, ', '));\nfprintf('Unique tasks: %s\\n', strjoin(unique(data.task), ', '));\nfprintf('Unique subjects: %s\\n', strjoin(unique(data.subject), ', '));\n</code></pre> <p>Expected Output: <pre><code>Dataset shape: (1500, 8)\nColumns: ['subject', 'task', 'step', 'phase_percent', 'knee_flexion_angle_ipsi_rad', 'hip_flexion_angle_ipsi_rad', 'ankle_flexion_angle_ipsi_rad', 'vertical_grf_ipsi_N']\nUnique tasks: ['level_walking', 'incline_walking', 'up_stairs']\nUnique subjects: ['SUB01', 'SUB02', 'SUB03']\n</code></pre></p>"},{"location":"getting_started/quick_start/#understanding-the-data-structure","title":"Understanding the Data Structure","text":"<p>All standardized datasets follow the same structure:</p>"},{"location":"getting_started/quick_start/#required-columns","title":"Required Columns","text":"<ul> <li><code>subject</code>: Subject identifier (e.g., 'SUB01')</li> <li><code>task</code>: Task name (e.g., 'level_walking')</li> <li><code>step</code>: Step/cycle number within the trial</li> <li><code>phase_percent</code>: Gait cycle phase (0-100%)</li> </ul>"},{"location":"getting_started/quick_start/#biomechanical-variables","title":"Biomechanical Variables","text":"<ul> <li>Joint angles: <code>{joint}_flexion_angle_{side}_rad</code></li> <li>Joint moments: <code>{joint}_moment_{side}_Nm</code></li> <li>Ground forces: <code>{direction}_grf_{side}_N</code></li> </ul>"},{"location":"getting_started/quick_start/#naming-convention","title":"Naming Convention","text":"<ul> <li>Side: <code>ipsi</code> (ipsilateral) or <code>contra</code> (contralateral)</li> <li>Units: Always included in variable name (<code>rad</code>, <code>Nm</code>, <code>N</code>)</li> </ul>"},{"location":"getting_started/quick_start/#filter-data-for-analysis","title":"Filter Data for Analysis","text":"<p>Focus on specific conditions for your analysis:</p> PythonMATLAB <pre><code># Filter for level walking from one subject\nlevel_walking = data[\n    (data['task'] == 'level_walking') &amp; \n    (data['subject'] == 'SUB01')\n]\n\nprint(f\"Level walking data: {level_walking.shape[0]} rows\")\nprint(f\"Number of gait cycles: {level_walking['step'].nunique()}\")\n\n# Look at one complete gait cycle\nsingle_cycle = level_walking[level_walking['step'] == 1]\nprint(f\"Single gait cycle: {single_cycle.shape[0]} points\")\n</code></pre> <pre><code>% Filter for level walking from one subject\nlevel_walking = data(strcmp(data.task, 'level_walking') &amp; ...\n                    strcmp(data.subject, 'SUB01'), :);\n\nfprintf('Level walking data: %d rows\\n', height(level_walking));\nfprintf('Number of gait cycles: %d\\n', length(unique(level_walking.step)));\n\n% Look at one complete gait cycle\nsingle_cycle = level_walking(level_walking.step == 1, :);\nfprintf('Single gait cycle: %d points\\n', height(single_cycle));\n</code></pre>"},{"location":"getting_started/quick_start/#create-your-first-visualization","title":"Create Your First Visualization","text":"<p>Plot knee angle across the gait cycle:</p> PythonMATLAB <pre><code># Calculate average knee angle across all steps\navg_knee = level_walking.groupby('phase_percent')['knee_flexion_angle_ipsi_rad'].mean()\n\n# Create the plot\nplt.figure(figsize=(10, 6))\nplt.plot(avg_knee.index, np.degrees(avg_knee.values), 'b-', linewidth=2)\nplt.xlabel('Gait Cycle (%)')\nplt.ylabel('Knee Flexion Angle (degrees)')\nplt.title('Average Knee Angle - Level Walking')\nplt.grid(True, alpha=0.3)\nplt.xlim(0, 100)\n\n# Add reference lines\nplt.axhline(y=0, color='k', linestyle='--', alpha=0.5, label='Full Extension')\nplt.legend()\n\nplt.tight_layout()\nplt.savefig('knee_angle_level_walking.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"Plot saved as 'knee_angle_level_walking.png'\")\n</code></pre> <pre><code>% Calculate average knee angle across all steps\navg_knee = groupsummary(level_walking, 'phase_percent', 'mean', 'knee_flexion_angle_ipsi_rad');\n\n% Create the plot\nfigure('Position', [100, 100, 800, 500]);\nplot(avg_knee.phase_percent, rad2deg(avg_knee.mean_knee_flexion_angle_ipsi_rad), 'b-', 'LineWidth', 2);\nxlabel('Gait Cycle (%)');\nylabel('Knee Flexion Angle (degrees)');\ntitle('Average Knee Angle - Level Walking');\ngrid on;\nxlim([0, 100]);\n\n% Add reference line\nhold on;\nyline(0, 'k--', 'Alpha', 0.5, 'DisplayName', 'Full Extension');\nlegend('Knee Angle', 'Full Extension');\nhold off;\n\nsaveas(gcf, 'knee_angle_level_walking.png');\n\nfprintf('Plot saved as ''knee_angle_level_walking.png''\\n');\n</code></pre>"},{"location":"getting_started/quick_start/#compare-across-tasks","title":"Compare Across Tasks","text":"<p>See how gait patterns differ between tasks:</p> PythonMATLAB <pre><code># Compare knee angles across different tasks\ntasks = ['level_walking', 'incline_walking', 'up_stairs']\n\nplt.figure(figsize=(12, 8))\n\nfor i, task in enumerate(tasks):\n    if task in data['task'].values:\n        task_data = data[data['task'] == task]\n        avg_knee = task_data.groupby('phase_percent')['knee_flexion_angle_ipsi_rad'].mean()\n\n        plt.subplot(2, 2, i+1)\n        plt.plot(avg_knee.index, np.degrees(avg_knee.values), 'b-', linewidth=2)\n        plt.xlabel('Gait Cycle (%)')\n        plt.ylabel('Knee Flexion (degrees)')\n        plt.title(f'Knee Angle - {task.replace(\"_\", \" \").title()}')\n        plt.grid(True, alpha=0.3)\n        plt.xlim(0, 100)\n\nplt.tight_layout()\nplt.savefig('knee_angle_comparison.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"Comparison plot saved as 'knee_angle_comparison.png'\")\n</code></pre> <pre><code>% Compare knee angles across different tasks\ntasks = {'level_walking', 'incline_walking', 'up_stairs'};\n\nfigure('Position', [100, 100, 1200, 800]);\n\nfor i = 1:length(tasks)\n    task = tasks{i};\n    task_data = data(strcmp(data.task, task), :);\n\n    if ~isempty(task_data)\n        avg_knee = groupsummary(task_data, 'phase_percent', 'mean', 'knee_flexion_angle_ipsi_rad');\n\n        subplot(2, 2, i);\n        plot(avg_knee.phase_percent, rad2deg(avg_knee.mean_knee_flexion_angle_ipsi_rad), 'b-', 'LineWidth', 2);\n        xlabel('Gait Cycle (%)');\n        ylabel('Knee Flexion (degrees)');\n        title(['Knee Angle - ', strrep(task, '_', ' ')]);\n        grid on;\n        xlim([0, 100]);\n    end\nend\n\nsaveas(gcf, 'knee_angle_comparison.png');\n\nfprintf('Comparison plot saved as ''knee_angle_comparison.png''\\n');\n</code></pre>"},{"location":"getting_started/quick_start/#calculate-basic-metrics","title":"Calculate Basic Metrics","text":"<p>Extract meaningful biomechanical parameters:</p> PythonMATLAB <pre><code># Calculate range of motion (ROM) for each gait cycle\ndef calculate_rom(group):\n    return group.max() - group.min()\n\n# ROM for each step\nknee_rom = level_walking.groupby('step')['knee_flexion_angle_ipsi_rad'].apply(calculate_rom)\n\nprint(\"Knee ROM by step (degrees):\")\nprint(np.degrees(knee_rom))\nprint(f\"\\nAverage knee ROM: {np.degrees(knee_rom.mean()):.1f} \u00b1 {np.degrees(knee_rom.std()):.1f} degrees\")\n\n# Peak knee flexion in stance phase (0-60% of gait cycle)\nstance_phase = level_walking[level_walking['phase_percent'] &lt;= 60]\npeak_knee_stance = stance_phase.groupby('step')['knee_flexion_angle_ipsi_rad'].max()\n\nprint(f\"Peak knee flexion in stance: {np.degrees(peak_knee_stance.mean()):.1f} \u00b1 {np.degrees(peak_knee_stance.std()):.1f} degrees\")\n</code></pre> <pre><code>% Calculate range of motion (ROM) for each gait cycle\nknee_rom = groupsummary(level_walking, 'step', {'min', 'max'}, 'knee_flexion_angle_ipsi_rad');\nknee_rom.rom = knee_rom.max_knee_flexion_angle_ipsi_rad - knee_rom.min_knee_flexion_angle_ipsi_rad;\n\nfprintf('Knee ROM by step (degrees):\\n');\ndisp(rad2deg(knee_rom.rom));\nfprintf('Average knee ROM: %.1f \u00b1 %.1f degrees\\n', ...\n    rad2deg(mean(knee_rom.rom)), rad2deg(std(knee_rom.rom)));\n\n% Peak knee flexion in stance phase (0-60% of gait cycle)\nstance_phase = level_walking(level_walking.phase_percent &lt;= 60, :);\npeak_knee_stance = groupsummary(stance_phase, 'step', 'max', 'knee_flexion_angle_ipsi_rad');\n\nfprintf('Peak knee flexion in stance: %.1f \u00b1 %.1f degrees\\n', ...\n    rad2deg(mean(peak_knee_stance.max_knee_flexion_angle_ipsi_rad)), ...\n    rad2deg(std(peak_knee_stance.max_knee_flexion_angle_ipsi_rad)));\n</code></pre>"},{"location":"getting_started/quick_start/#summary","title":"Summary","text":"<p>Congratulations! You've successfully:</p> <ul> <li>\u2705 Loaded a standardized dataset</li> <li>\u2705 Explored the data structure</li> <li>\u2705 Filtered data for specific conditions</li> <li>\u2705 Created visualizations</li> <li>\u2705 Calculated biomechanical metrics</li> </ul>"},{"location":"getting_started/quick_start/#whats-next","title":"What's Next?","text":""},{"location":"getting_started/quick_start/#learn-more","title":"Learn More","text":"<ul> <li>Your First Dataset - Complete analysis walkthrough</li> <li>Python Tutorial - Comprehensive Python guide</li> <li>MATLAB Tutorial - Comprehensive MATLAB guide</li> </ul>"},{"location":"getting_started/quick_start/#explore-advanced-features","title":"Explore Advanced Features","text":"<ul> <li>Working with Data - Advanced analysis techniques</li> <li>Validation Reports - Quality assessment tools</li> <li>API Reference - Complete function documentation</li> </ul>"},{"location":"getting_started/quick_start/#contribute-data","title":"Contribute Data","text":"<ul> <li>Contributor Guide - Add your own datasets</li> <li>Dataset Conversion - Technical conversion guide</li> </ul>"},{"location":"getting_started/quick_start/#common-next-steps","title":"Common Next Steps","text":"<p>Want to analyze your own data?</p> <p>See the Contributor Guide to convert your datasets to the standard format.</p> <p>Need more analysis examples?</p> <p>Check out the comprehensive Tutorials with real-world use cases.</p> <p>Working with large datasets?</p> <p>Learn about memory-efficient techniques in Working with Data.</p> <p>Questions? Check our Troubleshooting Guide or open an issue on GitHub.</p>"},{"location":"reference/api_reference/","title":"API Reference","text":"<p>Complete reference for functions and classes in the Locomotion Data Standardization library.</p>"},{"location":"reference/api_reference/#python-library","title":"Python Library","text":""},{"location":"reference/api_reference/#locomotiondata-class","title":"LocomotionData Class","text":"<p>The main class for working with standardized datasets.</p> <pre><code>from locomotion_analysis import LocomotionData\n\n# Load dataset\ndata = LocomotionData('dataset_phase.parquet')\n</code></pre>"},{"location":"reference/api_reference/#constructor","title":"Constructor","text":"<pre><code>LocomotionData(filepath, format='auto')\n</code></pre> <p>Parameters: - <code>filepath</code> (str): Path to the dataset file - <code>format</code> (str): File format ('parquet', 'csv', 'auto')</p> <p>Returns: - LocomotionData object with loaded dataset</p>"},{"location":"reference/api_reference/#core-methods","title":"Core Methods","text":""},{"location":"reference/api_reference/#filter","title":"<code>filter()</code>","text":"<p>Filter data by conditions.</p> <pre><code>filtered = data.filter(\n    tasks=['level_walking', 'incline_walking'],\n    subjects=['SUB01', 'SUB02'],\n    phase_range=(0, 60)  # Stance phase only\n)\n</code></pre> <p>Parameters: - <code>tasks</code> (list): Task names to include - <code>subjects</code> (list): Subject IDs to include - <code>phase_range</code> (tuple): Min and max phase percentage - <code>quality_threshold</code> (float): Minimum quality score (0-1)</p> <p>Returns: - New LocomotionData object with filtered data</p>"},{"location":"reference/api_reference/#get_cycles","title":"<code>get_cycles()</code>","text":"<p>Extract individual gait cycles.</p> <pre><code>cycles = data.get_cycles(\n    subject='SUB01',\n    task='level_walking',\n    variables=['knee_flexion_angle_ipsi_rad']\n)\n</code></pre> <p>Parameters: - <code>subject</code> (str): Subject identifier - <code>task</code> (str): Task name - <code>variables</code> (list): Variables to extract</p> <p>Returns: - 3D numpy array (cycles \u00d7 phase_points \u00d7 variables)</p>"},{"location":"reference/api_reference/#calculate_metrics","title":"<code>calculate_metrics()</code>","text":"<p>Compute biomechanical metrics.</p> <pre><code>metrics = data.calculate_metrics([\n    'range_of_motion',\n    'peak_flexion',\n    'peak_timing'\n])\n</code></pre> <p>Parameters: - <code>metrics</code> (list): Metric names to calculate</p> <p>Returns: - pandas DataFrame with metrics by cycle</p>"},{"location":"reference/api_reference/#analysis-methods","title":"Analysis Methods","text":""},{"location":"reference/api_reference/#plot_average_pattern","title":"<code>plot_average_pattern()</code>","text":"<p>Create average gait pattern plots.</p> <pre><code>fig = data.plot_average_pattern(\n    variable='knee_flexion_angle_ipsi_rad',\n    group_by='task',\n    show_variability=True\n)\n</code></pre> <p>Parameters: - <code>variable</code> (str): Variable to plot - <code>group_by</code> (str): Grouping variable ('task', 'subject') - <code>show_variability</code> (bool): Include error bands - <code>save_path</code> (str): File path to save plot</p> <p>Returns: - matplotlib Figure object</p>"},{"location":"reference/api_reference/#compare_tasks","title":"<code>compare_tasks()</code>","text":"<p>Statistical comparison between tasks.</p> <pre><code>results = data.compare_tasks(\n    variable='knee_flexion_angle_ipsi_rad',\n    metric='peak_value',\n    test='anova'\n)\n</code></pre> <p>Parameters: - <code>variable</code> (str): Variable to analyze - <code>metric</code> (str): Metric to compare - <code>test</code> (str): Statistical test ('anova', 'ttest', 'kruskal')</p> <p>Returns: - Dictionary with statistical results</p>"},{"location":"reference/api_reference/#validation-functions","title":"Validation Functions","text":""},{"location":"reference/api_reference/#validate_dataset","title":"<code>validate_dataset()</code>","text":"<p>Comprehensive dataset validation.</p> <pre><code>from locomotion_analysis import validate_dataset\n\nreport = validate_dataset(\n    filepath='dataset.parquet',\n    generate_plots=True,\n    output_dir='validation_output/'\n)\n</code></pre> <p>Parameters: - <code>filepath</code> (str): Path to dataset file - <code>generate_plots</code> (bool): Create validation plots - <code>output_dir</code> (str): Directory for output files</p> <p>Returns: - Validation report dictionary</p>"},{"location":"reference/api_reference/#check_biomechanical_plausibility","title":"<code>check_biomechanical_plausibility()</code>","text":"<p>Check if data values are biomechanically reasonable.</p> <pre><code>from locomotion_analysis import check_biomechanical_plausibility\n\nplausibility = check_biomechanical_plausibility(\n    data=data_array,\n    variable='knee_flexion_angle_ipsi_rad'\n)\n</code></pre> <p>Parameters: - <code>data</code> (array): Data values to check - <code>variable</code> (str): Variable name for context</p> <p>Returns: - Dictionary with plausibility scores and flags</p>"},{"location":"reference/api_reference/#conversion-functions","title":"Conversion Functions","text":""},{"location":"reference/api_reference/#convert_to_phase_indexed","title":"<code>convert_to_phase_indexed()</code>","text":"<p>Convert time-indexed data to phase-indexed format.</p> <pre><code>from locomotion_analysis import convert_to_phase_indexed\n\nphase_data = convert_to_phase_indexed(\n    time_data,\n    heel_strikes,\n    n_points=150\n)\n</code></pre> <p>Parameters: - <code>time_data</code> (DataFrame): Time-indexed dataset - <code>heel_strikes</code> (array): Heel strike time indices - <code>n_points</code> (int): Points per gait cycle (default: 150)</p> <p>Returns: - Phase-indexed DataFrame</p>"},{"location":"reference/api_reference/#standardize_variable_names","title":"<code>standardize_variable_names()</code>","text":"<p>Apply standard naming convention to variables.</p> <pre><code>from locomotion_analysis import standardize_variable_names\n\nstandardized = standardize_variable_names(\n    data,\n    mapping_file='variable_mapping.json'\n)\n</code></pre> <p>Parameters: - <code>data</code> (DataFrame): Dataset with original variable names - <code>mapping_file</code> (str): Path to variable mapping file</p> <p>Returns: - DataFrame with standardized variable names</p>"},{"location":"reference/api_reference/#matlab-functions","title":"MATLAB Functions","text":""},{"location":"reference/api_reference/#data-loading","title":"Data Loading","text":""},{"location":"reference/api_reference/#load_locomotion_data","title":"<code>load_locomotion_data()</code>","text":"<p>Load standardized locomotion dataset.</p> <pre><code>data = load_locomotion_data('dataset_phase.parquet');\n</code></pre> <p>Parameters: - <code>filepath</code> (char): Path to dataset file</p> <p>Returns: - Table with locomotion data</p>"},{"location":"reference/api_reference/#filter_locomotion_data","title":"<code>filter_locomotion_data()</code>","text":"<p>Filter dataset by conditions.</p> <pre><code>filtered_data = filter_locomotion_data(data, ...\n    'tasks', {'level_walking', 'incline_walking'}, ...\n    'subjects', {'SUB01', 'SUB02'}, ...\n    'phase_range', [0, 60]);\n</code></pre> <p>Parameters: - <code>data</code> (table): Input dataset - <code>'tasks'</code> (cell): Task names to include - <code>'subjects'</code> (cell): Subject IDs to include - <code>'phase_range'</code> (array): Min and max phase percentage</p> <p>Returns: - Filtered table</p>"},{"location":"reference/api_reference/#analysis-functions","title":"Analysis Functions","text":""},{"location":"reference/api_reference/#calculate_gait_metrics","title":"<code>calculate_gait_metrics()</code>","text":"<p>Compute standard gait metrics.</p> <pre><code>metrics = calculate_gait_metrics(data, ...\n    'variables', {'knee_flexion_angle_ipsi_rad'}, ...\n    'metrics', {'rom', 'peak_flexion', 'peak_timing'});\n</code></pre> <p>Parameters: - <code>data</code> (table): Locomotion dataset - <code>'variables'</code> (cell): Variables to analyze - <code>'metrics'</code> (cell): Metrics to calculate</p> <p>Returns: - Table with metrics by cycle</p>"},{"location":"reference/api_reference/#plot_gait_patterns","title":"<code>plot_gait_patterns()</code>","text":"<p>Create gait pattern visualizations.</p> <pre><code>fig = plot_gait_patterns(data, ...\n    'variable', 'knee_flexion_angle_ipsi_rad', ...\n    'group_by', 'task', ...\n    'show_individual', false);\n</code></pre> <p>Parameters: - <code>data</code> (table): Input dataset - <code>'variable'</code> (char): Variable to plot - <code>'group_by'</code> (char): Grouping variable - <code>'show_individual'</code> (logical): Show individual cycles</p> <p>Returns: - Figure handle</p>"},{"location":"reference/api_reference/#validation-functions_1","title":"Validation Functions","text":""},{"location":"reference/api_reference/#validate_locomotion_dataset","title":"<code>validate_locomotion_dataset()</code>","text":"<p>Validate dataset quality and structure.</p> <pre><code>report = validate_locomotion_dataset('dataset.parquet', ...\n    'generate_plots', true, ...\n    'output_dir', 'validation_output/');\n</code></pre> <p>Parameters: - <code>filepath</code> (char): Path to dataset file - <code>'generate_plots'</code> (logical): Create validation plots - <code>'output_dir'</code> (char): Directory for output files</p> <p>Returns: - Validation report structure</p>"},{"location":"reference/api_reference/#check_phase_indexing","title":"<code>check_phase_indexing()</code>","text":"<p>Verify phase indexing is correct.</p> <pre><code>is_valid = check_phase_indexing(data);\n</code></pre> <p>Parameters: - <code>data</code> (table): Phase-indexed dataset</p> <p>Returns: - Logical indicating if phase indexing is valid</p>"},{"location":"reference/api_reference/#constants-and-variables","title":"Constants and Variables","text":""},{"location":"reference/api_reference/#standard-variable-names","title":"Standard Variable Names","text":"<pre><code># Joint angles (required)\nREQUIRED_ANGLES = [\n    'hip_flexion_angle_ipsi_rad',\n    'knee_flexion_angle_ipsi_rad', \n    'ankle_flexion_angle_ipsi_rad',\n    'hip_flexion_angle_contra_rad',\n    'knee_flexion_angle_contra_rad',\n    'ankle_flexion_angle_contra_rad'\n]\n\n# Joint moments (optional)\nOPTIONAL_MOMENTS = [\n    'hip_moment_ipsi_Nm',\n    'knee_moment_ipsi_Nm',\n    'ankle_moment_ipsi_Nm',\n    'hip_moment_contra_Nm',\n    'knee_moment_contra_Nm',\n    'ankle_moment_contra_Nm'\n]\n\n# Ground reaction forces (optional)\nOPTIONAL_FORCES = [\n    'vertical_grf_ipsi_N',\n    'anterior_grf_ipsi_N',\n    'lateral_grf_ipsi_N',\n    'vertical_grf_contra_N',\n    'anterior_grf_contra_N',\n    'lateral_grf_contra_N'\n]\n</code></pre>"},{"location":"reference/api_reference/#standard-tasks","title":"Standard Tasks","text":"<pre><code>STANDARD_TASKS = [\n    'level_walking',\n    'incline_walking',\n    'decline_walking',\n    'up_stairs',\n    'down_stairs',\n    'run',\n    'sit_to_stand',\n    'jump',\n    'squats'\n]\n</code></pre>"},{"location":"reference/api_reference/#validation-ranges","title":"Validation Ranges","text":"<pre><code># Joint angle ranges (radians)\nANGLE_RANGES = {\n    'hip_flexion_angle': (-0.52, 1.57),    # -30\u00b0 to 90\u00b0\n    'knee_flexion_angle': (-0.17, 2.09),   # -10\u00b0 to 120\u00b0\n    'ankle_flexion_angle': (-0.87, 0.52)   # -50\u00b0 to 30\u00b0\n}\n\n# Phase indexing requirements\nPHASE_REQUIREMENTS = {\n    'points_per_cycle': 150,\n    'phase_min': 0.0,\n    'phase_max': 100.0,\n    'phase_tolerance': 0.1\n}\n</code></pre>"},{"location":"reference/api_reference/#error-handling","title":"Error Handling","text":""},{"location":"reference/api_reference/#common-exceptions","title":"Common Exceptions","text":""},{"location":"reference/api_reference/#datavalidationerror","title":"<code>DataValidationError</code>","text":"<p>Raised when dataset fails validation checks.</p> <pre><code>try:\n    data = LocomotionData('invalid_dataset.parquet')\nexcept DataValidationError as e:\n    print(f\"Validation failed: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#incompletedataerror","title":"<code>IncompleteDataError</code>","text":"<p>Raised when required variables are missing.</p> <pre><code>try:\n    metrics = data.calculate_metrics(['invalid_metric'])\nexcept IncompleteDataError as e:\n    print(f\"Missing data: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#phaseindexingerror","title":"<code>PhaseIndexingError</code>","text":"<p>Raised when phase indexing is incorrect.</p> <pre><code>try:\n    phase_data = convert_to_phase_indexed(time_data, heel_strikes)\nexcept PhaseIndexingError as e:\n    print(f\"Phase indexing failed: {e}\")\n</code></pre>"},{"location":"reference/api_reference/#examples","title":"Examples","text":""},{"location":"reference/api_reference/#basic-analysis-workflow","title":"Basic Analysis Workflow","text":"<pre><code># Load and filter data\ndata = LocomotionData('gtech_2023_phase.parquet')\nwalking_data = data.filter(tasks=['level_walking'])\n\n# Calculate metrics\nmetrics = walking_data.calculate_metrics([\n    'range_of_motion', 'peak_flexion', 'peak_timing'\n])\n\n# Create visualization\nfig = walking_data.plot_average_pattern(\n    variable='knee_flexion_angle_ipsi_rad',\n    group_by='subject',\n    show_variability=True\n)\n\n# Statistical comparison\nresults = walking_data.compare_tasks(\n    variable='knee_flexion_angle_ipsi_rad',\n    metric='range_of_motion'\n)\n</code></pre>"},{"location":"reference/api_reference/#dataset-conversion","title":"Dataset Conversion","text":"<pre><code># Convert custom format to standard\nfrom locomotion_analysis import DatasetConverter\n\nconverter = DatasetConverter()\nconverter.load_custom_format('lab_data.mat')\nconverter.detect_gait_events()\nconverter.apply_phase_indexing(n_points=150)\nconverter.standardize_variables()\nconverter.validate_quality()\nconverter.save_parquet('standardized_dataset.parquet')\n</code></pre>"},{"location":"reference/api_reference/#quality-assessment","title":"Quality Assessment","text":"<pre><code># Comprehensive validation\nreport = validate_dataset(\n    'new_dataset.parquet',\n    generate_plots=True,\n    output_dir='quality_check/'\n)\n\n# Check specific quality criteria\nplausibility = check_biomechanical_plausibility(\n    data.get_variable('knee_flexion_angle_ipsi_rad'),\n    variable='knee_flexion_angle_ipsi_rad'\n)\n\nprint(f\"Quality score: {report['overall_score']:.2f}\")\nprint(f\"Plausibility: {plausibility['score']:.2f}\")\n</code></pre>"},{"location":"reference/api_reference/#version-information","title":"Version Information","text":"<p>Current Version: 1.0.0 API Stability: Stable Backward Compatibility: Maintained within major version Update Frequency: Monthly minor releases, quarterly major releases  </p>"},{"location":"reference/api_reference/#support","title":"Support","text":"<ul> <li>Documentation: User Guide</li> <li>Tutorials: Getting Started</li> <li>Issues: GitHub Issues</li> <li>Discussions: GitHub Discussions</li> </ul> <p>This API reference is automatically updated with each release. For the latest functions and features, see the development documentation.</p>"},{"location":"reference/datasets_documentation/","title":"Locomotion Datasets Documentation","text":"<p>Comprehensive reference for all standardized locomotion datasets in this repository.</p> <p>Quick Reference: AddBiomechanics \u2022 GTech 2023 \u2022 UMich 2021</p>"},{"location":"reference/datasets_documentation/#available-datasets","title":"Available Datasets","text":""},{"location":"reference/datasets_documentation/#1-university-of-michigan-2021-umich-2021","title":"1. University of Michigan 2021 (UMich 2021)","text":"<ul> <li>Focus: Treadmill-based locomotion with speed and incline variations</li> <li>Subjects: 10 healthy adults (5M/5F, age 20-60)</li> <li>Key Activities: Walking (multiple speeds/inclines), running, sit-to-stand, stairs</li> <li>Unique Features: Systematic incline variations (-10\u00b0 to +10\u00b0), walk-to-run transitions</li> <li>Format: Time series (100 Hz) and phase-normalized (150 points/cycle)</li> <li>PI: Robert D. Gregg IV, Ph.D. (Locomotor Control Systems Laboratory)</li> <li>Publication: IEEE DataPort 2018</li> <li>Documentation: <code>dataset_umich_2021.md</code></li> </ul>"},{"location":"reference/datasets_documentation/#2-georgia-tech-2023-gtech-2023","title":"2. Georgia Tech 2023 (GTech 2023)","text":"<ul> <li>Focus: Diverse daily activities and sports movements</li> <li>Subjects: 12 healthy adults (AB01-AB13, excluding AB04)</li> <li>Key Activities: 20+ tasks including walking, running, jumping, sports movements, functional tasks</li> <li>Unique Features: EMG data, IMU sensors, extensive activity variety, non-cyclic tasks</li> <li>Format: Time series (200 Hz) and phase-normalized (150 points/cycle)</li> <li>PI: Aaron Young, Ph.D. (EPIC Lab - Exoskeleton and Prosthetic Intelligent Controls)</li> <li>Publication: Scientific Data 2023</li> <li>Documentation: <code>dataset_gtech_2023.md</code></li> </ul>"},{"location":"reference/datasets_documentation/#3-addbiomechanics","title":"3. AddBiomechanics","text":"<ul> <li>Focus: OpenSim-processed biomechanics data with full-body kinematics and kinetics</li> <li>Subjects: Multiple subjects from various sources</li> <li>Key Activities: Walking, running, and various locomotion tasks</li> <li>Unique Features: B3D file format, nimblephysics processing, pre-scaled OpenSim models</li> <li>Format: Time series and phase-normalized (150 points/cycle)</li> <li>PI: Stanford Neuromuscular Biomechanics Lab</li> <li>Publication: bioRxiv 2023</li> <li>Documentation: <code>dataset_addbiomechanics.md</code></li> </ul>"},{"location":"reference/datasets_documentation/#quick-comparison","title":"Quick Comparison","text":"Feature UMich 2021 GTech 2023 AddBiomechanics Year 2021 2023 Ongoing Subjects 10 12 Multiple Primary Focus Treadmill locomotion Multi-activity Full-body biomechanics Sampling Rate 100 Hz 200 Hz Variable Incline Walking \u2713 (-10\u00b0 to +10\u00b0) \u2713 (5\u00b0, 10\u00b0) \u2713 Running \u2713 (1.8-2.4 m/s) \u2713 \u2713 Stairs \u2713 (limited) \u2713 (extensive) \u2713 Sports Movements \u2717 \u2713 \u2713 EMG Data \u2717 \u2713 (raw) \u2717 IMU Data \u2717 \u2713 \u2717 Force Plates \u2713 (treadmill) \u2713 (ground+treadmill) \u2713"},{"location":"reference/datasets_documentation/#common-variables-across-datasets","title":"Common Variables Across Datasets","text":"<p>All datasets are standardized to include these core biomechanical variables:</p>"},{"location":"reference/datasets_documentation/#kinematics-per-leg-_contraipsi","title":"Kinematics (per leg: _contra/ipsi)","text":"<ul> <li>Joint angles: hip, knee, ankle (3 planes each)</li> <li>Joint velocities: hip, knee, ankle (sagittal plane minimum)</li> </ul>"},{"location":"reference/datasets_documentation/#kinetics-per-leg-_contraipsi","title":"Kinetics (per leg: _contra/ipsi)","text":"<ul> <li>Joint moments: hip, knee, ankle (3 planes each, mass-normalized)</li> <li>Ground reaction forces: AP, vertical, ML</li> <li>Center of pressure: AP, vertical, ML</li> </ul>"},{"location":"reference/datasets_documentation/#metadata","title":"Metadata","text":"<ul> <li><code>subject</code>: Unique subject identifier</li> <li><code>task</code>: Task/activity identifier</li> <li><code>time_s</code>: Time in seconds (time series format)</li> <li><code>phase</code>: Gait cycle percentage 0-100% (phase-normalized format)</li> </ul>"},{"location":"reference/datasets_documentation/#file-naming-convention","title":"File Naming Convention","text":"<p>All standardized datasets follow this structure: <pre><code>converted_datasets/\n\u251c\u2500\u2500 [dataset_name]_[year]_time.parquet      # Time series data\n\u251c\u2500\u2500 [dataset_name]_[year]_phase.parquet     # Phase-normalized data\n\u2514\u2500\u2500 [dataset_name]_[year]_metadata.json     # Additional metadata\n</code></pre></p>"},{"location":"reference/datasets_documentation/#usage-tips","title":"Usage Tips","text":"<ul> <li>For gait analysis: Use phase-normalized data for cross-subject comparisons</li> <li>For time-series ML: Use time series data with original sampling rates</li> <li>For multi-task analysis: GTech 2023 offers the most activity variety</li> <li>For treadmill studies: UMich 2021 provides systematic speed/incline conditions</li> </ul>"},{"location":"reference/datasets_documentation/#adding-new-datasets","title":"Adding New Datasets","text":"<p>When adding a new dataset to this repository:</p> <ol> <li>Create detailed documentation using existing files as templates</li> <li>Update this README with a summary entry</li> <li>Add the dataset to the quick comparison table</li> <li>Ensure conversion scripts output to <code>converted_datasets/</code> folder</li> <li>Update CLAUDE.md with any dataset-specific commands</li> </ol> <p>These datasets provide cleaned, tested biomechanical data ready for reproducible research.</p>"},{"location":"reference/datasets_documentation/dataset_addbiomechanics/","title":"AddBiomechanics Dataset","text":""},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#overview","title":"Overview","text":"<p>The AddBiomechanics dataset provides comprehensive 3D biomechanical data processed through the AddBiomechanics pipeline, which uses OpenSim-based musculoskeletal modeling and inverse dynamics.</p>"},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#dataset-information","title":"Dataset Information","text":"<ul> <li>Source Institution: Stanford Neuromuscular Biomechanics Lab</li> <li>Year: Ongoing collection</li> <li>Format: B3D (Biomechanics 3D) files</li> <li>Website: https://addbiomechanics.org/</li> <li>Paper: AddBiomechanics: Automating model scaling, inverse kinematics, and inverse dynamics from human motion data through sequential optimization</li> </ul>"},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#citation","title":"Citation","text":"<pre><code>@article{addbiomechanics2023,\n  title={AddBiomechanics: Automating model scaling, inverse kinematics, and inverse dynamics from human motion data through sequential optimization},\n  author={Werling, Keenon and Bianco, Nicholas A. and Raitor, Michael and Stingel, Jon and Hicks, Jennifer L. and Collins, Steven H. and Delp, Scott L. and Liu, C. Karen},\n  journal={bioRxiv},\n  year={2023},\n  doi={10.1101/2023.06.15.545116}\n}\n</code></pre>"},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#data-structure","title":"Data Structure","text":""},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#available-variables","title":"Available Variables","text":"<ul> <li>Kinematics: Full-body joint angles, velocities, and accelerations</li> <li>Kinetics: Joint moments and powers</li> <li>Ground Reaction Forces: 3D forces and center of pressure</li> <li>Segment Kinematics: Global positions and orientations</li> </ul>"},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#file-format","title":"File Format","text":"<ul> <li>Input: B3D binary files containing trial data</li> <li>Output: Standardized parquet files (time-indexed and phase-indexed)</li> </ul>"},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#coordinate-system","title":"Coordinate System","text":"<ul> <li>OpenSim standard: X-forward, Y-up, Z-right</li> <li>Joint angles follow OpenSim conventions</li> </ul>"},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#processing-pipeline","title":"Processing Pipeline","text":"<ol> <li>B3D Parsing: Extract biomechanical data using nimblephysics</li> <li>Variable Mapping: Convert to standardized naming convention</li> <li>Unit Conversion: Ensure SI units (rad, N, m)</li> <li>Phase Detection: Identify gait cycles from kinematics</li> <li>Validation: Apply biomechanical constraints</li> </ol>"},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#usage-example","title":"Usage Example","text":"<pre><code># Convert B3D files to standardized format\npython source/conversion_scripts/AddBiomechanics/convert_addbiomechanics_to_parquet.py\n\n# Add phase information\npython source/conversion_scripts/AddBiomechanics/add_phase_info.py\n\n# Load converted data\nimport pandas as pd\ndf = pd.read_parquet('converted_datasets/addbiomechanics_time.parquet')\n</code></pre>"},{"location":"reference/datasets_documentation/dataset_addbiomechanics/#notes","title":"Notes","text":"<ul> <li>Data includes full 3D kinematics and kinetics</li> <li>Suitable for machine learning applications</li> <li>Pre-processed through OpenSim pipeline</li> <li>Includes marker data and model scaling information</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/","title":"Georgia Tech 2023 Multi-Activity Dataset","text":""},{"location":"reference/datasets_documentation/dataset_gtech_2023/#overview","title":"Overview","text":"<p>Brief Description: Comprehensive motion capture dataset featuring diverse locomotion and daily activities including walking, running, stairs, sports movements, and functional tasks. This dataset captures both cyclic and non-cyclic activities crucial for developing adaptive prosthetics and exoskeletons.</p> <p>Collection Year: 2023</p> <p>Institution: Georgia Institute of Technology, Woodruff School of Mechanical Engineering and Institute of Robotics and Intelligent Machines</p> <p>Principal Investigators: Aaron Young, Ph.D. (EPIC Lab - Exoskeleton and Prosthetic Intelligent Controls Laboratory)</p>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#citation-information","title":"Citation Information","text":""},{"location":"reference/datasets_documentation/dataset_gtech_2023/#primary-citation","title":"Primary Citation","text":"<pre><code>Scherpereel, K., Molinaro, D., Inan, O., Shepherd, M., &amp; Young, A. (2023). \nA human lower-limb biomechanics and wearable sensors dataset during cyclic and non-cyclic activities. \nScientific Data, 10, 917. https://doi.org/10.1038/s41597-023-02341-6\n</code></pre>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#associated-publications","title":"Associated Publications","text":"<ol> <li>Young, A. et al. (2024). \"Task-Agnostic Exoskeleton Control via Biological Joint Moment Estimation.\"     Nature, 635, 337-344.</li> <li>EPIC Lab Open-Source Data &amp; Models: https://www.epic.gatech.edu/open-source-data-models/</li> </ol>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#acknowledgments","title":"Acknowledgments","text":"<p>This research was supported by: - NSF National Robotics Initiative (NRI) grants for machine learning in exoskeleton control - DoD CDMRP funding for intent recognition systems in powered prostheses - NIH New Investigator Award to Dr. Aaron Young</p>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#dataset-contents","title":"Dataset Contents","text":""},{"location":"reference/datasets_documentation/dataset_gtech_2023/#subjects","title":"Subjects","text":"<ul> <li>Total Subjects: 12 (AB01, AB02, AB03, AB05, AB06, AB07, AB08, AB09, AB10, AB11, AB12, AB13)</li> <li>Demographics:</li> <li>Age Range: 18-35 years (healthy young adults)</li> <li>Sex Distribution: Balanced male/female representation</li> <li>Height Range: Approximately 1.60-1.90 m</li> <li>Weight Range: 62.3-113.5 kg</li> <li>Mean Weight: 76.95 kg</li> <li>Inclusion Criteria: Healthy adults with no musculoskeletal or neurological impairments</li> <li>Note: Subject AB04 excluded from dataset</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#tasks-included","title":"Tasks Included","text":"Task ID Task Description Duration/Cycles Conditions Notes normal_walk Level ground walking Multiple trials Various speeds (0.6-2.5 m/s) Treadmill incline_walk Incline walking Multiple trials 5\u00b0 and 10\u00b0 inclines Up/down stairs Stair climbing Multiple cycles Standard stairs Up/down dynamic_walk Variable speed walking Continuous Speed changes Treadmill walk_backward Backward walking Continuous 1.0 m/s Treadmill weighted_walk Walking with load Continuous 25 lbs weight 1.0 m/s side_shuffle Lateral movement Multiple cycles Ipsilateral/contralateral Overground jump Jumping Multiple trials Vertical jumps Force plates squats Squatting Multiple reps With/without weight Static lunges Forward/backward lunges Multiple reps Ipsilateral/contralateral legs Overground sit_to_stand Sit-to-stand transitions Multiple cycles Chair height Functional ball_toss Ball tossing Multiple trials Left/mid/right targets Standing curb_up Stepping up curb Multiple cycles Street curb height Overground curb_down Stepping down curb Multiple cycles Street curb height Overground cutting Sharp turning while jogging Multiple trials Ipsilateral/contralateral Overground lift_weight Weight lifting Multiple trials Weighted/unweighted bag Functional step_ups Step-up exercise Multiple cycles Tall platform Exercise tire_run High-knee jogging Continuous Toe running Overground turn_and_step Turn and walk initiation Multiple trials Ipsilateral/contralateral turns From standing meander Free-form slow walking Continuous Self-selected path Overground obstacle_walk Walking with obstacles Continuous Foam blocks 1.0 m/s poses Static postures Hold positions Various poses Calibration push External perturbations Multiple trials Push/pull by experimenter Balance"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#data-columns","title":"Data Columns","text":""},{"location":"reference/datasets_documentation/dataset_gtech_2023/#kinematic-variables","title":"Kinematic Variables","text":"Variable Name Description Units Sampling Rate hip_flexion_angle_r/l_rad Hip flexion/extension angle radians 200 Hz hip_adduction_angle_r/l_rad Hip adduction/abduction angle radians 200 Hz hip_rotation_angle_r/l_rad Hip internal/external rotation radians 200 Hz knee_flexion_angle_r/l_rad Knee flexion/extension angle radians 200 Hz ankle_dorsiflexion_angle_r/l_rad Ankle dorsi/plantarflexion angle radians 200 Hz ankle_eversion_angle_r/l_rad Ankle inversion/eversion angle radians 200 Hz hip_flexion_velocity_r/l_rad_s Hip angular velocity (sagittal) rad/s 200 Hz hip_adduction_velocity_r/l_rad_s Hip angular velocity (frontal) rad/s 200 Hz hip_rotation_velocity_r/l_rad_s Hip angular velocity (transverse) rad/s 200 Hz knee_flexion_velocity_r/l_rad_s Knee angular velocity (sagittal) rad/s 200 Hz ankle_dorsiflexion_velocity_r/l_rad_s Ankle angular velocity (sagittal) rad/s 200 Hz ankle_eversion_velocity_r/l_rad_s Ankle angular velocity (frontal) rad/s 200 Hz pelvis_angle_s/f/t Pelvis angles (sagittal/frontal/transverse) radians 200 Hz torso_angle_s/f/t Torso angles (sagittal/frontal/transverse) radians 200 Hz thigh_angle_s/f/t_r/l Thigh segment angles radians 200 Hz shank_angle_s/f/t_r/l Shank segment angles radians 200 Hz foot_angle_s/f/t_r/l Foot segment angles radians 200 Hz"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#kinetic-variables","title":"Kinetic Variables","text":"Variable Name Description Units Sampling Rate hip_flexion_moment_r/l_Nm Hip flexion/extension moment Nm 200 Hz hip_adduction_moment_r/l_Nm Hip adduction/abduction moment Nm 200 Hz hip_rotation_moment_r/l_Nm Hip internal/external rotation moment Nm 200 Hz knee_flexion_moment_r/l_Nm Knee flexion/extension moment Nm 200 Hz ankle_dorsiflexion_moment_r/l_Nm Ankle dorsi/plantarflexion moment Nm 200 Hz ankle_eversion_moment_r/l_Nm Ankle inversion/eversion moment Nm 200 Hz force_x_r/l Anterior-posterior ground reaction force N 200 Hz force_y_r/l Medial-lateral ground reaction force N 200 Hz force_z_r/l Vertical ground reaction force N 200 Hz COP_x_r/l Anterior-posterior center of pressure m 200 Hz COP_y_r/l Medial-lateral center of pressure m 200 Hz COP_z_r/l Vertical center of pressure m 200 Hz"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#additional-data-if-applicable","title":"Additional Data (if applicable)","text":"Variable Name Type Description Units Sampling Rate Raw_EMGs EMG Raw electromyography signals mV 2000 Hz Real_IMUs IMU Real IMU sensor data Various 200 Hz Virtual_IMUs IMU Virtual IMU calculations Various 200 Hz Virtual_Insoles Pressure Virtual insole pressure N 200 Hz Joint_Powers Power Joint power calculations W/kg 200 Hz Link_Angles Kinematics Segment angles degrees 200 Hz Link_Velocities Kinematics Segment angular velocities deg/s 200 Hz Activity_Flag Metadata Activity phase markers Binary 200 Hz"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#file-structure","title":"File Structure","text":"<pre><code>gtech_2023/\n\u251c\u2500\u2500 time_series/\n\u2502   \u2514\u2500\u2500 gtech_2023_time.parquet\n\u251c\u2500\u2500 phase_normalized/\n\u2502   \u2514\u2500\u2500 gtech_2023_phase.parquet\n\u251c\u2500\u2500 individual_subjects/\n\u2502   \u2514\u2500\u2500 gtech_2023_time_[subject_id].parquet\n\u2514\u2500\u2500 raw_data/\n    \u2514\u2500\u2500 [subject_id]/CSV_Data/[task_name]/\n        \u251c\u2500\u2500 Joint_Angle.csv\n        \u251c\u2500\u2500 Joint_Moments.csv\n        \u251c\u2500\u2500 GroundFrame_GRFs.csv\n        \u2514\u2500\u2500 [additional files]\n</code></pre>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#data-collection-methods","title":"Data Collection Methods","text":""},{"location":"reference/datasets_documentation/dataset_gtech_2023/#motion-capture-system","title":"Motion Capture System","text":"<ul> <li>System: Vicon Motion Capture System</li> <li>Marker Set: Full-body marker set (modified Plug-in Gait)</li> <li>Sampling Rate: 200 Hz (native)</li> <li>Camera Count: 12-16 cameras for full capture volume</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#force-plates","title":"Force Plates","text":"<ul> <li>Model: AMTI Force Plates (ground-embedded) and Bertec Instrumented Treadmill</li> <li>Sampling Rate: 1000 Hz (downsampled to 200 Hz for synchronization)</li> <li>Configuration: Multiple ground-embedded plates + dual-belt instrumented treadmill</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#additional-sensors","title":"Additional Sensors","text":"<ul> <li>EMG System: Delsys Trigno Wireless EMG at 2000 Hz</li> <li>IMU System: Xsens MTw Awinda wireless IMUs at 200 Hz</li> <li>Virtual Sensors: Calculated from motion capture data (virtual IMUs and insoles)</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#caren-system","title":"CAREN System","text":"<ul> <li>Facility: Motek Computer-Aided Rehabilitation Environment (CAREN)</li> <li>Components: 10-camera Vicon system, 16-channel Delsys EMG, instrumented treadmill on 6-DOF Stewart platform</li> <li>Display: 180\u00b0 projection screen for immersive environments</li> <li>Software: Motek D-Flow for real-time data integration</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#processing-pipeline","title":"Processing Pipeline","text":"<ol> <li>Motion capture with full-body markers</li> <li>C3D file creation with Visual3D or similar</li> <li>Export to CSV format per trial</li> <li>Mass normalization for kinetic data</li> <li>Conversion to standardized parquet format</li> </ol>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#known-issues-and-limitations","title":"Known Issues and Limitations","text":""},{"location":"reference/datasets_documentation/dataset_gtech_2023/#data-quality-issues","title":"Data Quality Issues","text":"<ul> <li>Some trials may have marker occlusions during complex movements</li> <li>EMG data not yet standardized in parquet format</li> <li>IMU data not yet integrated into standard format</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#missing-data","title":"Missing Data","text":"<ul> <li>Subject AB04 not included in dataset</li> <li>Some subjects may be missing specific trials</li> <li>Phase normalization may fail for non-cyclic tasks</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#processing-artifacts","title":"Processing Artifacts","text":"<ul> <li>High-frequency noise in calculated velocities</li> <li>Force plate saturation possible during jumping tasks</li> <li>Coordinate system conversions required for standard alignment</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#usage-notes","title":"Usage Notes","text":""},{"location":"reference/datasets_documentation/dataset_gtech_2023/#recommended-use-cases","title":"Recommended Use Cases","text":"<ul> <li>Comprehensive movement analysis across diverse activities</li> <li>Sports biomechanics research</li> <li>Daily activity biomechanics</li> <li>Multi-task movement patterns</li> <li>Machine learning on varied movement data</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#not-recommended-for","title":"Not Recommended For","text":"<ul> <li>Clinical gait analysis (healthy subjects only)</li> <li>Pediatric or elderly populations</li> <li>Pathological movement patterns</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#data-access-requirements","title":"Data Access Requirements","text":"<ul> <li>License: Creative Commons Attribution 4.0 International (CC BY 4.0)</li> <li>Access Process: Contact EPIC Lab at epic-lab@gatech.edu</li> <li>Usage Restrictions: Academic and commercial use allowed with proper citation</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#version-history","title":"Version History","text":"Version Date Changes Notes 1.0 2023 Initial collection CSV format per trial 2.0 2024 Standardized format Parquet conversion with unified structure"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#contact-information","title":"Contact Information","text":"<ul> <li>Dataset Curator: Aaron Young, Ph.D.</li> <li>Lab Website: https://www.epic.gatech.edu/</li> <li>Lab Email: epic-lab@gatech.edu</li> <li>Technical Support: Contact via lab email</li> <li>Bug Reports: GitHub issues on this repository</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#additional-resources","title":"Additional Resources","text":"<ul> <li>Lab Website: https://www.epic.gatech.edu/</li> <li>Lab Publications: https://www.epic.gatech.edu/journal-papers/</li> <li>Open-Source Resources: https://www.epic.gatech.edu/open-source-data-models/</li> <li>Documentation: See conversion scripts in <code>source/conversion_scripts/Gtech_2023/</code></li> <li>Code Examples: See tutorials folder</li> <li>Visualization Tools: <code>mosaic_plot.py</code>, <code>walking_animator.py</code></li> <li>Related Datasets: UMich 2021, AddBiomechanics</li> </ul>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#funding-acknowledgment","title":"Funding Acknowledgment","text":"<p>This dataset was collected with support from: - NSF National Robotics Initiative (NRI) for machine learning in robotic exoskeletons - DoD Congressionally Directed Medical Research Programs (CDMRP) for powered prosthesis intent recognition - NIH New Investigator Award to Dr. Aaron Young - IEEE New Faces of Engineering Award</p>"},{"location":"reference/datasets_documentation/dataset_gtech_2023/#lab-description","title":"Lab Description","text":"<p>The Exoskeleton and Prosthetic Intelligent Controls (EPIC) Lab at Georgia Tech is devoted to the design and  improvement of powered orthotic and prosthetic control systems. The lab combines machine learning, robotics,  human biomechanics, and control systems to design wearable robots that improve community mobility for  individuals with walking disability. The EPIC Lab has state-of-the-art facilities including the CAREN system  for immersive biomechanics research.</p> <p>Last Updated: January 2025 Template Version: 1.0</p>"},{"location":"reference/datasets_documentation/dataset_umich_2021/","title":"University of Michigan 2021 Treadmill Dataset","text":""},{"location":"reference/datasets_documentation/dataset_umich_2021/#overview","title":"Overview","text":"<p>Brief Description: Comprehensive treadmill-based locomotion dataset including walking at various speeds and inclines, running, and transitions between activities.</p> <p>Collection Year: 2018-2021</p> <p>Institution: University of Michigan, Department of Robotics, Mechanical Engineering, and Electrical and Computer Engineering</p> <p>Principal Investigators: Robert D. Gregg IV, Ph.D. (Locomotor Control Systems Laboratory)</p>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#citation-information","title":"Citation Information","text":""},{"location":"reference/datasets_documentation/dataset_umich_2021/#primary-citation","title":"Primary Citation","text":"<pre><code>Locomotor Control Systems Laboratory. (2021). University of Michigan Treadmill Locomotion Dataset. \nUniversity of Michigan, Ann Arbor. [Contact lab for access]\n</code></pre>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#associated-publications","title":"Associated Publications","text":"<ol> <li>Gregg, R.D. et al. \"The Effect of Walking Incline and Speed on Human Leg Kinematics, Kinetics, and EMG\"     IEEE DataPort (2018). https://ieee-dataport.org/open-access/effect-walking-incline-and-speed-human-leg-kinematics-kinetics-and-emg</li> <li>Related publications available at: https://scholar.google.com/citations?user=hEypYOEAAAAJ&amp;hl=en</li> </ol>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#acknowledgments","title":"Acknowledgments","text":"<p>This research was supported by: - NIH Director's New Innovator Award (2013) - $2.3 million over 5 years for phase-based control research - NIH R01 Grant (2018) - $2.2 million for investigation of agile powered prosthetic leg control - NIH R01 Grant (2021) - $1.7 million for design and control of modular powered orthoses</p>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#dataset-contents","title":"Dataset Contents","text":""},{"location":"reference/datasets_documentation/dataset_umich_2021/#subjects","title":"Subjects","text":"<ul> <li>Total Subjects: 10 (AB01-AB10)</li> <li>Demographics:</li> <li>Age Range: 20-60 years</li> <li>Sex Distribution: 5F/5M</li> <li>Height Range: 1617-1900 mm</li> <li>Weight Range: 53.7-87.0 kg</li> <li>Mean Age: 30.4 years</li> <li>Mean Weight: 74.63 kg</li> <li>Mean Height: 1727.8 mm</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#tasks-included","title":"Tasks Included","text":"Task ID Task Description Duration/Cycles Conditions Notes Tread.d10 Decline walking Continuous -10\u00b0 decline Treadmill Tread.d5 Decline walking Continuous -5\u00b0 decline Treadmill Tread.i0 Level walking Continuous 0\u00b0 (level) Treadmill Tread.i5 Incline walking Continuous 5\u00b0 incline Treadmill Tread.i10 Incline walking Continuous 10\u00b0 incline Treadmill Run.s1x8 Running Continuous 1.8 m/s Level treadmill Run.s2x0 Running Continuous 2.0 m/s Level treadmill Run.s2x2 Running Continuous 2.2 m/s Level treadmill Run.s2x4 Running Continuous 2.4 m/s Level treadmill Wtr Walk-to-run transition Transition Variable Treadmill Sts Sit-to-stand Multiple cycles N/A Static task Stair Stair climbing Multiple cycles Standard stairs Overground"},{"location":"reference/datasets_documentation/dataset_umich_2021/#data-columns","title":"Data Columns","text":""},{"location":"reference/datasets_documentation/dataset_umich_2021/#kinematic-variables","title":"Kinematic Variables","text":"Variable Name Description Units Sampling Rate hip_angle_s_r/l Hip flexion/extension angle degrees 100 Hz hip_angle_f_r/l Hip adduction/abduction angle degrees 100 Hz hip_angle_t_r/l Hip internal/external rotation degrees 100 Hz knee_angle_s_r/l Knee flexion/extension angle degrees 100 Hz knee_angle_f_r/l Knee varus/valgus angle degrees 100 Hz knee_angle_t_r/l Knee internal/external rotation degrees 100 Hz ankle_angle_s_r/l Ankle dorsi/plantarflexion angle degrees 100 Hz ankle_angle_f_r/l Ankle inversion/eversion angle degrees 100 Hz ankle_angle_t_r/l Ankle internal/external rotation degrees 100 Hz pelvis_angle_s/f/t_r/l Pelvis angles (3 planes) degrees 100 Hz foot_progress_angle_s/f/t_r/l Foot progression angles degrees 100 Hz"},{"location":"reference/datasets_documentation/dataset_umich_2021/#kinetic-variables","title":"Kinetic Variables","text":"Variable Name Description Units Sampling Rate hip_torque_s_r/l Hip flexion/extension moment Nm/kg 100 Hz hip_torque_f_r/l Hip adduction/abduction moment Nm/kg 100 Hz hip_torque_t_r/l Hip internal/external rotation moment Nm/kg 100 Hz knee_torque_s_r/l Knee flexion/extension moment Nm/kg 100 Hz knee_torque_f_r/l Knee varus/valgus moment Nm/kg 100 Hz knee_torque_t_r/l Knee internal/external rotation moment Nm/kg 100 Hz ankle_torque_s_r/l Ankle dorsi/plantarflexion moment Nm/kg 100 Hz ankle_torque_f_r/l Ankle inversion/eversion moment Nm/kg 100 Hz ankle_torque_t_r/l Ankle internal/external rotation moment Nm/kg 100 Hz ap_grf_r/l Anterior-posterior ground reaction force N 100 Hz vertical_grf_r/l Vertical ground reaction force N 100 Hz ml_grf_r/l Medial-lateral ground reaction force N 100 Hz ap_cop_r/l Anterior-posterior center of pressure m 100 Hz vertical_cop_r/l Vertical center of pressure m 100 Hz ml_cop_r/l Medial-lateral center of pressure m 100 Hz"},{"location":"reference/datasets_documentation/dataset_umich_2021/#file-structure","title":"File Structure","text":"<pre><code>umich_2021/\n\u251c\u2500\u2500 time_series/\n\u2502   \u2514\u2500\u2500 umich_2021_time_series.parquet\n\u251c\u2500\u2500 phase_normalized/\n\u2502   \u2514\u2500\u2500 umich_2021_phase_normalized.parquet\n\u2514\u2500\u2500 metadata/\n    \u251c\u2500\u2500 Streaming.mat (original)\n    \u2514\u2500\u2500 Normalized.mat (original)\n</code></pre>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#data-collection-methods","title":"Data Collection Methods","text":""},{"location":"reference/datasets_documentation/dataset_umich_2021/#motion-capture-system","title":"Motion Capture System","text":"<ul> <li>System: Vicon Motion Capture System</li> <li>Marker Set: Modified Helen Hayes marker set</li> <li>Sampling Rate: 100 Hz</li> <li>Camera Count: 10 cameras (when at UT Dallas)</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#force-plates","title":"Force Plates","text":"<ul> <li>Model: Bertec Instrumented Treadmill</li> <li>Sampling Rate: 100 Hz (resampled)</li> <li>Configuration: Dual-belt treadmill with embedded force plates</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#emg-system","title":"EMG System","text":"<ul> <li>Model: Delsys Trigno EMG System</li> <li>Muscles Recorded: Rectus femoris, biceps femoris, tibialis anterior, gastrocnemius</li> <li>Sampling Rate: 2000 Hz (downsampled to 100 Hz for analysis)</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#processing-pipeline","title":"Processing Pipeline","text":"<ol> <li>Motion capture with marker-based system</li> <li>Gap filling and filtering</li> <li>Inverse kinematics for joint angles</li> <li>Inverse dynamics for joint moments</li> <li>Data exported to MATLAB format</li> <li>Conversion to standardized parquet format with sign convention alignment</li> </ol>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#known-issues-and-limitations","title":"Known Issues and Limitations","text":""},{"location":"reference/datasets_documentation/dataset_umich_2021/#data-quality-issues","title":"Data Quality Issues","text":"<ul> <li>Some subjects may have missing tasks in normalized data (e.g., Tread field missing)</li> <li>Joint angles and moments may be missing for certain stride cycles in normalized data</li> <li>Force plate data may have saturation during high-impact activities (running)</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#missing-data","title":"Missing Data","text":"<ul> <li>Specific secondary conditions may lack jointAngles, jointMoments, or forceplates fields</li> <li>Individual stride cycles may be excluded due to quality issues</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#processing-artifacts","title":"Processing Artifacts","text":"<ul> <li>Sign conventions in raw MAT files differ from OpenSim standards (handled by conversion scripts)</li> <li>Knee flexion angle requires negation for proper convention alignment</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#usage-notes","title":"Usage Notes","text":""},{"location":"reference/datasets_documentation/dataset_umich_2021/#recommended-use-cases","title":"Recommended Use Cases","text":"<ul> <li>Treadmill walking biomechanics analysis</li> <li>Speed and incline effects on gait</li> <li>Walk-to-run transition studies</li> <li>Comparative analysis across normalized gait cycles</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#not-recommended-for","title":"Not Recommended For","text":"<ul> <li>Overground walking analysis (limited stair data)</li> <li>High-speed running (max 2.4 m/s)</li> <li>Turning or cutting maneuvers (treadmill constraint)</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#data-access-requirements","title":"Data Access Requirements","text":"<ul> <li>License: Research use with appropriate citation</li> <li>Access Process: Contact Locomotor Control Systems Laboratory (locolab@umich.edu)</li> <li>Usage Restrictions: Academic research use only, commercial use requires separate agreement</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#version-history","title":"Version History","text":"Version Date Changes Notes 1.0 2021 Initial release Original MATLAB format 2.0 2024 Standardized format Converted to parquet with aligned conventions"},{"location":"reference/datasets_documentation/dataset_umich_2021/#contact-information","title":"Contact Information","text":"<ul> <li>Dataset Curator: Robert D. Gregg IV, Ph.D.</li> <li>Lab Website: https://gregg.engin.umich.edu/</li> <li>Lab Email: locolab@umich.edu</li> <li>Technical Support: Contact via lab email</li> <li>Bug Reports: GitHub issues on this repository</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#additional-resources","title":"Additional Resources","text":"<ul> <li>Lab Website: https://locolab.robotics.umich.edu/</li> <li>Lab GitHub: https://github.com/locolab (if available)</li> <li>Documentation: <code>umich_2021_mat_structure.md</code></li> <li>Code Examples: See tutorials folder</li> <li>Visualization Tools: <code>walking_animator.py</code></li> <li>Related Datasets: Georgia Tech datasets, AddBiomechanics</li> </ul>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#funding-acknowledgment","title":"Funding Acknowledgment","text":"<p>This dataset was collected with support from: - NIH Director's New Innovator Award (DP2HD080349) - NIH R01 Grant for agile powered prosthetic legs (R01HD094772) - Burroughs Wellcome Fund Career Award at the Scientific Interface ($500,000)</p>"},{"location":"reference/datasets_documentation/dataset_umich_2021/#lab-description","title":"Lab Description","text":"<p>The Locomotor Control Systems Laboratory is a highly interdisciplinary environment dedicated to scientific innovation,  clinical translation, and individual career development. The lab develops high-performance control systems for robotic  prostheses and orthoses to enable mobility and improve quality of life for persons with disabilities.</p> <p>Last Updated: January 2025 Template Version: 1.0</p>"},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/","title":"Dataset Validation Report","text":"<p>Generated: 2025-06-11 23:44:22 Dataset: <code>converted_datasets/umich_2021_phase.parquet</code></p>"},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#validation-summary","title":"Validation Summary","text":"<ul> <li>Total Steps Validated: 8305</li> <li>Valid Steps: 1920</li> <li>Failed Steps: 6385</li> <li>Success Rate: 23.1%</li> <li>Tasks Validated: decline_walking, incline_walking, level_walking</li> </ul>"},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#task-validation-results","title":"Task Validation Results","text":""},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#decline-walking","title":"Decline Walking","text":"<p>Kinematic Validation: </p> <p>Kinetic Validation: </p> <p>Step Summary: 1598/3518 failed steps (45.4%) Success Rate: 54.6%</p> <p>Validation Issues: 3274 failures detected - Kinematic: 3274 failures</p>"},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#incline-walking","title":"Incline Walking","text":"<p>Kinematic Validation: </p> <p>Kinetic Validation: </p> <p>Step Summary: 3176/3176 failed steps (100.0%) Success Rate: 0.0%</p> <p>Validation Issues: 42890 failures detected - Kinematic: 42890 failures</p>"},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#level-walking","title":"Level Walking","text":"<p>Kinematic Validation: </p> <p>Kinetic Validation: </p> <p>Step Summary: 1611/1611 failed steps (100.0%) Success Rate: 0.0%</p> <p>Validation Issues: 14174 failures detected - Kinematic: 14174 failures</p>"},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#detailed-failure-analysis-60338-total","title":"\u26a0\ufe0f Detailed Failure Analysis (60338 total)","text":""},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#kinematic-failures-60338","title":"Kinematic Failures (60338)","text":""},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#task-decline-walking","title":"Task: Decline Walking","text":"<p>Variable: hip_flexion_angle_ipsi (1583 failures)</p> Phase Value Expected Range Failure Reason 25.0% 0.185 0.190 to 0.700 Value 0.185 outside range [0.190, 0.700] at phase 25% 25.0% 0.186 0.190 to 0.700 Value 0.186 outside range [0.190, 0.700] at phase 25% 25.0% 0.188 0.190 to 0.700 Value 0.188 outside range [0.190, 0.700] at phase 25% 25.0% 0.187 0.190 to 0.700 Value 0.187 outside range [0.190, 0.700] at phase 25% 25.0% 0.157 0.190 to 0.700 Value 0.157 outside range [0.190, 0.700] at phase 25% 25.0% 0.160 0.190 to 0.700 Value 0.160 outside range [0.190, 0.700] at phase 25% 25.0% 0.156 0.190 to 0.700 Value 0.156 outside range [0.190, 0.700] at phase 25% 25.0% 0.173 0.190 to 0.700 Value 0.173 outside range [0.190, 0.700] at phase 25% 25.0% 0.179 0.190 to 0.700 Value 0.179 outside range [0.190, 0.700] at phase 25% 25.0% 0.169 0.190 to 0.700 Value 0.169 outside range [0.190, 0.700] at phase 25% <p>... and 1573 more failures</p> <p>Variable: hip_flexion_angle_contra (1583 failures)</p> Phase Value Expected Range Failure Reason 75.0% 0.185 0.190 to 0.700 Value 0.185 outside range [0.190, 0.700] at phase 75% 75.0% 0.186 0.190 to 0.700 Value 0.186 outside range [0.190, 0.700] at phase 75% 75.0% 0.188 0.190 to 0.700 Value 0.188 outside range [0.190, 0.700] at phase 75% 75.0% 0.187 0.190 to 0.700 Value 0.187 outside range [0.190, 0.700] at phase 75% 75.0% 0.157 0.190 to 0.700 Value 0.157 outside range [0.190, 0.700] at phase 75% 75.0% 0.160 0.190 to 0.700 Value 0.160 outside range [0.190, 0.700] at phase 75% 75.0% 0.156 0.190 to 0.700 Value 0.156 outside range [0.190, 0.700] at phase 75% 75.0% 0.173 0.190 to 0.700 Value 0.173 outside range [0.190, 0.700] at phase 75% 75.0% 0.179 0.190 to 0.700 Value 0.179 outside range [0.190, 0.700] at phase 75% 75.0% 0.169 0.190 to 0.700 Value 0.169 outside range [0.190, 0.700] at phase 75% <p>... and 1573 more failures</p> <p>Variable: ankle_flexion_angle_ipsi (24 failures)</p> Phase Value Expected Range Failure Reason 75.0% 0.304 -0.350 to 0.260 Value 0.304 outside range [-0.350, 0.260] at phase 75% 25.0% 0.143 -0.350 to 0.140 Value 0.143 outside range [-0.350, 0.140] at phase 25% 0.0% 0.402 -0.400 to 0.400 Value 0.402 outside range [-0.400, 0.400] at phase 0% 50.0% 0.114 -0.700 to 0.000 Value 0.114 outside range [-0.700, 0.000] at phase 50% 0.0% 0.585 -0.400 to 0.400 Value 0.585 outside range [-0.400, 0.400] at phase 0% 50.0% 0.066 -0.700 to 0.000 Value 0.066 outside range [-0.700, 0.000] at phase 50% 50.0% 0.071 -0.700 to 0.000 Value 0.071 outside range [-0.700, 0.000] at phase 50% 0.0% 0.443 -0.400 to 0.400 Value 0.443 outside range [-0.400, 0.400] at phase 0% 0.0% 0.461 -0.400 to 0.400 Value 0.461 outside range [-0.400, 0.400] at phase 0% 50.0% 0.014 -0.700 to 0.000 Value 0.014 outside range [-0.700, 0.000] at phase 50% <p>... and 14 more failures</p> <p>Variable: ankle_flexion_angle_contra (24 failures)</p> Phase Value Expected Range Failure Reason 25.0% 0.304 -0.350 to 0.260 Value 0.304 outside range [-0.350, 0.260] at phase 25% 75.0% 0.143 -0.350 to 0.140 Value 0.143 outside range [-0.350, 0.140] at phase 75% 50.0% 0.402 -0.400 to 0.400 Value 0.402 outside range [-0.400, 0.400] at phase 50% 0.0% 0.114 -0.700 to 0.000 Value 0.114 outside range [-0.700, 0.000] at phase 0% 50.0% 0.585 -0.400 to 0.400 Value 0.585 outside range [-0.400, 0.400] at phase 50% 0.0% 0.066 -0.700 to 0.000 Value 0.066 outside range [-0.700, 0.000] at phase 0% 0.0% 0.071 -0.700 to 0.000 Value 0.071 outside range [-0.700, 0.000] at phase 0% 50.0% 0.443 -0.400 to 0.400 Value 0.443 outside range [-0.400, 0.400] at phase 50% 50.0% 0.461 -0.400 to 0.400 Value 0.461 outside range [-0.400, 0.400] at phase 50% 0.0% 0.014 -0.700 to 0.000 Value 0.014 outside range [-0.700, 0.000] at phase 0% <p>... and 14 more failures</p> <p>Variable: knee_flexion_angle_contra (30 failures)</p> Phase Value Expected Range Failure Reason 25.0% 0.249 0.350 to 1.570 Value 0.249 outside range [0.350, 1.570] at phase 25% 25.0% 0.104 0.350 to 1.570 Value 0.104 outside range [0.350, 1.570] at phase 25% 25.0% 0.113 0.350 to 1.570 Value 0.113 outside range [0.350, 1.570] at phase 25% 50.0% 0.434 -0.170 to 0.400 Value 0.434 outside range [-0.170, 0.400] at phase 50% 25.0% -0.143 0.350 to 1.570 Value -0.143 outside range [0.350, 1.570] at phase 25% 25.0% 0.142 0.350 to 1.570 Value 0.142 outside range [0.350, 1.570] at phase 25% 25.0% -0.003 0.350 to 1.570 Value -0.003 outside range [0.350, 1.570] at phase 25% 50.0% -0.185 -0.170 to 0.400 Value -0.185 outside range [-0.170, 0.400] at phase 50% 25.0% -0.189 0.350 to 1.570 Value -0.189 outside range [0.350, 1.570] at phase 25% 25.0% 0.231 0.350 to 1.570 Value 0.231 outside range [0.350, 1.570] at phase 25% <p>... and 20 more failures</p> <p>Variable: knee_flexion_angle_ipsi (30 failures)</p> Phase Value Expected Range Failure Reason 75.0% 0.249 0.350 to 1.570 Value 0.249 outside range [0.350, 1.570] at phase 75% 75.0% 0.113 0.350 to 1.570 Value 0.113 outside range [0.350, 1.570] at phase 75% 75.0% 0.104 0.350 to 1.570 Value 0.104 outside range [0.350, 1.570] at phase 75% 0.0% 0.434 -0.170 to 0.400 Value 0.434 outside range [-0.170, 0.400] at phase 0% 75.0% -0.143 0.350 to 1.570 Value -0.143 outside range [0.350, 1.570] at phase 75% 75.0% 0.142 0.350 to 1.570 Value 0.142 outside range [0.350, 1.570] at phase 75% 75.0% -0.003 0.350 to 1.570 Value -0.003 outside range [0.350, 1.570] at phase 75% 0.0% -0.185 -0.170 to 0.400 Value -0.185 outside range [-0.170, 0.400] at phase 0% 75.0% -0.189 0.350 to 1.570 Value -0.189 outside range [0.350, 1.570] at phase 75% 75.0% 0.231 0.350 to 1.570 Value 0.231 outside range [0.350, 1.570] at phase 75% <p>... and 20 more failures</p>"},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#task-incline-walking","title":"Task: Incline Walking","text":"<p>Variable: hip_flexion_angle_ipsi (5040 failures)</p> Phase Value Expected Range Failure Reason 0.0% 0.961 0.250 to 0.800 Value 0.961 outside range [0.250, 0.800] at phase 0% 25.0% 0.553 0.000 to 0.500 Value 0.553 outside range [0.000, 0.500] at phase 25% 0.0% 0.862 0.250 to 0.800 Value 0.862 outside range [0.250, 0.800] at phase 0% 0.0% 0.954 0.250 to 0.800 Value 0.954 outside range [0.250, 0.800] at phase 0% 25.0% 0.546 0.000 to 0.500 Value 0.546 outside range [0.000, 0.500] at phase 25% 0.0% 0.907 0.250 to 0.800 Value 0.907 outside range [0.250, 0.800] at phase 0% 25.0% 0.518 0.000 to 0.500 Value 0.518 outside range [0.000, 0.500] at phase 25% 0.0% 1.028 0.250 to 0.800 Value 1.028 outside range [0.250, 0.800] at phase 0% 25.0% 0.599 0.000 to 0.500 Value 0.599 outside range [0.000, 0.500] at phase 25% 0.0% 0.968 0.250 to 0.800 Value 0.968 outside range [0.250, 0.800] at phase 0% <p>... and 5030 more failures</p> <p>Variable: knee_flexion_angle_ipsi (6987 failures)</p> Phase Value Expected Range Failure Reason 0.0% 0.464 0.000 to 0.250 Value 0.464 outside range [0.000, 0.250] at phase 0% 25.0% 0.495 0.100 to 0.400 Value 0.495 outside range [0.100, 0.400] at phase 25% 50.0% 0.076 0.600 to 0.900 Value 0.076 outside range [0.600, 0.900] at phase 50% 0.0% 0.499 0.000 to 0.250 Value 0.499 outside range [0.000, 0.250] at phase 0% 25.0% 0.445 0.100 to 0.400 Value 0.445 outside range [0.100, 0.400] at phase 25% 50.0% 0.099 0.600 to 0.900 Value 0.099 outside range [0.600, 0.900] at phase 50% 0.0% 0.556 0.000 to 0.250 Value 0.556 outside range [0.000, 0.250] at phase 0% 25.0% 0.462 0.100 to 0.400 Value 0.462 outside range [0.100, 0.400] at phase 25% 50.0% 0.111 0.600 to 0.900 Value 0.111 outside range [0.600, 0.900] at phase 50% 0.0% 0.595 0.000 to 0.250 Value 0.595 outside range [0.000, 0.250] at phase 0% <p>... and 6977 more failures</p> <p>Variable: knee_flexion_angle_contra (6987 failures)</p> Phase Value Expected Range Failure Reason 0.0% 0.090 0.600 to 0.900 Value 0.090 outside range [0.600, 0.900] at phase 0% 50.0% 0.464 0.000 to 0.250 Value 0.464 outside range [0.000, 0.250] at phase 50% 75.0% 0.495 0.100 to 0.400 Value 0.495 outside range [0.100, 0.400] at phase 75% 0.0% 0.076 0.600 to 0.900 Value 0.076 outside range [0.600, 0.900] at phase 0% 50.0% 0.499 0.000 to 0.250 Value 0.499 outside range [0.000, 0.250] at phase 50% 75.0% 0.445 0.100 to 0.400 Value 0.445 outside range [0.100, 0.400] at phase 75% 0.0% 0.099 0.600 to 0.900 Value 0.099 outside range [0.600, 0.900] at phase 0% 50.0% 0.556 0.000 to 0.250 Value 0.556 outside range [0.000, 0.250] at phase 50% 75.0% 0.462 0.100 to 0.400 Value 0.462 outside range [0.100, 0.400] at phase 75% 0.0% 0.111 0.600 to 0.900 Value 0.111 outside range [0.600, 0.900] at phase 0% <p>... and 6977 more failures</p> <p>Variable: ankle_flexion_angle_ipsi (9418 failures)</p> Phase Value Expected Range Failure Reason 0.0% -0.239 0.050 to 0.250 Value -0.239 outside range [0.050, 0.250] at phase 0% 25.0% -0.432 0.100 to 0.300 Value -0.432 outside range [0.100, 0.300] at phase 25% 50.0% -0.413 -0.300 to -0.100 Value -0.413 outside range [-0.300, -0.100] at phase 50% 75.0% -0.014 0.000 to 0.350 Value -0.014 outside range [0.000, 0.350] at phase 75% 0.0% -0.253 0.050 to 0.250 Value -0.253 outside range [0.050, 0.250] at phase 0% 25.0% -0.447 0.100 to 0.300 Value -0.447 outside range [0.100, 0.300] at phase 25% 50.0% -0.392 -0.300 to -0.100 Value -0.392 outside range [-0.300, -0.100] at phase 50% 0.0% -0.256 0.050 to 0.250 Value -0.256 outside range [0.050, 0.250] at phase 0% 25.0% -0.442 0.100 to 0.300 Value -0.442 outside range [0.100, 0.300] at phase 25% 50.0% -0.467 -0.300 to -0.100 Value -0.467 outside range [-0.300, -0.100] at phase 50% <p>... and 9408 more failures</p> <p>Variable: ankle_flexion_angle_contra (9418 failures)</p> Phase Value Expected Range Failure Reason 0.0% -0.350 -0.300 to -0.100 Value -0.350 outside range [-0.300, -0.100] at phase 0% 25.0% -0.005 0.000 to 0.350 Value -0.005 outside range [0.000, 0.350] at phase 25% 50.0% -0.239 0.050 to 0.250 Value -0.239 outside range [0.050, 0.250] at phase 50% 75.0% -0.432 0.100 to 0.300 Value -0.432 outside range [0.100, 0.300] at phase 75% 0.0% -0.413 -0.300 to -0.100 Value -0.413 outside range [-0.300, -0.100] at phase 0% 25.0% -0.014 0.000 to 0.350 Value -0.014 outside range [0.000, 0.350] at phase 25% 50.0% -0.253 0.050 to 0.250 Value -0.253 outside range [0.050, 0.250] at phase 50% 75.0% -0.447 0.100 to 0.300 Value -0.447 outside range [0.100, 0.300] at phase 75% 0.0% -0.392 -0.300 to -0.100 Value -0.392 outside range [-0.300, -0.100] at phase 0% 50.0% -0.256 0.050 to 0.250 Value -0.256 outside range [0.050, 0.250] at phase 50% <p>... and 9408 more failures</p> <p>Variable: hip_flexion_angle_contra (5040 failures)</p> Phase Value Expected Range Failure Reason 50.0% 0.961 0.250 to 0.800 Value 0.961 outside range [0.250, 0.800] at phase 50% 75.0% 0.553 0.000 to 0.500 Value 0.553 outside range [0.000, 0.500] at phase 75% 50.0% 0.862 0.250 to 0.800 Value 0.862 outside range [0.250, 0.800] at phase 50% 50.0% 0.954 0.250 to 0.800 Value 0.954 outside range [0.250, 0.800] at phase 50% 75.0% 0.546 0.000 to 0.500 Value 0.546 outside range [0.000, 0.500] at phase 75% 50.0% 0.907 0.250 to 0.800 Value 0.907 outside range [0.250, 0.800] at phase 50% 75.0% 0.518 0.000 to 0.500 Value 0.518 outside range [0.000, 0.500] at phase 75% 50.0% 1.028 0.250 to 0.800 Value 1.028 outside range [0.250, 0.800] at phase 50% 75.0% 0.599 0.000 to 0.500 Value 0.599 outside range [0.000, 0.500] at phase 75% 50.0% 0.968 0.250 to 0.800 Value 0.968 outside range [0.250, 0.800] at phase 50% <p>... and 5030 more failures</p>"},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#task-level-walking","title":"Task: Level Walking","text":"<p>Variable: knee_flexion_angle_ipsi (2427 failures)</p> Phase Value Expected Range Failure Reason 0.0% 0.152 0.000 to 0.150 Value 0.152 outside range [0.000, 0.150] at phase 0% 50.0% 0.213 0.500 to 0.800 Value 0.213 outside range [0.500, 0.800] at phase 50% 50.0% 0.198 0.500 to 0.800 Value 0.198 outside range [0.500, 0.800] at phase 50% 50.0% 0.165 0.500 to 0.800 Value 0.165 outside range [0.500, 0.800] at phase 50% 50.0% 0.174 0.500 to 0.800 Value 0.174 outside range [0.500, 0.800] at phase 50% 50.0% 0.218 0.500 to 0.800 Value 0.218 outside range [0.500, 0.800] at phase 50% 50.0% 0.197 0.500 to 0.800 Value 0.197 outside range [0.500, 0.800] at phase 50% 50.0% 0.199 0.500 to 0.800 Value 0.199 outside range [0.500, 0.800] at phase 50% 50.0% 0.179 0.500 to 0.800 Value 0.179 outside range [0.500, 0.800] at phase 50% 50.0% 0.214 0.500 to 0.800 Value 0.214 outside range [0.500, 0.800] at phase 50% <p>... and 2417 more failures</p> <p>Variable: knee_flexion_angle_contra (2427 failures)</p> Phase Value Expected Range Failure Reason 0.0% 0.165 0.500 to 0.800 Value 0.165 outside range [0.500, 0.800] at phase 0% 50.0% 0.152 0.000 to 0.150 Value 0.152 outside range [0.000, 0.150] at phase 50% 0.0% 0.213 0.500 to 0.800 Value 0.213 outside range [0.500, 0.800] at phase 0% 0.0% 0.198 0.500 to 0.800 Value 0.198 outside range [0.500, 0.800] at phase 0% 0.0% 0.165 0.500 to 0.800 Value 0.165 outside range [0.500, 0.800] at phase 0% 0.0% 0.174 0.500 to 0.800 Value 0.174 outside range [0.500, 0.800] at phase 0% 0.0% 0.218 0.500 to 0.800 Value 0.218 outside range [0.500, 0.800] at phase 0% 0.0% 0.197 0.500 to 0.800 Value 0.197 outside range [0.500, 0.800] at phase 0% 0.0% 0.199 0.500 to 0.800 Value 0.199 outside range [0.500, 0.800] at phase 0% 0.0% 0.179 0.500 to 0.800 Value 0.179 outside range [0.500, 0.800] at phase 0% <p>... and 2417 more failures</p> <p>Variable: ankle_flexion_angle_ipsi (2835 failures)</p> Phase Value Expected Range Failure Reason 0.0% -0.123 -0.050 to 0.050 Value -0.123 outside range [-0.050, 0.050] at phase 0% 25.0% -0.192 0.050 to 0.250 Value -0.192 outside range [0.050, 0.250] at phase 25% 25.0% -0.175 0.050 to 0.250 Value -0.175 outside range [0.050, 0.250] at phase 25% 0.0% -0.134 -0.050 to 0.050 Value -0.134 outside range [-0.050, 0.050] at phase 0% 25.0% -0.157 0.050 to 0.250 Value -0.157 outside range [0.050, 0.250] at phase 25% 0.0% -0.050 -0.050 to 0.050 Value -0.050 outside range [-0.050, 0.050] at phase 0% 25.0% -0.164 0.050 to 0.250 Value -0.164 outside range [0.050, 0.250] at phase 25% 0.0% -0.087 -0.050 to 0.050 Value -0.087 outside range [-0.050, 0.050] at phase 0% 25.0% -0.166 0.050 to 0.250 Value -0.166 outside range [0.050, 0.250] at phase 25% 0.0% -0.073 -0.050 to 0.050 Value -0.073 outside range [-0.050, 0.050] at phase 0% <p>... and 2825 more failures</p> <p>Variable: hip_flexion_angle_ipsi (1825 failures)</p> Phase Value Expected Range Failure Reason 50.0% 0.010 -0.350 to 0.000 Value 0.010 outside range [-0.350, 0.000] at phase 50% 50.0% 0.017 -0.350 to 0.000 Value 0.017 outside range [-0.350, 0.000] at phase 50% 0.0% 0.605 0.150 to 0.600 Value 0.605 outside range [0.150, 0.600] at phase 0% 50.0% 0.040 -0.350 to 0.000 Value 0.040 outside range [-0.350, 0.000] at phase 50% 50.0% 0.016 -0.350 to 0.000 Value 0.016 outside range [-0.350, 0.000] at phase 50% 50.0% 0.038 -0.350 to 0.000 Value 0.038 outside range [-0.350, 0.000] at phase 50% 50.0% 0.042 -0.350 to 0.000 Value 0.042 outside range [-0.350, 0.000] at phase 50% 50.0% 0.015 -0.350 to 0.000 Value 0.015 outside range [-0.350, 0.000] at phase 50% 50.0% 0.004 -0.350 to 0.000 Value 0.004 outside range [-0.350, 0.000] at phase 50% 50.0% 0.010 -0.350 to 0.000 Value 0.010 outside range [-0.350, 0.000] at phase 50% <p>... and 1815 more failures</p> <p>Variable: ankle_flexion_angle_contra (2835 failures)</p> Phase Value Expected Range Failure Reason 50.0% -0.123 -0.050 to 0.050 Value -0.123 outside range [-0.050, 0.050] at phase 50% 75.0% -0.192 0.050 to 0.250 Value -0.192 outside range [0.050, 0.250] at phase 75% 75.0% -0.175 0.050 to 0.250 Value -0.175 outside range [0.050, 0.250] at phase 75% 50.0% -0.134 -0.050 to 0.050 Value -0.134 outside range [-0.050, 0.050] at phase 50% 75.0% -0.157 0.050 to 0.250 Value -0.157 outside range [0.050, 0.250] at phase 75% 50.0% -0.050 -0.050 to 0.050 Value -0.050 outside range [-0.050, 0.050] at phase 50% 75.0% -0.164 0.050 to 0.250 Value -0.164 outside range [0.050, 0.250] at phase 75% 50.0% -0.087 -0.050 to 0.050 Value -0.087 outside range [-0.050, 0.050] at phase 50% 75.0% -0.166 0.050 to 0.250 Value -0.166 outside range [0.050, 0.250] at phase 75% 50.0% -0.073 -0.050 to 0.050 Value -0.073 outside range [-0.050, 0.050] at phase 50% <p>... and 2825 more failures</p> <p>Variable: hip_flexion_angle_contra (1825 failures)</p> Phase Value Expected Range Failure Reason 0.0% 0.010 -0.350 to 0.000 Value 0.010 outside range [-0.350, 0.000] at phase 0% 0.0% 0.017 -0.350 to 0.000 Value 0.017 outside range [-0.350, 0.000] at phase 0% 50.0% 0.605 0.150 to 0.600 Value 0.605 outside range [0.150, 0.600] at phase 50% 0.0% 0.040 -0.350 to 0.000 Value 0.040 outside range [-0.350, 0.000] at phase 0% 0.0% 0.016 -0.350 to 0.000 Value 0.016 outside range [-0.350, 0.000] at phase 0% 0.0% 0.038 -0.350 to 0.000 Value 0.038 outside range [-0.350, 0.000] at phase 0% 0.0% 0.042 -0.350 to 0.000 Value 0.042 outside range [-0.350, 0.000] at phase 0% 0.0% 0.015 -0.350 to 0.000 Value 0.015 outside range [-0.350, 0.000] at phase 0% 0.0% 0.004 -0.350 to 0.000 Value 0.004 outside range [-0.350, 0.000] at phase 0% 0.0% 0.010 -0.350 to 0.000 Value 0.010 outside range [-0.350, 0.000] at phase 0% <p>... and 1815 more failures</p>"},{"location":"reference/datasets_documentation/validation_reports/umich_2021_phase_validation_report/#recommendations","title":"Recommendations","text":"<ol> <li>Review data collection protocols for tasks with high failure rates</li> <li>Check sensor calibration for variables consistently out of range</li> <li>Verify subject instructions and movement quality</li> <li>Consider if validation ranges need updating for your population</li> </ol>"},{"location":"reference/standard_spec/","title":"Standard Specification","text":"<p>Data format specifications and validation rules for locomotion datasets.</p> <p>Quick Reference: Format Spec \u2022 Units &amp; Conventions \u2022 Task Definitions</p>"},{"location":"reference/standard_spec/#core-specifications","title":"Core Specifications","text":"<p>Data Format - standard_spec.md: - Variable naming: <code>knee_flexion_angle_ipsi_rad</code> - Time vs phase-indexed formats - Required columns and validation rules</p> <p>Units &amp; Conventions - units_and_conventions.md: - OpenSim-compatible coordinate system and sign conventions - Variable naming patterns and units - Typical biomechanical values and ranges</p> <p>Task Definitions - task_definitions.md: - Standard task vocabulary - Metadata schema for task parameters - Usage examples and field descriptions</p>"},{"location":"reference/standard_spec/#validation-specifications","title":"Validation Specifications","text":"<p>Kinematic Validation - validation_expectations_kinematic.md: - Joint angle validation ranges - Phase-specific biomechanical expectations - Task-specific validation rules</p> <p>Kinetic Validation - validation_expectations_kinetic.md: - Force and moment validation ranges - Ground reaction force expectations - Power and energy validation criteria</p>"},{"location":"reference/standard_spec/#templates-and-tools","title":"Templates and Tools","text":"<p>Dataset Template - dataset_template.md: - Standard template for documenting new datasets - Required fields and citation format - Implementation guidelines</p> <p>Validation Images - validation/: - Phase-specific kinematic pose visualizations - Biomechanical range validation plots - Reference images for expected movement patterns</p> <p>These specifications ensure consistency and quality across all standardized datasets.</p>"},{"location":"reference/standard_spec/PM_ongoing/","title":"PM ONGOING - Standard Specification","text":""},{"location":"reference/standard_spec/PM_ongoing/#high-level-tasks","title":"High Level Tasks","text":""},{"location":"reference/standard_spec/PM_ongoing/#1-complete-kinetic-validation-coverage","title":"1. Complete Kinetic Validation Coverage","text":"<ul> <li>Description: Expand kinetic validation ranges to all 9 tasks (currently only 3 tasks have kinetic data)</li> <li>Status: \u2705 PRODUCTION READY</li> <li>Completed Tasks: All 9 tasks now have complete kinetic validation coverage</li> <li>Implementation: Literature-based GRF and joint moment patterns for all locomotion tasks</li> </ul>"},{"location":"reference/standard_spec/PM_ongoing/#2-opensim-convention-alignment","title":"2. OpenSim Convention Alignment","text":"<ul> <li>Description: Ensure all joint angle sign conventions match OpenSim standards for maximum biomechanical modeling compatibility</li> <li>Status: \u2705 PRODUCTION READY</li> </ul>"},{"location":"reference/standard_spec/PM_ongoing/#3-motion-capture-error-tolerance","title":"3. Motion Capture Error Tolerance","text":"<ul> <li>Description: Implement realistic validation ranges that accommodate measurement noise and calibration errors</li> <li>Status: \u2705 PRODUCTION READY</li> </ul>"},{"location":"reference/standard_spec/PM_ongoing/#4-validation-expectations-enhancement","title":"4. Validation Expectations Enhancement","text":"<ul> <li>Description: Develop comprehensive phase-specific validation ranges with visual kinematic verification</li> <li>Status: \u2705 PRODUCTION READY</li> </ul>"},{"location":"reference/standard_spec/PM_ongoing/#2-kinetic-validation-refinement","title":"2. Kinetic Validation Refinement","text":"<ul> <li>Description: Refine literature-based kinetic validation ranges with enhanced biomechanical accuracy</li> <li>Status: \ud83d\udea7 NEXT PRIORITY  </li> <li>Current Status: Basic literature estimates implemented for all 9 tasks</li> <li>Requirements: Deep literature review for task-specific GRF and joint moment patterns with enhanced precision</li> </ul>"},{"location":"reference/standard_spec/PM_ongoing/#recent-work-last-15-items","title":"Recent Work (Last 15 Items)","text":""},{"location":"reference/standard_spec/PM_ongoing/#2025-06-11","title":"2025-06-11","text":"<ol> <li>Documentation Streamlining to Minimal Aesthetic - Applied refined minimal style across all standard specification files</li> <li>Streamlined standard_spec.md from verbose technical documentation to concise reference</li> <li>Consolidated sign_conventions.md into units_and_conventions.md with typical biomechanical values</li> <li>Applied minimal aesthetic with quick reference navigation and visual separators</li> <li>Maintained OpenSim compatibility and biomechanical accuracy while improving accessibility</li> <li> <p>Created consistent documentation structure with essential information focus</p> </li> <li> <p>README Files for Standard Spec Directories - Enhanced navigation and user experience</p> </li> <li>Created docs/standard_spec/README.md with quick reference navigation</li> <li>Created docs/tutorials/README.md streamlined from existing verbose version</li> <li>Created docs/datasets_documentation/README.md for dataset navigation</li> <li>Applied consistent minimal style with bullet-separated quick links</li> <li>Improved project documentation discoverability and usability</li> </ol>"},{"location":"reference/standard_spec/PM_ongoing/#2025-06-10","title":"2025-06-10","text":"<ol> <li>Complete Kinetic Validation Coverage - Extended kinetic validation to all 9 locomotion tasks</li> <li>Added 6 missing tasks: decline_walking, up_stairs, down_stairs, sit_to_stand, jump, squats</li> <li>Implemented literature-based GRF and joint moment patterns for each task</li> <li>Generated kinetic filters by phase validation images for all new tasks</li> <li>Hardcoded validation image output directory to prevent incorrect placement</li> <li>Research findings: decline walking eccentric control, stair climbing 3x knee moments, explosive jumping patterns</li> </ol>"},{"location":"reference/standard_spec/PM_ongoing/#2025-06-10_1","title":"2025-06-10","text":"<ol> <li>Visualization Naming Refactor Complete - Updated terminology and unified plotting architecture</li> <li>Renamed \"phase progression\" \u2192 \"filters by phase\" throughout all documentation</li> <li>Added \"forward kinematics\" to pose visualization naming for clarity</li> <li>Merged individual plotting scripts into unified <code>filters_by_phase_plots.py</code> with mode toggle</li> <li>Renamed <code>kinematic_pose_generator.py</code> \u2192 <code>forward_kinematics_plots.py</code> for consistency</li> <li>Fixed contralateral offset logic for complete 100% phase cyclical data</li> <li>Generated all 48 validation images with new naming convention</li> <li>Updated all cross-references and import statements</li> </ol>"},{"location":"reference/standard_spec/PM_ongoing/#2025-01-09","title":"2025-01-09","text":"<ol> <li>OpenSim Convention Alignment Complete - Fixed knee flexion sign convention throughout standard specification</li> <li>Updated sign_conventions.md with detailed joint-specific notation</li> <li>Corrected validation_expectations_kinematic.md problematic range (heel strike: 0\u00b0 to 9\u00b0)</li> <li>Added OpenSim compatibility statements throughout documentation</li> <li> <p>Enhanced biomechanical interpretation sections</p> </li> <li> <p>Motion Capture Error Tolerance Implementation - Added -10\u00b0 tolerance for realistic measurement scenarios</p> </li> <li>Updated 17 knee flexion ranges across all tasks and phases</li> <li>Changed minimums from 0.0 (0\u00b0) to -0.17 (-10\u00b0) in validation_expectations_kinematic.md</li> <li>Added clear documentation of motion capture tolerance in sign_conventions.md</li> <li> <p>Validated 100% acceptance rate for realistic motion capture noise</p> </li> <li> <p>Test Case Generation with Error Tolerance - Created comprehensive test suite for motion capture scenarios</p> </li> <li>Updated spec_compliance_test_suite.py with realistic motion capture error simulation</li> <li>Created test_mocap_tolerance.py for end-to-end validation system testing</li> <li>Created validate_mocap_ranges.py for direct range validation testing</li> <li>Generated test data accommodating -10\u00b0 to +120\u00b0 knee flexion ranges</li> </ol>"},{"location":"reference/standard_spec/PM_ongoing/#2025-01-08","title":"2025-01-08","text":"<ol> <li>Forward Kinematics Fix - Corrected stick figure generation for anatomically accurate visualization</li> <li>Fixed joint angle calculations in generate_phase_range_images.py</li> <li>Implemented proper kinematic chain: hip \u2192 thigh \u2192 shank \u2192 foot</li> <li>Verified OpenSim convention implementation in visualization system</li> <li> <p>Generated 36 validation images with corrected biomechanical postures</p> </li> <li> <p>Phase Progression Plot Generation - Added missing phase progression visualizations</p> </li> <li>Generated 9 phase progression plots for all validated tasks</li> <li>Implemented contralateral offset logic with 50% phase relationships</li> <li>Created realistic joint angle patterns across 0%, 25%, 50%, 75% phases</li> <li> <p>Fixed broken markdown image references in validation documentation</p> </li> <li> <p>Validation System Architecture Update - Implemented v5.0 phase system with enhanced bilateral handling</p> </li> <li>Updated from 0%, 33%, 50%, 66% to 0%, 25%, 50%, 75% phase points</li> <li>Implemented automatic contralateral offset computation</li> <li>Added task classification system (gait vs bilateral symmetric)</li> <li> <p>Enhanced validation_expectations.md with biomechanically verified ranges</p> </li> <li> <p>Sign Convention Documentation Enhancement - Added comprehensive joint angle notation</p> </li> <li>Created detailed hip, knee, and ankle joint definitions</li> <li>Added biomechanical interpretation for each degree of freedom</li> <li>Included typical functional ranges and clinical significance</li> <li> <p>Added visual reference systems and summary tables</p> </li> <li> <p>Version Management Separation - Moved version history out of main validation file</p> </li> <li>Created validation_expectations_changelog.md for version tracking</li> <li>Cleaned up validation_expectations.md main specification</li> <li>Added proper cross-references between documents</li> <li>Maintained historical record while improving readability</li> </ol>"},{"location":"reference/standard_spec/PM_ongoing/#context-scratchpad","title":"Context Scratchpad","text":""},{"location":"reference/standard_spec/PM_ongoing/#opensim-conventions","title":"OpenSim Conventions","text":"<ul> <li>Hip: Flexion positive (thigh forward), extension negative</li> <li>Knee: Extension = 0\u00b0, flexion positive (0\u00b0 \u2192 140\u00b0) - KEY CONVENTION</li> <li>Ankle: Dorsiflexion positive (toes up), plantarflexion negative</li> <li>Motion Capture Tolerance: -10\u00b0 minimum for knee due to measurement errors</li> </ul>"},{"location":"reference/standard_spec/PM_ongoing/#key-files","title":"Key Files","text":"<ul> <li>units_and_conventions.md: Authoritative source for joint angle interpretation, sign conventions, and typical values</li> <li>validation_expectations_kinematic.md: Phase-specific validation ranges  </li> <li>validation_expectations_changelog.md: Version history and changes</li> <li>generate_phase_range_images.py: Stick figure generation with corrected kinematics</li> </ul>"},{"location":"reference/standard_spec/PM_ongoing/#validation-commands","title":"Validation Commands","text":"<ul> <li><code>python3 source/visualization/phase_progression_plots.py</code> - Generate progression plots</li> <li><code>python3 scripts/generate_phase_range_images.py</code> - Generate individual phase images</li> <li><code>python3 source/tests/validate_mocap_ranges.py</code> - Test motion capture tolerance</li> </ul>"},{"location":"reference/standard_spec/dataset_template/","title":"Dataset Name","text":""},{"location":"reference/standard_spec/dataset_template/#overview","title":"Overview","text":"<p>Brief Description: [1-2 sentence summary of the dataset's purpose and scope]</p> <p>Collection Year: [Year]</p> <p>Institution: [Institution name and department]</p> <p>Principal Investigators: [PI names and affiliations]</p>"},{"location":"reference/standard_spec/dataset_template/#citation-information","title":"Citation Information","text":""},{"location":"reference/standard_spec/dataset_template/#primary-citation","title":"Primary Citation","text":"<pre><code>[Authors]. ([Year]). [Dataset title]. [Repository/Archive]. [DOI/URL]\n</code></pre>"},{"location":"reference/standard_spec/dataset_template/#associated-publications","title":"Associated Publications","text":"<ol> <li>[List any papers that describe the dataset or use it]</li> <li>[Include DOI links where available]</li> </ol>"},{"location":"reference/standard_spec/dataset_template/#acknowledgments","title":"Acknowledgments","text":"<p>[Any specific acknowledgment text required by the dataset creators or funding sources]</p>"},{"location":"reference/standard_spec/dataset_template/#dataset-contents","title":"Dataset Contents","text":""},{"location":"reference/standard_spec/dataset_template/#subjects","title":"Subjects","text":"<ul> <li>Total Subjects: [Number]</li> <li>Demographics:</li> <li>Age Range: [min-max years]</li> <li>Sex Distribution: [M/F counts]</li> <li>Height Range: [min-max cm]</li> <li>Weight Range: [min-max kg]</li> <li>Additional Characteristics: [e.g., healthy/pathological, activity level]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#tasks-included","title":"Tasks Included","text":"Task ID Task Description Duration/Cycles Conditions Notes [ID] [Description] [Time/cycles] [Speed/incline/etc] [Special notes]"},{"location":"reference/standard_spec/dataset_template/#data-columns","title":"Data Columns","text":""},{"location":"reference/standard_spec/dataset_template/#kinematic-variables","title":"Kinematic Variables","text":"Variable Name Description Units Sampling Rate [name] [description] [units] [Hz]"},{"location":"reference/standard_spec/dataset_template/#kinetic-variables","title":"Kinetic Variables","text":"Variable Name Description Units Sampling Rate [name] [description] [units] [Hz]"},{"location":"reference/standard_spec/dataset_template/#additional-data-if-applicable","title":"Additional Data (if applicable)","text":"Variable Name Type Description Units Sampling Rate [name] [EMG/IMU/etc] [description] [units] [Hz]"},{"location":"reference/standard_spec/dataset_template/#file-structure","title":"File Structure","text":"<pre><code>dataset_name/\n\u251c\u2500\u2500 time_series/\n\u2502   \u2514\u2500\u2500 [file_naming_pattern].parquet\n\u251c\u2500\u2500 phase_normalized/\n\u2502   \u2514\u2500\u2500 [file_naming_pattern].parquet\n\u2514\u2500\u2500 metadata/\n    \u2514\u2500\u2500 [any additional metadata files]\n</code></pre>"},{"location":"reference/standard_spec/dataset_template/#data-collection-methods","title":"Data Collection Methods","text":""},{"location":"reference/standard_spec/dataset_template/#motion-capture-system","title":"Motion Capture System","text":"<ul> <li>System: [e.g., Vicon, OptiTrack]</li> <li>Marker Set: [e.g., Plug-in Gait, custom]</li> <li>Sampling Rate: [Hz]</li> <li>Camera Count: [Number]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#force-plates-if-applicable","title":"Force Plates (if applicable)","text":"<ul> <li>Model: [Manufacturer and model]</li> <li>Sampling Rate: [Hz]</li> <li>Configuration: [e.g., embedded in walkway, treadmill-mounted]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#additional-sensors-if-applicable","title":"Additional Sensors (if applicable)","text":"<ul> <li>EMG System: [Details]</li> <li>IMU System: [Details]</li> <li>Other: [Details]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#processing-pipeline","title":"Processing Pipeline","text":"<ol> <li>[Step 1: e.g., marker labeling]</li> <li>[Step 2: e.g., gap filling]</li> <li>[Step 3: e.g., filtering specifications]</li> <li>[Step 4: e.g., inverse kinematics/dynamics]</li> </ol>"},{"location":"reference/standard_spec/dataset_template/#known-issues-and-limitations","title":"Known Issues and Limitations","text":""},{"location":"reference/standard_spec/dataset_template/#data-quality-issues","title":"Data Quality Issues","text":"<ul> <li>[Issue 1: e.g., marker occlusions in specific tasks]</li> <li>[Issue 2: e.g., force plate saturation in running trials]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#missing-data","title":"Missing Data","text":"<ul> <li>[Subject IDs with missing trials]</li> <li>[Tasks with incomplete data]</li> <li>[Specific variables with gaps]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#processing-artifacts","title":"Processing Artifacts","text":"<ul> <li>[Any known artifacts from processing]</li> <li>[Recommended exclusion criteria]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#usage-notes","title":"Usage Notes","text":""},{"location":"reference/standard_spec/dataset_template/#recommended-use-cases","title":"Recommended Use Cases","text":"<ul> <li>[Appropriate research applications]</li> <li>[Validated analyses with this dataset]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#not-recommended-for","title":"Not Recommended For","text":"<ul> <li>[Limitations on use]</li> <li>[Analyses that may be problematic]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#data-access-requirements","title":"Data Access Requirements","text":"<ul> <li>License: [Open/Restricted/Custom]</li> <li>Access Process: [How to obtain the data]</li> <li>Usage Restrictions: [Any specific restrictions]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#version-history","title":"Version History","text":"Version Date Changes Notes 1.0 [Date] Initial release [Notes]"},{"location":"reference/standard_spec/dataset_template/#contact-information","title":"Contact Information","text":"<ul> <li>Dataset Curator: [Name, email]</li> <li>Technical Support: [Contact info]</li> <li>Bug Reports: [Where to report issues]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#additional-resources","title":"Additional Resources","text":"<ul> <li>Documentation: [Links to additional docs]</li> <li>Code Examples: [Links to example scripts]</li> <li>Visualization Tools: [Available tools]</li> <li>Related Datasets: [Similar or complementary datasets]</li> </ul>"},{"location":"reference/standard_spec/dataset_template/#funding-acknowledgment","title":"Funding Acknowledgment","text":"<p>[Grant numbers and funding agencies that supported this work]</p> <p>Last Updated: [Date] Template Version: 1.0</p>"},{"location":"reference/standard_spec/standard_spec/","title":"Locomotion Data Standard","text":"<p>Standardized format for biomechanical datasets with consistent variable naming and structure.</p> <p>Quick Reference: Variable Naming \u2022 Data Formats \u2022 Task Definitions</p>"},{"location":"reference/standard_spec/standard_spec/#data-formats","title":"Data Formats","text":""},{"location":"reference/standard_spec/standard_spec/#time-indexed-data","title":"Time-Indexed Data","text":"<p>Original sampling frequency preserved</p> <ul> <li>Format: <code>dataset_time.parquet</code></li> <li>Structure: Continuous time series data</li> <li>Use case: Temporal analysis, event detection</li> </ul>"},{"location":"reference/standard_spec/standard_spec/#phase-indexed-data","title":"Phase-Indexed Data","text":"<p>Normalized to 150 points per gait cycle</p> <ul> <li>Format: <code>dataset_phase.parquet</code> </li> <li>Structure: 150 points per cycle (0-100%)</li> <li>Use case: Cross-subject comparison, averaging</li> </ul>"},{"location":"reference/standard_spec/standard_spec/#variable-naming","title":"Variable Naming","text":"<p>Pattern: <code>&lt;joint&gt;_&lt;motion&gt;_&lt;measurement&gt;_&lt;side&gt;_&lt;unit&gt;</code></p> <p>Examples: - <code>knee_flexion_angle_ipsi_rad</code> - <code>hip_moment_contra_Nm</code> - <code>ankle_flexion_velocity_ipsi_rad_s</code></p> <p>Sides: - <code>ipsi</code> - Ipsilateral (same side as leading leg) - <code>contra</code> - Contralateral (opposite side)</p> <p>Units: - Angles: <code>rad</code> (radians) - Moments: <code>Nm</code> (Newton-meters)  - Velocities: <code>rad_s</code> (radians per second) - Forces: <code>N</code> (Newtons)</p>"},{"location":"reference/standard_spec/standard_spec/#required-columns","title":"Required Columns","text":"<p>Structural: - <code>subject</code> - Subject identifier - <code>task</code> - Task name - <code>step</code> - Step/cycle number</p> <p>Phase Data: - <code>phase_percent</code> - Gait cycle phase (0-100%)</p> <p>Time Data: - <code>time_s</code> - Time in seconds</p>"},{"location":"reference/standard_spec/standard_spec/#standard-variables","title":"Standard Variables","text":"<p>Joint Angles (required): - <code>hip_flexion_angle_&lt;side&gt;_rad</code> - <code>knee_flexion_angle_&lt;side&gt;_rad</code>  - <code>ankle_flexion_angle_&lt;side&gt;_rad</code></p> <p>Joint Moments (optional): - <code>hip_moment_&lt;side&gt;_Nm</code> - <code>knee_moment_&lt;side&gt;_Nm</code> - <code>ankle_moment_&lt;side&gt;_Nm</code></p> <p>Ground Forces (optional): - <code>vertical_grf_&lt;side&gt;_N</code> - <code>anterior_grf_&lt;side&gt;_N</code> - <code>lateral_grf_&lt;side&gt;_N</code></p>"},{"location":"reference/standard_spec/standard_spec/#task-definitions","title":"Task Definitions","text":"<p>Standard Task Names: - <code>level_walking</code> - Walking on level ground - <code>incline_walking</code> - Walking uphill - <code>decline_walking</code> - Walking downhill - <code>up_stairs</code> - Stair ascent - <code>down_stairs</code> - Stair descent - <code>run</code> - Running - <code>sit_to_stand</code> - Chair rise - <code>jump</code> - Jumping - <code>squats</code> - Squatting motion</p>"},{"location":"reference/standard_spec/standard_spec/#sign-conventions","title":"Sign Conventions","text":"<p>Joint Angles: - Positive flexion: Hip, knee, ankle dorsiflexion - Negative extension: Hip, knee, ankle plantarflexion</p> <p>Coordinate System: - X: Anterior (forward) - Y: Superior (up) - Z: Lateral (right)</p> <p>Ground Forces: - Positive Y: Upward (vertical) - Positive X: Forward (anterior) - Positive Z: Rightward (lateral)</p>"},{"location":"reference/standard_spec/standard_spec/#phase-calculation","title":"Phase Calculation","text":"<p>Phase-indexed data normalization: 1. Detect gait events (heel strike to heel strike) 2. Normalize each cycle to exactly 150 points 3. Calculate phase percentage: <code>phase_percent = (point_index / 149) * 100</code></p> <p>Phase Interpretation: - <code>0%</code> - Heel strike (start of gait cycle) - <code>~60%</code> - Opposite heel strike (typical) - <code>100%</code> - Next heel strike (end of cycle)</p>"},{"location":"reference/standard_spec/standard_spec/#missing-data","title":"Missing Data","text":"<p>Handling: - Missing values: <code>NaN</code> (Not a Number) - Invalid measurements: <code>NaN</code> - No synthetic data generation</p> <p>Quality Flags (optional): - <code>is_reconstructed_&lt;side&gt;</code> - Boolean flag for filled data - Use <code>true</code> for interpolated/reconstructed values</p>"},{"location":"reference/standard_spec/standard_spec/#file-examples","title":"File Examples","text":"<p>Time-indexed: <pre><code>subject,task,step,time_s,knee_flexion_angle_ipsi_rad,hip_moment_contra_Nm\nSUB01,level_walking,0,0.00,0.123,-0.456\nSUB01,level_walking,0,0.01,0.126,-0.445\nSUB01,level_walking,1,1.20,0.120,-0.460\n</code></pre></p> <p>Phase-indexed: <pre><code>subject,task,step,phase_percent,knee_flexion_angle_ipsi_rad,hip_moment_contra_Nm\nSUB01,level_walking,0,0.0,0.123,-0.456\nSUB01,level_walking,0,0.7,0.126,-0.445\nSUB01,level_walking,0,100.0,0.120,-0.460\nSUB01,level_walking,1,0.0,0.125,-0.458\n</code></pre></p>"},{"location":"reference/standard_spec/standard_spec/#validation-requirements","title":"Validation Requirements","text":"<p>Phase Data Validation: - Exactly 150 points per cycle - Phase values: 0.0 to 100.0 - No gaps in phase progression</p> <p>Variable Validation: - Joint angles: -\u03c0 to \u03c0 radians - Realistic biomechanical ranges - Consistent units across datasets</p> <p>For detailed implementation examples, see the Python Tutorial and MATLAB Tutorial.</p>"},{"location":"reference/standard_spec/task_definitions/","title":"Task Definitions","text":"<p>Standardized task vocabulary and metadata structure for locomotion datasets.</p>"},{"location":"reference/standard_spec/task_definitions/#standard-task-names","title":"Standard Task Names","text":"<p>Walking Tasks: - <code>level_walking</code> - Walking on level ground - <code>incline_walking</code> - Walking uphill (positive incline) - <code>decline_walking</code> - Walking downhill (negative incline) - <code>treadmill_walking</code> - Treadmill walking</p> <p>Stair Tasks: - <code>up_stairs</code> - Stair ascent - <code>down_stairs</code> - Stair descent</p> <p>Dynamic Tasks: - <code>run</code> - Running or jogging - <code>jump</code> - Jumping motion - <code>hop</code> - Single-leg hopping</p> <p>Functional Tasks: - <code>sit_to_stand</code> - Chair rise - <code>squats</code> - Squatting motion - <code>lunges</code> - Lunge exercise</p>"},{"location":"reference/standard_spec/task_definitions/#task-metadata-schema","title":"Task Metadata Schema","text":"<p>Required Fields: - <code>task_id</code> - Unique task identifier (e.g., <code>SUB01_T01</code>) - <code>subject</code> - Subject identifier - <code>task</code> - Standardized task name</p> <p>Optional Parameters: - <code>ground_inclination_deg</code> - Surface angle (degrees) - <code>walking_speed_m_s</code> - Target speed (m/s) - <code>step_height_m</code> - Step height for stairs (meters) - <code>load_weight_kg</code> - Carried weight (kg)</p>"},{"location":"reference/standard_spec/task_definitions/#field-details","title":"Field Details","text":"<ul> <li><code>step_height_m</code>: vertical rise of each step, typically used in <code>up_stairs</code> and <code>down_stairs</code> tasks. Units: meters.</li> <li><code>stair_inclination_deg</code>: inclination of the staircase itself in degrees. Can be positive for both ascent and descent if describing the physical characteristic of the stairs. Relevant for <code>up_stairs</code> and <code>down_stairs</code> tasks. Units: degrees.</li> <li><code>task_id</code>: Prefer a structured format combining subject and trial, e.g. <code>S01_T03</code> for Subject 01, Task 03.</li> <li><code>task_name</code>: Must match one of the entries in <code>reference/task_vocabulary.csv</code>.</li> <li>Time Bounds (<code>start_time_s</code>, <code>end_time_s</code>): Used to extract continuous segments for each task; these may be omitted if segmentation is implicit in the fact table.</li> <li>Task Parameters:</li> <li><code>ground_inclination_deg</code>: slope of treadmill or ramp; positive values indicate an upward incline.</li> <li><code>walking_speed_m_s</code> / <code>treadmill_speed_m_s</code>: use exactly one when applicable; leave the other <code>NaN</code>.</li> <li><code>load_weight_kg</code>: relevant for load-bearing tasks (e.g., <code>lift_weight</code>).</li> <li>Distance Metrics (<code>path_length_m</code>): total path length; useful for overground walking tasks.</li> <li>Markers for Phase (<code>source_marker_*</code>): if the dataset includes explicit heel-strike events, store the original marker name or frame index; conversion pipelines may skip GRF-based detection.</li> </ul>"},{"location":"reference/standard_spec/task_definitions/#usage-example","title":"Usage Example","text":"<p>Load metadata and join in Python:</p> <p>```python import pandas as pd</p>"},{"location":"reference/standard_spec/task_definitions/#read-dimension-and-fact","title":"Read dimension and fact","text":"<p>meta_task = pd.read_parquet('metadata_task.parquet') fact = pd.read_parquet('dataset_time.parquet')</p>"},{"location":"reference/standard_spec/task_definitions/#merge-on-task_id","title":"Merge on task_id","text":"<p>df = fact.merge(meta_task, on='task_id', how='left') ````</p> <p>Please review and suggest any additional fields or clarifications needed for your task definitions.\"```}</p>"},{"location":"reference/standard_spec/units_and_conventions/","title":"Units and Conventions","text":"<p>OpenSim-compatible coordinate system, variable naming, and biomechanical reference values.</p> <p>Quick Reference: Coordinate System \u2022 Variable Naming \u2022 Joint Angles \u2022 Forces and Moments \u2022 Typical Values</p>"},{"location":"reference/standard_spec/units_and_conventions/#coordinate-system","title":"Coordinate System","text":"<p>Global Frame (Right-handed): - X: Forward (anterior) - Y: Upward (superior) - Z: Rightward (lateral)</p>"},{"location":"reference/standard_spec/units_and_conventions/#variable-naming","title":"Variable Naming","text":"<p>Pattern: <code>&lt;joint&gt;_&lt;motion&gt;_&lt;measurement&gt;_&lt;side&gt;_&lt;unit&gt;</code></p> <p>Examples: - <code>knee_flexion_angle_ipsi_rad</code> - <code>hip_flexion_moment_contra_Nm</code> - <code>ankle_flexion_velocity_ipsi_rad_s</code></p> <p>Sides: - <code>ipsi</code> - Ipsilateral (same side as leading leg) - <code>contra</code> - Contralateral (opposite side)</p> <p>Units: - Angles: <code>rad</code> (radians) - Moments: <code>Nm</code> (Newton-meters)  - Velocities: <code>rad_s</code> (radians per second) - Forces: <code>N</code> (Newtons)</p>"},{"location":"reference/standard_spec/units_and_conventions/#joint-angles","title":"Joint Angles","text":""},{"location":"reference/standard_spec/units_and_conventions/#hip-joint","title":"Hip Joint","text":"<p>Hip Flexion (<code>hip_flexion_angle_[ipsi|contra]_rad</code>): - Positive: Thigh forward relative to pelvis - Zero: Vertical thigh alignment - Range: -20\u00b0 (extension) to 110\u00b0 (sitting)</p> <p>Hip Adduction (<code>hip_adduction_angle_[ipsi|contra]_rad</code>): - Positive: Thigh toward midline - Range: -20\u00b0 to 30\u00b0</p>"},{"location":"reference/standard_spec/units_and_conventions/#knee-joint","title":"Knee Joint","text":"<p>Knee Flexion (<code>knee_flexion_angle_[ipsi|contra]_rad</code>): - Zero: Full extension (OpenSim standard) - Positive: Knee bending (0\u00b0 \u2192 140\u00b0) - Range: 0\u00b0 (extension) to 140\u00b0 (maximum flexion) - Note: Motion capture may show -10\u00b0 due to measurement noise</p> <p>Knee Adduction (<code>knee_adduction_angle_[ipsi|contra]_rad</code>): - Positive: Valgus (toward midline) - Negative: Varus (away from midline) - Range: -10\u00b0 to 15\u00b0</p>"},{"location":"reference/standard_spec/units_and_conventions/#ankle-joint","title":"Ankle Joint","text":"<p>Ankle Flexion (<code>ankle_flexion_angle_[ipsi|contra]_rad</code>): - Zero: Foot flat on ground - Positive: Dorsiflexion (toes up) - Negative: Plantarflexion (toes down) - Range: -25\u00b0 (plantarflexion) to 40\u00b0 (dorsiflexion)</p> <p>Ankle Inversion (<code>ankle_inversion_angle_[ipsi|contra]_rad</code>): - Positive: Sole toward midline - Range: -15\u00b0 to 20\u00b0</p>"},{"location":"reference/standard_spec/units_and_conventions/#forces-and-moments","title":"Forces and Moments","text":""},{"location":"reference/standard_spec/units_and_conventions/#ground-reaction-forces","title":"Ground Reaction Forces","text":"<p>Following the OpenSim coordinate system:</p> <ul> <li>vertical_grf_N: Vertical ground reaction force (N/kg when normalized)</li> <li>Positive: Upward force (along global Y-axis)</li> <li> <p>Zero reference: No vertical force</p> </li> <li> <p>ap_grf_N: Anterior-posterior ground reaction force (N/kg when normalized)</p> </li> <li>Positive: Forward/anterior force (along global X-axis) - propulsive</li> <li>Negative: Backward/posterior force - braking/decelerative</li> <li> <p>Zero reference: No anterior-posterior force</p> </li> <li> <p>ml_grf_N: Medial-lateral ground reaction force (N/kg when normalized)</p> </li> <li>Positive: Rightward/lateral force (along global Z-axis)</li> <li>Negative: Leftward/medial force</li> <li>Zero reference: No medial-lateral force</li> </ul>"},{"location":"reference/standard_spec/units_and_conventions/#joint-moments","title":"Joint Moments","text":"<p>Following the OpenSim right-hand rule:</p> <ul> <li>hip_flexion_moment_[ipsi|contra]_Nm: Hip flexion/extension moment</li> <li>Positive: Hip flexion moment (thigh forward rotation)</li> <li>Negative: Hip extension moment (thigh backward rotation)</li> <li>Zero reference: No hip moment</li> <li> <p>Anatomical meaning: Positive values assist hip flexor muscles, negative values assist hip extensor muscles</p> </li> <li> <p>knee_flexion_moment_[ipsi|contra]_Nm: Knee flexion/extension moment</p> </li> <li>Positive: Knee flexion moment</li> <li>Negative: Knee extension moment</li> <li> <p>Anatomical meaning: Positive values assist knee flexor muscles, negative values assist knee extensor muscles</p> </li> <li> <p>ankle_flexion_moment_[ipsi|contra]_Nm: Ankle dorsiflexion/plantarflexion moment</p> </li> <li>Positive: Ankle dorsiflexion moment (dorsiflexor muscles)</li> <li>Negative: Ankle plantarflexion moment (plantarflexor muscles)</li> <li>Anatomical meaning: Positive values assist dorsiflexor muscles, negative values assist plantarflexor muscles</li> </ul>"},{"location":"reference/standard_spec/units_and_conventions/#typical-biomechanical-values","title":"Typical Biomechanical Values","text":""},{"location":"reference/standard_spec/units_and_conventions/#reference-body-weight","title":"Reference Body Weight","text":"<ul> <li>Standard reference: 70kg adult</li> <li>Body weight force: 686N (70kg \u00d7 9.8 m/s\u00b2)</li> <li>Normalized units: 9.8 N/kg</li> </ul>"},{"location":"reference/standard_spec/units_and_conventions/#ground-reaction-force-ranges","title":"Ground Reaction Force Ranges","text":"<ul> <li>Walking GRF ranges: 0.8-1.5 BW (8-15 N/kg) for vertical, \u00b10.3 BW (\u00b13 N/kg) for horizontal</li> <li>Running GRF ranges: 2.0-2.9 BW (20-28 N/kg) for vertical, higher horizontal forces</li> </ul> <p>Typical values by direction: - vertical_grf_N_kg: 8-15 N/kg walking, 20-28 N/kg running - ap_grf_N_kg: -3 to +3 N/kg walking, -8 to +12 N/kg running - ml_grf_N_kg: \u00b11 N/kg walking, \u00b12.5 N/kg running</p>"},{"location":"reference/standard_spec/units_and_conventions/#joint-moment-ranges-peak-values","title":"Joint Moment Ranges (Peak Values)","text":"<ul> <li>Hip: 0.8-1.1 Nm/kg</li> <li>Knee: 0.4-0.6 Nm/kg</li> <li>Ankle: 1.2-1.6 Nm/kg</li> </ul>"},{"location":"reference/standard_spec/units_and_conventions/#reference-table","title":"Reference Table","text":"Joint Motion Positive Zero Reference Range Hip Flexion Forward Vertical thigh -20\u00b0 to 110\u00b0 Hip Adduction Toward midline Neutral -20\u00b0 to 30\u00b0 Knee Flexion Bending Full extension 0\u00b0 to 140\u00b0 Knee Adduction Valgus Neutral -10\u00b0 to 15\u00b0 Ankle Flexion Dorsiflexion Foot flat -25\u00b0 to 40\u00b0 Ankle Inversion Toward midline Neutral -15\u00b0 to 20\u00b0"},{"location":"reference/standard_spec/units_and_conventions/#implementation","title":"Implementation","text":"<p>Dataset Compatibility: - OpenSim models \u2713 - AddBiomechanics dataset \u2713 - Standard gait analysis literature \u2713</p> <p>Conversion Requirements: 1. Identify source convention 2. Apply transformation to OpenSim standard 3. Validate using anatomical limits 4. Document in dataset README</p> <p>These conventions ensure consistency across datasets and validation systems.</p>"},{"location":"reference/standard_spec/validation_expectations_kinematic/","title":"Kinematic Validation Expectations Specification","text":"<p>Single Source of Truth for Biomechanically Accurate Kinematic Validation Rules</p> <p>This document provides biomechanically verified kinematic validation ranges (joint angles) based on published gait analysis literature. The specification uses a modern phase system (0%, 25%, 50%, 75%) with contralateral offset logic for optimal validation efficiency.</p> <p>\ud83d\udcca Related: See validation_expectations_kinetic.md for kinetic validation rules (forces and moments).</p> <p>\ud83d\udccb Version Information: See ../development/validation_expectations_changelog.md for detailed version history and changes. \ud83c\udfa8 Image Generation: See ../development/kinematic_visualization_guide.md for generating validation images.</p> <p>\ud83d\udd04 Plot Generation: </p> <p>One-click regeneration (VS Code): <code>Ctrl+Shift+P</code> \u2192 <code>Tasks: Run Task</code> \u2192 <code>\ud83d\udd04 Regenerate Kinematic Plots</code></p> <p>GitHub Actions: </p> <p>Manual commands: <pre><code>python3 source/validation/generate_validation_plots.py\n# Or for specific tasks:\npython3 source/validation/generate_validation_plots.py --tasks level_walking incline_walking\n# Or for specific plot types:\npython3 source/validation/generate_validation_plots.py --forward-kinematic-only\npython3 source/validation/generate_validation_plots.py --filters-only\n</code></pre></p>"},{"location":"reference/standard_spec/validation_expectations_kinematic/#validation-tables","title":"Validation Tables","text":"<p>\ud83e\udd16 AUTOMATED TUNING - DECLINE_WALKING</p> <p>\u26a0\ufe0f  Data-Driven Ranges: These validation ranges were automatically generated using statistical analysis.</p> <p>\ud83d\udcca Source: <code>umich_2021_phase.parquet</code> | \ud83d\udcc8 Method: 95% Percentile | \ud83d\udd52 Generated: 2025-06-12 12:32:24</p>"},{"location":"reference/standard_spec/validation_expectations_kinematic/#task-decline_walking","title":"Task: decline_walking","text":"<p>Phase-Specific Range Validation (Ipsilateral Leg Only):</p> <p>| Variable | | 0% | | | 25% | | | 50% | | | 75% | | | 95% | | |Units|Notes| |:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|:---:|:---| | | Min | Max | | Min | Max | | Min | Max | | Min | Max | | Min | Max | | | |</p> <p>Contralateral Offset Logic: - Phase 0% ipsilateral (heel strike) = Phase 50% contralateral (toe-off) - Phase 25% ipsilateral (mid-stance) = Phase 75% contralateral (mid-swing) - Phase 50% ipsilateral (toe-off) = Phase 0% contralateral (heel strike) - Phase 75% ipsilateral (mid-swing) = Phase 25% contralateral (mid-stance)</p> <p>Forward Kinematics Range Visualization:</p> Phase 0% (Heel Strike) Phase 25% (Mid-Stance) Phase 50% (Toe-Off) Phase 75% (Mid-Swing) <p>Filters by Phase Validation:</p> <p></p> <p>\ud83e\udd16 AUTOMATED TUNING - INCLINE_WALKING</p> <p>\u26a0\ufe0f  Data-Driven Ranges: These validation ranges were automatically generated using statistical analysis.</p> <p>\ud83d\udcca Source: <code>umich_2021_phase.parquet</code> | \ud83d\udcc8 Method: 95% Percentile | \ud83d\udd52 Generated: 2025-06-12 12:32:25</p>"},{"location":"reference/standard_spec/validation_expectations_kinematic/#task-incline_walking","title":"Task: incline_walking","text":"<p>Phase-Specific Range Validation (Ipsilateral Leg Only):</p> <p>| Variable | | 0% | | | 25% | | | 50% | | | 75% | | | 95% | | |Units|Notes| |:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|:---:|:---| | | Min | Max | | Min | Max | | Min | Max | | Min | Max | | Min | Max | | | |</p> <p>Contralateral Offset Logic: - Phase 0% ipsilateral (heel strike) = Phase 50% contralateral (toe-off) - Phase 25% ipsilateral (mid-stance) = Phase 75% contralateral (mid-swing) - Phase 50% ipsilateral (toe-off) = Phase 0% contralateral (heel strike) - Phase 75% ipsilateral (mid-swing) = Phase 25% contralateral (mid-stance)</p> <p>Forward Kinematics Range Visualization:</p> Phase 0% (Heel Strike) Phase 25% (Mid-Stance) Phase 50% (Toe-Off) Phase 75% (Mid-Swing) <p>Filters by Phase Validation:</p> <p></p> <p>\ud83e\udd16 AUTOMATED TUNING - LEVEL_WALKING</p> <p>\u26a0\ufe0f  Data-Driven Ranges: These validation ranges were automatically generated using statistical analysis.</p> <p>\ud83d\udcca Source: <code>umich_2021_phase.parquet</code> | \ud83d\udcc8 Method: 95% Percentile | \ud83d\udd52 Generated: 2025-06-12 12:32:25</p>"},{"location":"reference/standard_spec/validation_expectations_kinematic/#task-level_walking","title":"Task: level_walking","text":"<p>Phase-Specific Range Validation (Ipsilateral Leg Only):</p> <p>| Variable | | 0% | | | 25% | | | 50% | | | 75% | | | 95% | | |Units|Notes| |:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|:---:|:---| | | Min | Max | | Min | Max | | Min | Max | | Min | Max | | Min | Max | | | |</p> <p>Contralateral Offset Logic: - Phase 0% ipsilateral (heel strike) = Phase 50% contralateral (toe-off) - Phase 25% ipsilateral (mid-stance) = Phase 75% contralateral (mid-swing) - Phase 50% ipsilateral (toe-off) = Phase 0% contralateral (heel strike) - Phase 75% ipsilateral (mid-swing) = Phase 25% contralateral (mid-stance)</p> <p>Forward Kinematics Range Visualization:</p> Phase 0% (Heel Strike) Phase 25% (Mid-Stance) Phase 50% (Toe-Off) Phase 75% (Mid-Swing) <p>Filters by Phase Validation:</p> <p></p>"},{"location":"reference/standard_spec/validation_expectations_kinematic/#joint-validation-range-summary","title":"Joint Validation Range Summary","text":"<p>The filters by phase validation plots have been moved to their corresponding individual task sections above. Each task now includes both forward kinematics range visualizations and filters by phase validation plots.</p> <p>Reading the Filters by Phase Plots: - X-axis: Movement phase progression (0%, 25%, 50%, 75%) - Y-axis: Joint angle values in radians (left) and degrees (right) - Layout: 3 rows (hip, knee, ankle) \u00d7 2 columns (left leg, right leg) - Bounding Boxes: Colored rectangles show valid range for each phase - Connecting Lines:    - Red line with circles: Minimum acceptable values across phases   - Blue line with circles: Maximum acceptable values across phases - Shaded Area: Filled region between min/max shows complete acceptable range - Value Labels: Degree values shown at min/max points for easy reference - Color Coding:    - Red: Hip flexion angles   - Teal: Knee flexion angles   - Blue: Ankle flexion angles</p> <p>These plots make it easy to visualize how joint angle requirements change throughout the movement cycle and compare bilateral coordination patterns between left and right legs.</p>"},{"location":"reference/standard_spec/validation_expectations_kinematic/#pattern-definitions","title":"Pattern Definitions","text":"<p>Temporal Patterns: - <code>peak_at_X</code>: Maximum value occurs at phase X% - <code>valley_at_X</code>: Minimum value occurs at phase X% - <code>increasing</code>: Monotonic increase throughout phase range - <code>decreasing</code>: Monotonic decrease throughout phase range - <code>negative_to_positive</code>: Crosses zero from negative to positive - <code>U_shaped</code>: Decreases then increases (valley in middle) - <code>inverted_U</code>: Increases then decreases (peak in middle)</p> <p>Amplitude Patterns: - <code>near_zero</code>: Values close to zero throughout - <code>predominantly_negative</code>: Mostly negative values - <code>predominantly_positive</code>: Mostly positive values - <code>variable</code>: High variability, no clear pattern - <code>controlled_motion</code>: Smooth, controlled changes</p>"},{"location":"reference/standard_spec/validation_expectations_kinematic/#parser-usage","title":"Parser Usage","text":"<p>This markdown file can be parsed programmatically using the companion parser:</p> <pre><code>from validation_markdown_parser import ValidationMarkdownParser\n\nparser = ValidationMarkdownParser()\nvalidation_rules = parser.parse_file('validation_expectations.md')\n\n# Get rules for specific task\nlevel_walking_rules = validation_rules['level_walking']\n\n# Validate data against rules\nresults = parser.validate_data(data, 'level_walking')\n</code></pre>"},{"location":"reference/standard_spec/validation_expectations_kinematic/#maintenance-guidelines","title":"Maintenance Guidelines","text":"<ol> <li>Adding New Tasks: Follow the exact table format</li> <li>Variable Names: Must match dataset column names exactly</li> <li>Phase Ranges: Use format \"start-end\" (e.g., \"0-100\", \"45-55\")  </li> <li>Patterns: Use predefined pattern names from Pattern Definitions</li> <li>Units: Must match standard specification units</li> <li>Tolerance: Percentage (e.g., \"15%\") or absolute values</li> </ol>"},{"location":"reference/standard_spec/validation_expectations_kinematic/#references","title":"References","text":"<p>These ranges are verified against: 1. Perry, J., &amp; Burnfield, J. M. (2010). Gait Analysis: Normal and Pathological Function (2<sup>nd</sup> ed.) 2. Winter, D. A. (2009). Biomechanics and Motor Control of Human Movement (4<sup>th</sup> ed.) 3. Whittle, M. W. (2007). Gait Analysis: An Introduction (4<sup>th</sup> ed.) 4. Nordin, M., &amp; Frankel, V. H. (2012). Basic Biomechanics of the Musculoskeletal System (4<sup>th</sup> ed.) 5. Schoenfeld, B. J. (2010). Squatting kinematics and kinetics and their application to exercise performance 6. Cook, G. (2010). Movement: Functional Movement Systems 7. Various peer-reviewed sources from 2024 literature searches</p> <p>\ud83d\udccb Version History: See validation_expectations_changelog.md for complete version history and detailed change documentation. \ud83e\uddea Parser Testing: See test_validation_parser.md for markdown parser unit test data.</p>"},{"location":"reference/standard_spec/validation_expectations_kinetic/","title":"Kinetic Validation Expectations Specification","text":"<p>Single Source of Truth for Biomechanically Accurate Kinetic Validation Rules</p> <p>This document provides biomechanically verified kinetic validation ranges (forces and moments) based on published gait analysis literature. The specification uses a modern phase system (0%, 25%, 50%, 75%) with contralateral offset logic for optimal validation efficiency.</p> <p>\ud83d\udcca Related: See validation_expectations_kinematic.md for kinematic validation rules (joint angles).</p> <p>\ud83d\udccb Version Information: See validation_expectations_changelog.md for detailed version history and changes. \ud83d\udd2c Research Status: REQUIRES LITERATURE RESEARCH - Kinetic ranges need verification against published biomechanics literature.</p> <p>\ud83d\udd04 Plot Generation: </p> <p>One-click regeneration (VS Code): <code>Ctrl+Shift+P</code> \u2192 <code>Tasks: Run Task</code> \u2192 <code>\ud83d\udd04 Regenerate Kinetic Plots</code></p> <p>GitHub Actions: </p> <p>Manual command: <pre><code>python3 source/validation/generate_validation_plots.py --filters-only\n</code></pre></p>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#validation-tables","title":"Validation Tables","text":"<p>\ud83e\udd16 AUTOMATED TUNING - DECLINE_WALKING</p> <p>\u26a0\ufe0f  Data-Driven Ranges: These validation ranges were automatically generated using statistical analysis.</p> <p>\ud83d\udcca Source: <code>umich_2021_phase.parquet</code> | \ud83d\udcc8 Method: 95% Percentile | \ud83d\udd52 Generated: 2025-06-12 12:33:33</p>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#task-decline_walking","title":"Task: decline_walking","text":"<p>Phase-Specific Range Validation (Ipsilateral Leg Only):</p> <p>| Variable | | 0% | | | 25% | | | 50% | | | 75% | | |Units|Notes| |:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|:---:|:---| | | Min | Max | | Min | Max | | Min | Max | | Min | Max | | | |</p> <p>Filters by Phase Validation:</p> <p></p> <p>\ud83e\udd16 AUTOMATED TUNING - INCLINE_WALKING</p> <p>\u26a0\ufe0f  Data-Driven Ranges: These validation ranges were automatically generated using statistical analysis.</p> <p>\ud83d\udcca Source: <code>umich_2021_phase.parquet</code> | \ud83d\udcc8 Method: 95% Percentile | \ud83d\udd52 Generated: 2025-06-12 12:33:33</p>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#task-incline_walking","title":"Task: incline_walking","text":"<p>Phase-Specific Range Validation (Ipsilateral Leg Only):</p> <p>| Variable | | 0% | | | 25% | | | 50% | | | 75% | | |Units|Notes| |:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|:---:|:---| | | Min | Max | | Min | Max | | Min | Max | | Min | Max | | | |</p> <p>Filters by Phase Validation:</p> <p></p> <p>\ud83e\udd16 AUTOMATED TUNING - LEVEL_WALKING</p> <p>\u26a0\ufe0f  Data-Driven Ranges: These validation ranges were automatically generated using statistical analysis.</p> <p>\ud83d\udcca Source: <code>umich_2021_phase.parquet</code> | \ud83d\udcc8 Method: 95% Percentile | \ud83d\udd52 Generated: 2025-06-12 12:33:33</p>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#task-level_walking","title":"Task: level_walking","text":"<p>Phase-Specific Range Validation (Ipsilateral Leg Only):</p> <p>| Variable | | 0% | | | 25% | | | 50% | | | 75% | | |Units|Notes| |:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|---:|:---:|:---|:---:|:---| | | Min | Max | | Min | Max | | Min | Max | | Min | Max | | | |</p> <p>Filters by Phase Validation:</p> <p></p>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#research-requirements","title":"Research Requirements","text":""},{"location":"reference/standard_spec/validation_expectations_kinetic/#literature-sources-needed","title":"Literature Sources Needed","text":"<ol> <li>Ground Reaction Forces:</li> <li>Normal walking GRF patterns and magnitudes</li> <li>Incline/decline walking force modifications</li> <li>Running vs walking force differences</li> <li> <p>Stair climbing/descending force patterns</p> </li> <li> <p>Joint Moments:</p> </li> <li>Hip, knee, ankle moment patterns during gait</li> <li>Task-specific moment modifications</li> <li>Age and anthropometric scaling factors</li> <li> <p>Pathological vs normal moment patterns</p> </li> <li> <p>Power Analysis:</p> </li> <li>Joint power generation and absorption patterns</li> <li>Energy transfer between joints</li> <li>Efficiency metrics across tasks</li> </ol>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#key-research-questions","title":"Key Research Questions","text":"<ol> <li>What are typical GRF magnitudes relative to body weight?</li> <li>How do joint moments scale with anthropometric measures?</li> <li>What are the phase-specific patterns for different locomotion tasks?</li> <li>How do kinetic patterns differ between ipsilateral and contralateral legs?</li> <li>What are acceptable ranges for healthy adult populations?</li> </ol>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#recommended-literature-sources","title":"Recommended Literature Sources","text":"<ul> <li>Winter, D. A. (2009). Biomechanics and Motor Control of Human Movement</li> <li>Perry, J., &amp; Burnfield, J. M. (2010). Gait Analysis: Normal and Pathological Function</li> <li>Robertson, D. G. E., et al. (2013). Research Methods in Biomechanics</li> <li>Journal of Biomechanics - recent gait analysis studies</li> <li>Gait &amp; Posture - locomotion-specific research</li> <li>IEEE Transactions on Biomedical Engineering - force platform studies</li> </ul>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#parser-usage","title":"Parser Usage","text":"<p>This markdown file can be parsed programmatically using the same parser as kinematic validation:</p> <pre><code>from validation_markdown_parser import ValidationMarkdownParser\n\nparser = ValidationMarkdownParser()\nkinetic_rules = parser.parse_file('validation_expectations_kinetic.md')\n\n# Get rules for specific task\nlevel_walking_kinetics = kinetic_rules['level_walking']\n\n# Validate kinetic data against rules\nresults = parser.validate_data(kinetic_data, 'level_walking')\n</code></pre>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#maintenance-guidelines","title":"Maintenance Guidelines","text":"<ol> <li>Adding New Tasks: Follow the exact table format used for kinematics</li> <li>Variable Names: Must match dataset column names exactly</li> <li>Phase Ranges: Use format \"start-end\" (e.g., \"0-100\", \"45-55\")  </li> <li>Units: Must match standard specification units (N, Nm, W)</li> <li>Research Verification: All ranges must be verified against literature before production use</li> </ol>"},{"location":"reference/standard_spec/validation_expectations_kinetic/#references","title":"References","text":"<p>\u26a0\ufe0f PLACEHOLDER: Literature references need to be added after research completion</p> <p>These ranges will be verified against: 1. Winter, D. A. (2009). Biomechanics and Motor Control of Human Movement (4<sup>th</sup> ed.) 2. Perry, J., &amp; Burnfield, J. M. (2010). Gait Analysis: Normal and Pathological Function (2<sup>nd</sup> ed.) 3. Robertson, D. G. E., et al. (2013). Research Methods in Biomechanics (2<sup>nd</sup> ed.) 4. [Additional peer-reviewed sources to be added after research]</p> <p>\ud83d\udccb Version History: See validation_expectations_changelog.md for complete version history and detailed change documentation. \ud83e\uddea Parser Testing: See test_validation_parser.md for markdown parser unit test data.</p>"},{"location":"tutorials/","title":"Tutorials","text":"<p>Step-by-step guides for using standardized locomotion datasets.</p> <p>Quick Start: Python \u2022 MATLAB \u2022 Test Status</p>"},{"location":"tutorials/#getting-started","title":"Getting Started","text":"<p>Python Tutorial - python/getting_started_python.md: - Load and analyze Parquet datasets - Basic data operations and filtering - Quick plotting and visualization</p> <p>MATLAB Tutorial - matlab/getting_started_matlab.md: - Load Parquet files in MATLAB - Data manipulation and analysis - Plotting and visualization examples</p>"},{"location":"tutorials/#advanced-usage","title":"Advanced Usage","text":"<p>Python Library - python/library_tutorial_python.md: - LocomotionData class advanced features - 3D array operations for multi-cycle analysis - Efficient data reshaping and processing</p> <p>MATLAB Library - matlab/library_tutorial_matlab.md: - LocomotionData class comprehensive guide - Advanced analysis and visualization - Integration with existing MATLAB workflows</p>"},{"location":"tutorials/#test-files-and-examples","title":"Test Files and Examples","text":"<p>Sample Data - test_files/: - <code>locomotion_data.csv</code> - Sample dataset for tutorials - <code>task_info.csv</code> - Task metadata examples - Example plots: <code>knee_angle_by_task.png</code>, <code>knee_angle_incline.png</code></p> <p>Testing Status - TESTING_STATUS.md: - Current testing coverage for tutorials - Known issues and limitations - Testing procedure documentation</p> <p>Learn to effectively use standardized biomechanical datasets for reproducible research.</p>"},{"location":"tutorials/TESTING_STATUS/","title":"Tutorial Testing Status","text":""},{"location":"tutorials/TESTING_STATUS/#summary","title":"Summary","text":"<p>All tutorial code has been verified to ensure it will run correctly.</p>"},{"location":"tutorials/TESTING_STATUS/#python-tutorial-testing","title":"Python Tutorial Testing","text":"<ul> <li>Status: \u2705 PASSED</li> <li>Test File: <code>python/test_library.py</code></li> <li>Results: All tests pass successfully</li> <li>Data loading and 3D array operations work correctly</li> <li>Validation functions operate as expected</li> <li>Statistical calculations produce correct results</li> <li>Plotting functions generate valid figures</li> <li>Data merging functionality works properly</li> <li>Error handling is robust</li> </ul>"},{"location":"tutorials/TESTING_STATUS/#matlab-tutorial-testing","title":"MATLAB Tutorial Testing","text":"<ul> <li>Status: \u2705 VERIFIED (Syntax and Structure)</li> <li>Test File: <code>matlab/test_library_tutorial.m</code></li> <li>Verification Methods:</li> <li>Syntax checker (<code>matlab/check_syntax.py</code>) - Created to verify MATLAB code structure</li> <li>Comprehensive test script - Tests all library functionality</li> <li>Path verification - All file paths confirmed correct after reorganization</li> </ul>"},{"location":"tutorials/TESTING_STATUS/#matlab-test-coverage","title":"MATLAB Test Coverage","text":"<p>The test script verifies: 1. Basic data loading and object creation 2. 3D array creation and manipulation 3. Data validation functionality 4. Statistical calculations 5. ROM (Range of Motion) calculations 6. Data merging operations 7. All plotting functions (time series, phase patterns, task comparison) 8. Functional interface (non-OOP approach) 9. Multi-subject data handling 10. Error handling and edge cases</p>"},{"location":"tutorials/TESTING_STATUS/#file-path-verification","title":"File Path Verification","text":"<p>All file paths in both tutorials have been verified: - Library paths: <code>../../../source/lib/python</code> and <code>../../../source/lib/matlab</code> - Test data paths: <code>../test_files/</code> - All paths are correct relative to the new directory structure</p>"},{"location":"tutorials/TESTING_STATUS/#running-the-tests","title":"Running the Tests","text":""},{"location":"tutorials/TESTING_STATUS/#python","title":"Python","text":"<pre><code>cd docs/tutorials/python\npython3 test_library.py\n</code></pre>"},{"location":"tutorials/TESTING_STATUS/#matlab","title":"MATLAB","text":"<pre><code>cd('docs/tutorials/matlab')\ntest_library_tutorial\n</code></pre>"},{"location":"tutorials/TESTING_STATUS/#notes","title":"Notes","text":"<ul> <li>Python tests run successfully with simulated data</li> <li>MATLAB test script created with comprehensive coverage</li> <li>Both tutorials include proper error handling</li> <li>All functionality from the original tutorials is preserved in the libraries</li> </ul>"},{"location":"tutorials/matlab/getting_started_matlab/","title":"Getting Started with MATLAB for Locomotion Data Analysis","text":"<p>This tutorial provides a basic guide on how to work with standardized locomotion data using MATLAB. We'll cover common tasks such as joining different data sources (e.g., primary data and task data), filtering by specific criteria, and performing basic analyses like calculating averages for features.</p> <p>MATLAB's built-in table data type and functions are well-suited for these operations.</p> <p>Running the Examples/Test Script:</p> <p>The code examples in this tutorial are designed to match the <code>test_matlab_tutorial.m</code> script located in the <code>docs/tutorials/test_files/</code> directory. To run these examples: 1.  Ensure you have <code>locomotion_data.csv</code> and <code>task_info.csv</code> in the same directory as your script (or the test script), or that your MATLAB Current Folder is set to this directory. You can copy the CSV files from <code>docs/tutorials/test_files/</code> if needed. 2.  Open MATLAB and navigate its Current Folder to the directory containing the script and CSV files. 3.  Run the script from the MATLAB command window: <code>test_matlab_tutorial</code> (or your script's name).</p> <p>The test script wraps all operations in a <code>try...catch ME ... end</code> block to handle errors. For clarity, this tutorial presents code in separate blocks where logical, but aims to reflect the test script's flow.</p>"},{"location":"tutorials/matlab/getting_started_matlab/#1-loading-your-data","title":"1. Loading Your Data","text":"<p>Let's assume your standardized locomotion data is stored in CSV files. MATLAB can easily import this data into <code>table</code> objects.</p> <p>File 1: <code>locomotion_data.csv</code></p> <p>Create a file named <code>locomotion_data.csv</code> with the following content (this is the same file used in the Python tutorial):</p> <pre><code>time_s,step_id,subject_id,task_id,knee_flexion_angle_rad,hip_flexion_angle_rad,ankle_flexion_angle_rad,cop_x_m,cop_y_m,vertical_grf_N\n0.01,1,P001,P001_T01,0.178,0.089,0.052,0.10,0.05,650.2\n0.02,1,P001,P001_T01,0.218,0.108,0.063,0.11,0.06,680.5\n0.03,1,P001,P001_T01,0.264,0.122,0.075,0.12,0.07,700.3\n0.04,2,P001,P001_T02,0.354,0.183,0.087,0.15,0.10,720.8\n0.05,2,P001,P001_T02,0.384,0.197,0.093,0.16,0.11,750.2\n0.06,2,P001,P001_T02,0.447,0.224,0.105,0.17,0.12,760.5\n0.07,3,P001,P001_T01,0.155,0.075,0.045,0.09,0.04,620.1\n0.08,3,P001,P001_T01,0.182,0.087,0.055,0.10,0.05,640.3\n0.09,3,P001,P001_T01,0.230,0.107,0.068,0.11,0.06,660.7\n0.10,3,P001,P001_T01,0.279,0.131,0.079,0.12,0.07,680.9\n</code></pre> <p>File 2: <code>task_info.csv</code></p> <p>Create a file named <code>task_info.csv</code> with the following content (also the same as in the Python tutorial):</p> <pre><code>step_id,task_id,task_name,subject_id,ground_inclination_deg,walking_speed_m_s\n1,P001_T01,level_walking,P001,0,1.2\n2,P001_T02,incline_walking,P001,5,1.5\n3,P001_T01,level_walking,P001,0,1.2\n</code></pre> <p>Now, let's load this data using <code>readtable()</code>:</p> <pre><code>% Define file paths (relative to the script's location or MATLAB Current Folder)\nlocomotionDataFile = 'locomotion_data.csv';\ntaskInfoFile = 'task_info.csv';\n\nif exist(locomotionDataFile, 'file') &amp;&amp; exist(taskInfoFile, 'file')\n    tblLocomotion = readtable(locomotionDataFile);\n    tblTasks = readtable(taskInfoFile);\n\n    disp('Locomotion Data (first 3 rows):');\n    disp(tblLocomotion(1:3,:)); % Display first 3 rows, matching test script\n    disp('Task Information:');\n    disp(tblTasks); % Display all task info (it's small), matching test script\nelse\n    disp('Error: Ensure ''''locomotion_data.csv'''' and ''''task_info.csv'''' exist in the MATLAB Current Folder or provide correct paths.');\n    % Create empty tables to allow the rest of the script to run without error\n    tblLocomotion = table(); \n    tblTasks = table();\nend\n</code></pre> <p>This setup provides <code>tblLocomotion</code> with time-series data and <code>tblTasks</code> with information about the tasks performed.</p>"},{"location":"tutorials/matlab/getting_started_matlab/#2-combining-locomotion-data-with-task-data-outer-join","title":"2. Combining Locomotion Data with Task Data (Outer Join)","text":"<p>To analyze locomotion features in the context of specific tasks, you'll combine these tables. An outer join keeps all rows from both tables, filling in missing values with appropriate fill values (e.g., <code>NaN</code> for numeric, <code>&lt;missing&gt;</code> for categorical/string) where a match isn't found. In MATLAB, <code>outerjoin</code> is used for this.</p> <pre><code>% Convert relevant columns to categorical for join operation consistency and performance\n% This should be done if these columns are not already categorical or if there are type mismatches.\n% The test script applies this to both tables before joining.\ntblLocomotion.step_id = categorical(tblLocomotion.step_id);\ntblTasks.step_id = categorical(tblTasks.step_id);\ntblLocomotion.task_id = categorical(tblLocomotion.task_id);\ntblTasks.task_id = categorical(tblTasks.task_id);\ntblLocomotion.subject_id = categorical(tblLocomotion.subject_id);\ntblTasks.subject_id = categorical(tblTasks.subject_id);\n\n% Perform an outer join on common keys\ntblCombined = outerjoin(tblLocomotion, tblTasks, 'Keys', {'step_id', 'task_id', 'subject_id'});\n\ndisp('Combined Data (first 3 rows):');\ndisp(tblCombined(1:3,:)); % Display first 3 rows, matching test script\n</code></pre> <p>Why an outer join? *   You might have locomotion data that wasn't assigned a task (it will still be included). *   You might have task definitions for which no locomotion data was recorded (they will also be included). In many cases, a <code>leftjoin</code> or <code>innerjoin</code> might be more appropriate depending on your specific data and analysis goals.</p>"},{"location":"tutorials/matlab/getting_started_matlab/#3-filtering-for-a-particular-task","title":"3. Filtering for a Particular Task","text":"<p>Once your data is combined, you can easily filter it to focus on a specific task. For example, let's filter the data for the 'incline_walking' task.</p> <pre><code>% Filter for a specific task, e.g., 'incline_walking'\n% Ensure task_name is a cell array of strings or a string array for strcmp\n% The test script handles potential type differences for task_name before comparison.\nif iscellstr(tblCombined.task_name) || isstring(tblCombined.task_name) % Check added from test script\n    is_incline_walking = strcmp(tblCombined.task_name, 'incline_walking');\nelse\n    % Fallback for other types, though direct comparison might work if it's categorical and matches\n    is_incline_walking = tblCombined.task_name == 'incline_walking'; \nend\ntblInclineWalking = tblCombined(is_incline_walking, :);\n\ndisp('Data for 'incline_walking' task:');\ndisp(tblInclineWalking);\n\n% You can also filter by other criteria, e.g., subject_id\n% is_subject_p001 = strcmp(tblCombined.subject_id, 'P001'); % Assuming subject_id is categorical or string\n% tblSubjectP001 = tblCombined(is_subject_p001, :);\n</code></pre> <p>This allows you to isolate the data segments relevant to your particular research question or analysis.</p>"},{"location":"tutorials/matlab/getting_started_matlab/#4-phase-based-averaging-for-gait-analysis","title":"4. Phase-Based Averaging for Gait Analysis","text":"<p>A common operation in biomechanics is to normalize gait cycles to 0-100% phase and then generate average curves. This allows for comparing gait patterns regardless of differences in cycle duration.</p> <p>Example: Averaging knee angle across steps by phase percentage</p> <pre><code>% For demonstration, add a phase column (0-100%) to tblLocomotion\n% In a real dataset, this might come from a separate phase-normalized data file.\ntblWithPhaseDemo = tblLocomotion; % Use a new variable to avoid confusion with later steps in test script\ntblWithPhaseDemo.phase_ = zeros(height(tblLocomotion), 1);\n\nuniqueStepIds = unique(tblLocomotion.step_id);\nfor i = 1:length(uniqueStepIds)\n    stepId = uniqueStepIds(i);\n    stepMask = tblLocomotion.step_id == stepId;\n    numPoints = sum(stepMask);\n    tblWithPhaseDemo.phase_(stepMask) = linspace(0, 100, numPoints)';\nend\n\n% Create phase bins (e.g., 1% width)\nphaseBinWidth = 1; \nphaseBins = 0:phaseBinWidth:100; % Edges: 0, 1, ..., 100\nphaseBinCenters = phaseBins(1:end-1) + phaseBinWidth/2; % Centers: 0.5, 1.5, ..., 99.5\n\n% Assign each row to a phase bin based on its phase_ value\n% The test script uses a direct find approach for binning\ngetBin = @(phaseVal) find(phaseBins &lt;= phaseVal, 1, 'last');\nif isempty(tblWithPhaseDemo) || ~ismember('phase_', tblWithPhaseDemo.Properties.VariableNames)\n    disp('Skipping phase binning as tblWithPhaseDemo is empty or missing phase_ column');\n    tblWithPhaseDemo.phase_bin = zeros(height(tblWithPhaseDemo),0); % empty column\nelse\n    tblWithPhaseDemo.phase_bin = arrayfun(getBin, tblWithPhaseDemo.phase_);\nend\n\n% Calculate average knee angle for each phase bin across all steps in tblWithPhaseDemo\nphaseAveragesAllSteps = NaN(length(phaseBinCenters), 1); % Initialize with NaN\nif ismember('phase_bin', tblWithPhaseDemo.Properties.VariableNames)\n    for bin_idx = 1:length(phaseBinCenters)\n        % In the test script, the bin index in arrayfun corresponds to the label of the bin.\n        % For example, phase_bin = 1 corresponds to the first bin [0-1%)\n        binData = tblWithPhaseDemo(tblWithPhaseDemo.phase_bin == bin_idx, :);\n        if ~isempty(binData)\n            phaseAveragesAllSteps(bin_idx) = mean(binData.knee_flexion_angle_rad, 'omitnan');\n        end\n    end\nend\ndisp('Average knee flexion angle by phase (first 5 phases - all steps):');\nif length(phaseBinCenters) &gt;=5 &amp;&amp; length(phaseAveragesAllSteps) &gt;=5\n    phaseTableAllSteps = table(phaseBinCenters(1:5)', phaseAveragesAllSteps(1:5), 'VariableNames', {'Phase', 'AvgKneeFlexionAngle'});\n    disp(phaseTableAllSteps);\nelse\n    disp('Not enough data for first 5 phases table.');\nend\n\n% For by-task analysis, the test script re-initializes tblWithPhase from tblLocomotion,\n% adds phase and phase_bin, and then joins with tblTasks.\n\ntblWithPhaseForTask = tblLocomotion; % Start from original locomotion data\ntblWithPhaseForTask.phase_ = zeros(height(tblLocomotion), 1);\nfor i = 1:length(uniqueStepIds) % uniqueStepIds from earlier\n    stepId = uniqueStepIds(i);\n    stepMask = tblLocomotion.step_id == stepId;\n    numPoints = sum(stepMask);\n    tblWithPhaseForTask.phase_(stepMask) = linspace(0, 100, numPoints)';\nend\ntblWithPhaseForTask.phase_bin = arrayfun(getBin, tblWithPhaseForTask.phase_); % Use same getBin\n\n% Ensure key columns are categorical for the join\ntblWithPhaseForTask.step_id = categorical(tblWithPhaseForTask.step_id);\ntblWithPhaseForTask.task_id = categorical(tblWithPhaseForTask.task_id);\ntblWithPhaseForTask.subject_id = categorical(tblWithPhaseForTask.subject_id);\n% tblTasks should have its keys already categorical from Section 2\n\ntblPhaseWithTask = innerjoin(tblWithPhaseForTask, tblTasks, 'Keys', {'step_id', 'task_id', 'subject_id'});\n\nuniqueTaskNames = unique(tblPhaseWithTask.task_name);\nuniqueTaskNames = uniqueTaskNames(~ismissing(uniqueTaskNames)); % Remove missing values\n\ntaskPhaseAverages = NaN(length(phaseBinCenters), length(uniqueTaskNames)); % Initialize with NaN\n\nfor t_idx = 1:length(uniqueTaskNames)\n    currentTaskName = uniqueTaskNames(t_idx);\n    taskData = tblPhaseWithTask(strcmp(tblPhaseWithTask.task_name, currentTaskName), :);\n\n    if ismember('phase_bin', taskData.Properties.VariableNames)\n        for bin_idx = 1:length(phaseBinCenters)\n            % Again, bin_idx refers to the label assigned by getBin\n            binDataForTask = taskData(taskData.phase_bin == bin_idx, :);\n            if ~isempty(binDataForTask)\n                taskPhaseAverages(bin_idx, t_idx) = mean(binDataForTask.knee_flexion_angle_rad, 'omitnan');\n            end\n        end\n    end\nend\n\ndisp('Phase-based knee flexion angle by task (first 3 phases):');\nfor t_idx = 1:length(uniqueTaskNames)\n    disp(['Task: ', char(uniqueTaskNames(t_idx))]);\n    if length(phaseBinCenters) &gt;=3 &amp;&amp; size(taskPhaseAverages,1) &gt;=3\n        taskPhaseTable = table(phaseBinCenters(1:3)', taskPhaseAverages(1:3,t_idx), 'VariableNames', {'Phase', 'AvgKneeFlexionAngle'});\n        disp(taskPhaseTable);\n    else\n        disp('Not enough data for first 3 phases table for this task.');\n    end\nend\n</code></pre> <p>Note: The standardized data format may also provide data already indexed by phase (e.g., in Parquet files). MATLAB can read Parquet files using <code>parquetread()</code> (requires appropriate setup/addons if not built-in to your version).</p>"},{"location":"tutorials/matlab/getting_started_matlab/#5-basic-plotting","title":"5. Basic Plotting","text":"<p>Visualizing your data is essential. MATLAB has powerful built-in plotting capabilities. The test script saves plots to files.</p> <p>Example 5.1: Plotting a time-series feature for a specific task</p> <p>Let's plot the <code>knee_flexion_angle_rad</code> over time for the 'incline_walking' task and save it.</p> <pre><code>% Using tblInclineWalking from section 3\nif height(tblInclineWalking) &gt; 0\n    figure; % Create a new figure window\n    plot(tblInclineWalking.time_s, tblInclineWalking.knee_flexion_angle_rad, 'o-'); % Marker 'o', line '-'\n    xlabel('Time (s)');\n    ylabel('Knee Flexion Angle (rad)');\n    title('Knee Flexion Angle during Incline Walking');\n    grid on;\n    saveas(gcf, 'matlab_knee_angle_incline.png'); % Save the current figure\n    disp('Plot saved as ''matlab_knee_angle_incline.png''');\nelse\n    disp('No data available for 'incline_walking' task to plot.');\nend\n\n% Example 5.2: Comparing average feature values across tasks (Bar Plot)\n% Using taskPhaseAverages calculated in section 4\nif ~isempty(uniqueTaskNames) &amp;&amp; ~isempty(taskPhaseAverages)\n    figure;\n    % Calculate the overall average across all phases for each task for the bar plot\n    taskMeansForBarPlot = mean(taskPhaseAverages, 1, 'omitnan'); % Mean across 1st dim (phases)\n\n    if ~isempty(taskMeansForBarPlot)\n        bar(categorical(uniqueTaskNames), taskMeansForBarPlot);\n        xlabel('Task Name');\n        ylabel('Average Knee Flexion Angle (rad)');\n        title('Average Knee Flexion Angle by Task (mean of phase averages)');\n        xtickangle(45); % Rotate x-axis labels for readability\n        saveas(gcf, 'matlab_knee_angle_by_task.png');\n        disp('Plot saved as ''matlab_knee_angle_by_task.png''');\n    else\n        disp('No task means available for bar plot.');\n    end\nelse\n    disp('No task data available for bar plot (uniqueTaskNames or taskPhaseAverages is empty).');\nend\n</code></pre>"},{"location":"tutorials/matlab/getting_started_matlab/#6-calculating-derived-metrics","title":"6. Calculating Derived Metrics","text":"<p>Often, you'll need to compute new metrics from your existing data.</p> <p>Example 6.1: Calculate Knee Angle Range of Motion (RoM) per step</p> <p>Let's calculate the knee angle RoM for each step in the 'level_walking' task. RoM can be (max value - min value). We use <code>tblPhaseWithTask</code> from Section 4 which contains <code>task_name</code>.</p> <pre><code>% Using tblPhaseWithTask from section 4\n% Filter for level_walking task\nif iscellstr(tblPhaseWithTask.task_name) || isstring(tblPhaseWithTask.task_name)\n    is_level_walking = strcmp(tblPhaseWithTask.task_name, 'level_walking');\nelsel\n    is_level_walking = tblPhaseWithTask.task_name == 'level_walking';\nend\ntblLevelWalking = tblPhaseWithTask(is_level_walking, :);\n\nif height(tblLevelWalking) &gt; 0\n    % Define a helper function for range or use an anonymous function\n    rangefun = @(x) max(x) - min(x);\n\n    % Group by step_id and then calculate RoM for knee_flexion_angle_rad\n    % Ensure step_id is categorical for groupsummary\n    tblLevelWalking.step_id = categorical(tblLevelWalking.step_id);\n    % The test script does not rename 'fun1_Variable' but directly uses it or finds it.\n    kneeRomTable = groupsummary(tblLevelWalking, 'step_id', rangefun, 'knee_flexion_angle_rad');\n\n    % Find the automatically named RoM column (e.g., 'fun1_knee_flexion_angle_rad')\n    romColName = '';\n    varNames = kneeRomTable.Properties.VariableNames;\n    for k=1:length(varNames)\n        if contains(varNames{k}, 'fun') &amp;&amp; contains(varNames{k}, 'knee_flexion_angle_rad')\n            romColName = varNames{k};\n            break;\n        end\n    end\n\n    disp('Knee Flexion Angle ROM per step during 'level_walking':');\n    if ~isempty(romColName)\n        % Optionally rename for clarity if desired, but test script selects by found name\n        % kneeRomTable.Properties.VariableNames{romColName} = 'knee_flexion_angle_rom_rad';\n        disp(kneeRomTable(:, {'step_id', romColName})); \n    else\n        disp('Could not automatically find RoM column. Displaying with default name(s).');\n        disp(kneeRomTable); % Display the whole table if renaming/finding failed\n    end\nelse\n    disp('No data available for 'level_walking' task to calculate RoM.');\nend\n\n% Final message\ndisp('MATLAB tutorial operations completed (mimicking test script structure).');\n</code></pre>"},{"location":"tutorials/matlab/getting_started_matlab/#conclusion","title":"Conclusion","text":"<p>This tutorial covered basic operations for handling standardized locomotion data in MATLAB: *   Loading data into tables using <code>readtable</code>. *   Joining different tables using <code>outerjoin</code> (and <code>innerjoin</code> for specific analyses). *   Filtering tables based on task information or other criteria. *   Working with phase-normalized data for gait analysis, including binning and averaging. *   Creating basic plots using <code>plot</code> and <code>bar</code>, and saving them with <code>saveas</code>. *   Calculating derived metrics like Range of Motion using <code>groupsummary</code>.</p> <p>These examples provide a starting point. MATLAB offers extensive toolboxes for more advanced signal processing, statistics, and machine learning that can be applied to locomotion data.</p> <p>Refer to the MATLAB documentation for more comprehensive information. Consult your dataset's specific metadata and the Units &amp; Conventions documentation for details on column names, units, and conventions. </p>"},{"location":"tutorials/matlab/library_tutorial_matlab/","title":"MATLAB Library Tutorial for Locomotion Data Analysis","text":"<p>This tutorial demonstrates how to use the LocomotionData class and helper functions for efficient analysis of standardized locomotion data in MATLAB. The library provides both object-oriented and functional approaches for common operations.</p>"},{"location":"tutorials/matlab/library_tutorial_matlab/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have MATLAB with the following capabilities: - Statistics and Machine Learning Toolbox (for statistical functions) - Support for parquet files (<code>parquetread</code> function)</p>"},{"location":"tutorials/matlab/library_tutorial_matlab/#0-setup-and-path-configuration","title":"0. Setup and Path Configuration","text":"<pre><code>% Add library path to MATLAB path\naddpath('../../../source/lib/matlab');\n\n% Verify the library is available\nif exist('LocomotionData', 'class') == 8\n    fprintf('LocomotionData library loaded successfully\\n');\nelse\n    error('LocomotionData library not found. Check path.');\nend\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#1-loading-data","title":"1. Loading Data","text":""},{"location":"tutorials/matlab/library_tutorial_matlab/#using-the-locomotiondata-class","title":"Using the LocomotionData Class","text":"<pre><code>% Load phase-indexed parquet data\ndataPath = 'path/to/gtech_2023_phase.parquet';\nloco = LocomotionData(dataPath);\n\n% Or specify column names if different\n% loco = LocomotionData(dataPath, 'SubjectCol', 'subject_id', 'TaskCol', 'task_name');\n\n% View basic information\nfprintf('Loaded %d rows\\n', height(loco.data));\nfprintf('Subjects: %s\\n', strjoin(loco.subjects(1:min(5, length(loco.subjects))), ', '));\nfprintf('Tasks: %s\\n', strjoin(loco.tasks, ', '));\nfprintf('Features: %d biomechanical features\\n', length(loco.features));\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#using-helper-functions-alternative-approach","title":"Using Helper Functions (Alternative Approach)","text":"<pre><code>% Load data directly without class\ndataTable = parquetread(dataPath);\n\n% Define features of interest\nfeatures = {'hip_flexion_angle_right_rad', 'knee_flexion_angle_right_rad', 'ankle_flexion_angle_right_rad'};\n\n% Use standalone functions\n[data3D, featureNames] = efficientReshape3D(dataTable, 'AB01', 'normal_walk', features);\nfprintf('Extracted data shape: %d cycles x %d points x %d features\\n', ...\n        size(data3D, 1), size(data3D, 2), size(data3D, 3));\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#2-basic-data-exploration","title":"2. Basic Data Exploration","text":"<pre><code>% Display available data\nfprintf('\\nAvailable subjects:\\n');\nfor i = 1:length(loco.subjects)\n    fprintf('  %s\\n', loco.subjects{i});\nend\n\nfprintf('\\nAvailable tasks:\\n');\nfor i = 1:length(loco.tasks)\n    fprintf('  %s\\n', loco.tasks{i});\nend\n\nfprintf('\\nBiomechanical features (first 10):\\n');\nfor i = 1:min(10, length(loco.features))\n    fprintf('  %s\\n', loco.features{i});\nend\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#3-efficient-3d-data-access","title":"3. Efficient 3D Data Access","text":"<p>The core functionality converts phase-indexed data into 3D arrays:</p> <pre><code>% Select subject and task\nsubject = loco.subjects{1};\ntask = 'normal_walk';\n\n% Get 3D array for all features\n[data3D, featureNames] = loco.getCycles(subject, task);\n\nif ~isempty(data3D)\n    fprintf('Data shape: %d cycles x %d points x %d features\\n', ...\n            size(data3D, 1), size(data3D, 2), size(data3D, 3));\n    fprintf('Found %d gait cycles\\n', size(data3D, 1));\n    fprintf('Features extracted: %d\\n', length(featureNames));\nelse\n    fprintf('No data found for %s - %s\\n', subject, task);\nend\n\n% Extract specific features only\nangleFeatures = {'hip_flexion_angle_right_rad', 'knee_flexion_angle_right_rad', 'ankle_flexion_angle_right_rad'};\n[angleData, angleNames] = loco.getCycles(subject, task, angleFeatures);\nfprintf('Angle data shape: %d x %d x %d\\n', size(angleData));\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#4-data-validation","title":"4. Data Validation","text":"<p>Automatically validate cycles based on biomechanical constraints:</p> <pre><code>% Validate all cycles\nvalidMask = loco.validateCycles(subject, task);\nnValid = sum(validMask);\nnTotal = length(validMask);\n\nfprintf('Valid cycles: %d/%d (%.1f%%)\\n', nValid, nTotal, nValid/nTotal*100);\n\n% Get details on invalid cycles\ninvalidIndices = find(~validMask);\nif ~isempty(invalidIndices)\n    fprintf('Invalid cycle indices: %s\\n', mat2str(invalidIndices));\nend\n\n% Using helper function approach\nvalidMaskHelper = validateCycles(angleData, angleNames);\nfprintf('Helper function validation: %d/%d valid\\n', ...\n        sum(validMaskHelper), length(validMaskHelper));\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#5-statistical-analysis","title":"5. Statistical Analysis","text":""},{"location":"tutorials/matlab/library_tutorial_matlab/#mean-and-standard-deviation-patterns","title":"Mean and Standard Deviation Patterns","text":"<pre><code>% Get mean patterns for each feature\nmeanPatterns = loco.getMeanPatterns(subject, task, angleFeatures);\nstdPatterns = loco.getStdPatterns(subject, task, angleFeatures);\n\n% Display results for knee angle\nif isfield(meanPatterns, 'knee_flexion_angle_right_rad')\n    kneeMean = meanPatterns.knee_flexion_angle_right_rad;\n    fprintf('Knee angle: mean = %.3f rad, peak = %.3f rad\\n', ...\n            mean(kneeMean), max(kneeMean));\nend\n\n% Using helper functions\n[meanPatternsHelper, stdPatternsHelper] = calculateMeanPatterns(angleData, angleNames);\nfprintf('Mean patterns calculated using helper functions\\n');\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#range-of-motion-rom-analysis","title":"Range of Motion (ROM) Analysis","text":"<pre><code>% Calculate ROM per cycle\nromPerCycle = loco.calculateROM(subject, task, angleFeatures, true);\n\n% Calculate overall ROM\nromOverall = loco.calculateROM(subject, task, angleFeatures, false);\n\n% Display results\nfprintf('\\nRange of Motion Analysis:\\n');\nfor i = 1:length(angleFeatures)\n    feature = angleFeatures{i};\n    fieldName = matlab.lang.makeValidName(feature);\n\n    if isfield(romPerCycle, fieldName)\n        romCycles = romPerCycle.(fieldName);\n        romTotal = romOverall.(fieldName);\n\n        fprintf('%s:\\n', feature);\n        fprintf('  ROM per cycle: %.3f \u00b1 %.3f rad\\n', mean(romCycles), std(romCycles));\n        fprintf('  Overall ROM: %.3f rad\\n', romTotal);\n    end\nend\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#summary-statistics","title":"Summary Statistics","text":"<pre><code>% Get comprehensive summary statistics\nsummary = loco.getSummaryStatistics(subject, task, angleFeatures);\nfprintf('\\nSummary Statistics:\\n');\ndisp(summary);\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#6-outlier-detection","title":"6. Outlier Detection","text":"<pre><code>% Find outlier cycles with default threshold (2.0)\noutlierIndices = loco.findOutlierCycles(subject, task, angleFeatures);\nfprintf('Outlier cycles (&gt;2 std): %s\\n', mat2str(outlierIndices));\n\n% Find outliers with stricter threshold\nstrictOutliers = loco.findOutlierCycles(subject, task, angleFeatures, 1.5);\nfprintf('Outlier cycles (&gt;1.5 std): %s\\n', mat2str(strictOutliers));\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#7-data-merging","title":"7. Data Merging","text":"<p>Merge locomotion data with additional task information:</p> <pre><code>% Create example task data\ntaskData = table();\ntaskData.subject = {subject; subject};\ntaskData.task = {'normal_walk'; 'incline_walk'};\ntaskData.speed_m_s = [1.2; 1.0];\ntaskData.incline_deg = [0; 5];\n\n% Merge with locomotion data\nmergedData = loco.mergeWithTaskData(taskData, 'Type', 'inner');\nfprintf('Merged data shape: %d x %d\\n', height(mergedData), width(mergedData));\n\n% Show new columns\noriginalCols = loco.data.Properties.VariableNames;\nnewCols = setdiff(mergedData.Properties.VariableNames, originalCols);\nfprintf('New columns: %s\\n', strjoin(newCols, ', '));\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#8-visualization","title":"8. Visualization","text":"<p>The MATLAB library provides comprehensive plotting utilities for phase-normalized locomotion data with multiple visualization styles.</p>"},{"location":"tutorials/matlab/library_tutorial_matlab/#phase-pattern-plotting","title":"Phase Pattern Plotting","text":"<p>The library offers three main plotting styles for phase-normalized data:</p> <pre><code>% 1. Spaghetti plots - show all individual cycles\nloco.plotPhasePatterns(subject, task, angleFeatures, ...\n                      'PlotType', 'spaghetti', ...\n                      'SavePath', 'spaghetti_plot.png');\n\n% 2. Mean \u00b1 standard deviation plots with shaded confidence bands\nloco.plotPhasePatterns(subject, task, angleFeatures, ...\n                      'PlotType', 'mean', ...\n                      'SavePath', 'mean_patterns.png');\n\n% 3. Combined plots - both individual cycles and mean pattern overlay  \nloco.plotPhasePatterns(subject, task, angleFeatures, ...\n                      'PlotType', 'both', ...\n                      'SavePath', 'phase_patterns.png');\n</code></pre> <p>Plot Features: - Gray lines: Valid cycles passing biomechanical validation - Red lines: Invalid cycles failing validation criteria - Blue line: Mean pattern across valid cycles only - Blue shaded area: \u00b11 standard deviation (in 'mean' mode) - Automatic layout: Intelligent subplot arrangement (up to 3 columns)</p>"},{"location":"tutorials/matlab/library_tutorial_matlab/#task-comparison-plots","title":"Task Comparison Plots","text":"<p>Compare mean patterns across different tasks for the same subject:</p> <pre><code>% Compare multiple tasks for the same subject\navailableTasks = intersect(loco.tasks, {'normal_walk', 'incline_walk', 'decline_walk'});\nif length(availableTasks) &gt; 1\n    loco.plotTaskComparison(subject, availableTasks, angleFeatures, ...\n                           'SavePath', 'task_comparison.png');\nend\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#time-series-plotting","title":"Time Series Plotting","text":"<p>For time-indexed data analysis:</p> <pre><code>% Plot time series data (if time column exists)\nif any(strcmp('time_s', loco.data.Properties.VariableNames))\n    loco.plotTimeSeries(subject, task, angleFeatures, ...\n                       'TimeCol', 'time_s', ...\n                       'SavePath', 'time_series.png');\nend\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#custom-plotting-with-raw-data","title":"Custom Plotting with Raw Data","text":"<p>Access underlying 3D arrays for advanced custom visualizations:</p> <pre><code>% Get 3D data arrays\n[data3D, featureNames] = loco.getCycles(subject, task, angleFeatures);\nvalidMask = loco.validateCycles(subject, task, angleFeatures);\n\n% Create custom percentile plot\nfigure('Position', [100, 100, 1200, 300]);\nphaseX = linspace(0, 100, 150);\n\nfor i = 1:length(featureNames)\n    subplot(1, length(featureNames), i);\n\n    featData = data3D(:, :, i);\n    validData = featData(validMask, :);\n\n    % Calculate percentiles\n    p25 = prctile(validData, 25, 1);\n    p50 = prctile(validData, 50, 1);  % Median\n    p75 = prctile(validData, 75, 1);\n\n    % Plot with custom styling\n    fill([phaseX, fliplr(phaseX)], [p25, fliplr(p75)], ...\n         [0.7, 0.9, 1.0], 'FaceAlpha', 0.5, 'EdgeColor', 'none');\n    hold on;\n    plot(phaseX, p50, 'Color', [0, 0.2, 0.6], 'LineWidth', 2);\n\n    xlabel('Gait Cycle (%)');\n    ylabel(strrep(featureNames{i}, '_', ' '));\n    title(featureNames{i}, 'Interpreter', 'none');\n    xlim([0, 100]);\n    grid on;\n    legend({'IQR (25-75%)', 'Median'}, 'Location', 'best');\nend\n\nsgtitle(sprintf('%s - %s: Custom Percentile Analysis', subject, task));\nprint('custom_percentile_plot.png', '-dpng', '-r300');\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#alternative-helper-function-plotting","title":"Alternative Helper Function Plotting","text":"<p>For more control over plotting, use the helper functions directly:</p> <pre><code>% Using helper function for custom plotting\nvalidMask = loco.validateCycles(subject, task, angleFeatures);\n[data3D, featureNames] = loco.getCycles(subject, task, angleFeatures);\n\n% Create mosaic plot with custom options\nfig = figure('Position', [100, 100, 1000, 600]);\nplotMosaicData(data3D, featureNames, ...\n              'Title', sprintf('%s - %s', subject, task), ...\n              'ValidMask', validMask, ...\n              'PlotType', 'both', ...\n              'ColorScheme', 'custom', ...\n              'ShowLegend', true);\n\n% Save with high resolution\nprint(fig, 'custom_mosaic_plot.png', '-dpng', '-r300');\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#9-advanced-analysis-example","title":"9. Advanced Analysis Example","text":"<p>Complete workflow for analyzing gait variability:</p> <pre><code>function results = analyzeGaitVariability(loco, subject, task, features)\n    % Comprehensive gait variability analysis\n\n    fprintf('\\n=== Gait Variability Analysis: %s - %s ===\\n', subject, task);\n\n    % 1. Get data and validate\n    [data3D, featureNames] = loco.getCycles(subject, task, features);\n    if isempty(data3D)\n        fprintf('No data found\\n');\n        results = struct();\n        return;\n    end\n\n    validMask = loco.validateCycles(subject, task, features);\n    nValid = sum(validMask);\n    nTotal = length(validMask);\n\n    fprintf('Valid cycles: %d/%d (%.1f%%)\\n', nValid, nTotal, nValid/nTotal*100);\n\n    % 2. Calculate metrics for valid cycles only\n    validData = data3D(validMask, :, :);\n\n    % 3. Initialize results structure\n    results = struct();\n\n    % 4. Analyze each feature\n    for i = 1:length(featureNames)\n        feature = featureNames{i};\n        featData = validData(:, :, i);\n\n        % Mean pattern\n        meanPattern = mean(featData, 1);\n\n        % Cycle-to-cycle variability (CV)\n        cycleMeans = mean(featData, 2);\n        cv = std(cycleMeans) / mean(cycleMeans) * 100;\n\n        % Step-to-step variability at each phase\n        phaseCV = std(featData, 0, 1) ./ mean(featData, 1) * 100;\n        meanPhaseCV = mean(phaseCV);\n\n        % Range of motion\n        romValues = max(featData, [], 2) - min(featData, [], 2);\n        romCV = std(romValues) / mean(romValues) * 100;\n\n        % Store results\n        fieldName = matlab.lang.makeValidName(feature);\n        results.(fieldName) = struct(...\n            'cycleCV', cv, ...\n            'phaseCV', meanPhaseCV, ...\n            'romCV', romCV, ...\n            'meanROM', mean(romValues));\n\n        fprintf('\\n%s:\\n', feature);\n        fprintf('  Cycle-to-cycle CV: %.1f%%\\n', cv);\n        fprintf('  Phase-to-phase CV: %.1f%%\\n', meanPhaseCV);\n        fprintf('  ROM CV: %.1f%%\\n', romCV);\n        fprintf('  Mean ROM: %.3f rad\\n', mean(romValues));\n    end\n\n    % 5. Find most variable feature\n    cvs = zeros(1, length(featureNames));\n    for i = 1:length(featureNames)\n        fieldName = matlab.lang.makeValidName(featureNames{i});\n        cvs(i) = results.(fieldName).cycleCV;\n    end\n\n    [maxCV, maxIdx] = max(cvs);\n    mostVariable = featureNames{maxIdx};\n    fprintf('\\nMost variable feature: %s (CV = %.1f%%)\\n', mostVariable, maxCV);\nend\n\n% Run the analysis\nfeaturesToAnalyze = {'hip_flexion_angle_right_rad', 'knee_flexion_angle_right_rad', 'ankle_flexion_angle_right_rad'};\nvariabilityResults = analyzeGaitVariability(loco, subject, task, featuresToAnalyze);\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#10-batch-processing-multiple-subjects","title":"10. Batch Processing Multiple Subjects","text":"<pre><code>function results = batchProcessSubjects(loco, task, features, maxSubjects)\n    % Process multiple subjects and compare results\n\n    if nargin &lt; 4\n        maxSubjects = 5;\n    end\n\n    subjects = loco.subjects(1:min(maxSubjects, length(loco.subjects)));\n    results = struct();\n\n    fprintf('\\n=== Batch Processing %d subjects for %s ===\\n', ...\n            length(subjects), task);\n\n    for i = 1:length(subjects)\n        subject = subjects{i};\n        fprintf('\\nProcessing %s...\\n', subject);\n\n        % Get data\n        [data3D, ~] = loco.getCycles(subject, task, features);\n        if isempty(data3D)\n            fprintf('  No data for %s\\n', subject);\n            continue;\n        end\n\n        % Validate and get statistics\n        validMask = loco.validateCycles(subject, task, features);\n        meanPatterns = loco.getMeanPatterns(subject, task, features);\n        romData = loco.calculateROM(subject, task, features, false);\n\n        % Store results\n        results.(matlab.lang.makeValidName(subject)) = struct(...\n            'nCycles', size(data3D, 1), ...\n            'nValid', sum(validMask), ...\n            'meanPatterns', meanPatterns, ...\n            'romData', romData);\n\n        fprintf('  Cycles: %d (valid: %d)\\n', size(data3D, 1), sum(validMask));\n    end\n\n    % Compare ROM across subjects\n    fprintf('\\n=== ROM Comparison ===\\n');\n    subjectFields = fieldnames(results);\n\n    for i = 1:length(features)\n        feature = features{i};\n        fprintf('\\n%s:\\n', feature);\n\n        for j = 1:length(subjectFields)\n            subjectField = subjectFields{j};\n            romField = matlab.lang.makeValidName(feature);\n\n            if isfield(results.(subjectField).romData, romField)\n                rom = results.(subjectField).romData.(romField);\n                fprintf('  %s: %.3f rad\\n', subjectField, rom);\n            end\n        end\n    end\nend\n\n% Run batch processing\nbatchResults = batchProcessSubjects(loco, 'normal_walk', angleFeatures, 3);\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#11-export-results","title":"11. Export Results","text":"<pre><code>% Export summary statistics to CSV\nsummaryStats = loco.getSummaryStatistics(subject, task);\nwritetable(summaryStats, 'summary_statistics.csv', 'WriteRowNames', true);\nfprintf('Summary statistics saved to summary_statistics.csv\\n');\n\n% Export ROM data\nromData = loco.calculateROM(subject, task, angleFeatures, true);\nromTable = table();\n\n% Convert ROM struct to table\nfor i = 1:length(angleFeatures)\n    feature = angleFeatures{i};\n    fieldName = matlab.lang.makeValidName(feature);\n    if isfield(romData, fieldName)\n        romTable.(fieldName) = romData.(fieldName);\n    end\nend\n\nwritetable(romTable, 'rom_per_cycle.csv');\nfprintf('ROM data saved to rom_per_cycle.csv\\n');\n\n% Export using helper function\nexportToCSV(angleData, angleNames, 'exported_cycles.csv', ...\n           'Format', 'long', 'Subject', subject, 'Task', task);\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#12-working-with-multiple-datasets","title":"12. Working with Multiple Datasets","text":"<pre><code>% Compare data from different datasets\ndatasets = {'gtech_2023_phase.parquet', 'umich_2021_phase.parquet'};\ndatasetNames = {'GTech2023', 'UMich2021'};\n\nfor i = 1:length(datasets)\n    if exist(datasets{i}, 'file')\n        fprintf('\\n=== Loading %s ===\\n', datasetNames{i});\n\n        % Load dataset\n        loco_temp = LocomotionData(datasets{i});\n\n        % Find common subjects and tasks\n        commonSubjects = intersect(loco.subjects, loco_temp.subjects);\n        commonTasks = intersect(loco.tasks, loco_temp.tasks);\n\n        fprintf('Common subjects: %d\\n', length(commonSubjects));\n        fprintf('Common tasks: %d\\n', length(commonTasks));\n\n        % Compare for first common subject/task\n        if ~isempty(commonSubjects) &amp;&amp; ~isempty(commonTasks)\n            subj = commonSubjects{1};\n            tsk = commonTasks{1};\n\n            [data1, ~] = loco.getCycles(subj, tsk, angleFeatures);\n            [data2, ~] = loco_temp.getCycles(subj, tsk, angleFeatures);\n\n            if ~isempty(data1) &amp;&amp; ~isempty(data2)\n                fprintf('Dataset 1 cycles: %d\\n', size(data1, 1));\n                fprintf('Dataset 2 cycles: %d\\n', size(data2, 1));\n            end\n        end\n    end\nend\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#13-performance-comparison","title":"13. Performance Comparison","text":"<pre><code>% Compare efficiency of different approaches\nfprintf('\\n=== Performance Comparison ===\\n');\n\n% Method 1: Using LocomotionData class\ntic;\n[data3D_class, ~] = loco.getCycles(subject, task, angleFeatures);\ntime_class = toc;\n\n% Method 2: Using helper functions\ntic;\n[data3D_helper, ~] = efficientReshape3D(loco.data, subject, task, angleFeatures);\ntime_helper = toc;\n\nfprintf('Class method: %.4f seconds\\n', time_class);\nfprintf('Helper function: %.4f seconds\\n', time_helper);\nfprintf('Speedup: %.1fx\\n', time_class / time_helper);\n\n% Verify results are identical\nif isequal(data3D_class, data3D_helper)\n    fprintf('\u2713 Results are identical\\n');\nelse\n    fprintf('\u26a0 Results differ\\n');\nend\n</code></pre>"},{"location":"tutorials/matlab/library_tutorial_matlab/#conclusion","title":"Conclusion","text":"<p>This tutorial covered the main features of the MATLAB LocomotionData library:</p> <ul> <li>Efficient data loading from parquet files</li> <li>Object-oriented and functional interfaces for different programming styles</li> <li>3D array operations for fast cycle-based analysis</li> <li>Automatic validation based on biomechanical constraints</li> <li>Statistical analysis including mean patterns, ROM, and variability</li> <li>Comprehensive visualization with customizable plots</li> <li>Data merging capabilities</li> <li>Batch processing for multiple subjects</li> <li>Export functionality for results</li> </ul>"},{"location":"tutorials/matlab/library_tutorial_matlab/#key-functions-summary","title":"Key Functions Summary","text":"<p>LocomotionData Class Methods: - <code>getCycles()</code> - Extract 3D arrays - <code>validateCycles()</code> - Validate biomechanical constraints - <code>getMeanPatterns()</code> / <code>getStdPatterns()</code> - Statistical patterns - <code>calculateROM()</code> - Range of motion analysis - <code>plotPhasePatterns()</code> - Visualization - <code>mergeWithTaskData()</code> - Data joining</p> <p>Helper Functions: - <code>efficientReshape3D()</code> - Core 3D reshaping - <code>calculateMeanPatterns()</code> - Statistical calculations - <code>validateCycles()</code> - Standalone validation - <code>plotMosaicData()</code> - Flexible plotting - <code>exportToCSV()</code> - Data export</p> <p>The library provides efficient, validated methods for analyzing standardized locomotion data while maintaining MATLAB's familiar syntax and functionality.</p> <p>For more advanced usage, see the source code in <code>source/lib/matlab/</code> which includes additional customization options and implementation details.</p>"},{"location":"tutorials/python/getting_started_python/","title":"Getting Started with Python for Locomotion Data Analysis","text":"<p>This tutorial provides a basic guide on how to work with standardized locomotion data using Python. We'll cover common tasks such Datalab joining different data sources (e.g., primary data and task data), filtering by specific criteria, and performing basic analyses like calculating averages for features.</p> <p>We will primarily use the Pandas library, which is a powerful tool for data manipulation and analysis in Python.</p>"},{"location":"tutorials/python/getting_started_python/#0-setup","title":"0. Setup","text":"<p>Ensure you have Pandas and Matplotlib installed. If not, you can install them using pip:</p> <pre><code>pip install pandas matplotlib numpy\n</code></pre> <p>In your Python script or Jupyter notebook, you'll typically start by importing the necessary libraries:</p> <pre><code>import pandas as pd\nimport numpy as np # Often useful for numerical operations\nimport matplotlib.pyplot as plt # For plotting\nimport os # For operating system dependent functionality like getting current directory\n</code></pre> <p>Running the Examples/Test Script:</p> <p>The code examples in this tutorial are designed to match the <code>test_python_tutorial.py</code> script located in the <code>docs/tutorials/test_files/</code> directory. To run these examples: 1.  Ensure you have <code>locomotion_data.csv</code> and <code>task_info.csv</code> in the same directory as your script (or the test script). You can copy them from the <code>docs/tutorials/test_files/</code> directory if needed. 2.  Navigate to that directory in your terminal. 3.  Run the script using: <code>python your_script_name.py</code> (or <code>python test_python_tutorial.py</code> for the provided test script).</p> <p>The test script wraps all operations in a <code>try...except</code> block to catch errors. For clarity, this tutorial presents code in separate blocks.</p>"},{"location":"tutorials/python/getting_started_python/#1-loading-your-data","title":"1. Loading Your Data","text":"<p>Let's assume your standardized locomotion data is stored in CSV files. Create these files in the same directory where you are running your Python script.</p> <p>File 1: <code>locomotion_data.csv</code></p> <p>Create a file named <code>locomotion_data.csv</code> with the following content:</p> <pre><code>time_s,step_id,subject_id,task_id,knee_flexion_angle_rad,hip_flexion_angle_rad,ankle_flexion_angle_rad,cop_x_m,cop_y_m,vertical_grf_N\n0.01,1,P001,P001_T01,0.178,0.089,0.052,0.10,0.05,650.2\n0.02,1,P001,P001_T01,0.218,0.108,0.063,0.11,0.06,680.5\n0.03,1,P001,P001_T01,0.264,0.122,0.075,0.12,0.07,700.3\n0.04,2,P001,P001_T02,0.354,0.183,0.087,0.15,0.10,720.8\n0.05,2,P001,P001_T02,0.384,0.197,0.093,0.16,0.11,750.2\n0.06,2,P001,P001_T02,0.447,0.224,0.105,0.17,0.12,760.5\n0.07,3,P001,P001_T01,0.155,0.075,0.045,0.09,0.04,620.1\n0.08,3,P001,P001_T01,0.182,0.087,0.055,0.10,0.05,640.3\n0.09,3,P001,P001_T01,0.230,0.107,0.068,0.11,0.06,660.7\n0.10,3,P001,P001_T01,0.279,0.131,0.079,0.12,0.07,680.9\n</code></pre> <p>File 2: <code>task_info.csv</code></p> <p>Create a file named <code>task_info.csv</code> with the following content:</p> <pre><code>step_id,task_id,task_name,subject_id,ground_inclination_deg,walking_speed_m_s\n1,P001_T01,level_walking,P001,0,1.2\n2,P001_T02,incline_walking,P001,5,1.5\n3,P001_T01,level_walking,P001,0,1.2\n</code></pre> <p>Now, let's load this data using Pandas:</p> <pre><code>print(\"Working directory:\", os.getcwd())\n# Load the data from the CSV files\ntry:\n    df_locomotion = pd.read_csv('locomotion_data.csv')\n    df_tasks = pd.read_csv('task_info.csv')\n\n    print(\"\\nLocomotion Data:\")\n    print(df_locomotion.head(3)) # Show first 3 rows\n    print(\"\\nTask Information:\")\n    print(df_tasks) # Show all task info (it's small)\nexcept FileNotFoundError:\n    print(\"Error: Ensure 'locomotion_data.csv' and 'task_info.csv' exist in the current directory.\")\n    # Create empty dataframes to allow the rest of the script to run without error, though plots/results will be empty.\n    df_locomotion = pd.DataFrame({'time_s': [], 'step_id': [], 'knee_flexion_angle_rad': [], 'hip_flexion_angle_rad': [], 'ankle_flexion_angle_rad': [], 'cop_x_m': [], 'cop_y_m': [], 'vertical_grf_N': []})\n    df_tasks = pd.DataFrame({'step_id': [], 'task_id': [], 'task_name': [], 'subject_id': [], 'ground_inclination_deg': [], 'walking_speed_m_s': []})\n</code></pre> <p>This setup provides <code>df_locomotion</code> with time-series data and <code>df_tasks</code> with information about the tasks performed.</p>"},{"location":"tutorials/python/getting_started_python/#2-combining-locomotion-data-with-task-data-outer-join","title":"2. Combining Locomotion Data with Task Data (Outer Join)","text":"<p>To analyze locomotion features in the context of specific tasks, you'll often need to combine these datasets. An outer join is useful if you want to keep all records from both dataframes, filling in missing values with <code>NaN</code> where a match isn't found. In Pandas, <code>pd.merge()</code> is used for this.</p> <p>Let's assume we want to join on the common keys <code>step_id</code>, <code>task_id</code>, and <code>subject_id</code>.</p> <pre><code># Perform an outer join on common keys\n# This ensures that all locomotion data and all task data are preserved.\n# If a key combination exists in one DataFrame but not the other,\n# the columns from the other DataFrame will be filled with NaN for that row.\ndf_combined = pd.merge(df_locomotion, df_tasks, on=['step_id', 'task_id', 'subject_id'], how='outer')\n\nprint(\"\\nCombined Data (first 3 rows):\")\nprint(df_combined.head(3))\n</code></pre> <p>Why an outer join? *   You might have locomotion data that wasn't assigned a task (it will still be included). *   You might have task definitions for which no locomotion data was recorded (they will also be included, though less common in this specific example structure). In many cases, a <code>left</code> join (keeping all records from <code>df_locomotion</code> and matching task info) or an <code>inner</code> join (keeping only records where the key combination exists in both) might be more appropriate depending on your specific data and analysis goals.</p>"},{"location":"tutorials/python/getting_started_python/#3-filtering-for-a-particular-task","title":"3. Filtering for a Particular Task","text":"<p>Once your data is combined, you can easily filter it to focus on a specific task. For example, let's filter the data for the 'incline_walking' task.</p> <pre><code># Filter for a specific task, e.g., 'incline_walking'\ndf_incline_walking = df_combined[df_combined['task_name'] == 'incline_walking']\nprint(\"\\nData for 'incline_walking' task:\")\nprint(df_incline_walking)\n\n# You can also filter by other criteria, e.g., subject_id or step_id\n# df_subject_p001 = df_combined[df_combined['subject_id'] == 'P001']\n</code></pre> <p>This allows you to isolate the data segments relevant to your particular research question or analysis.</p>"},{"location":"tutorials/python/getting_started_python/#4-phase-based-averaging-for-gait-analysis","title":"4. Phase-Based Averaging for Gait Analysis","text":"<p>A common operation in biomechanics is to normalize gait cycles to 0-100% phase and then generate average curves across multiple steps or subjects. This allows for comparing gait patterns regardless of differences in cycle duration.</p> <p>Example: Averaging knee angle across steps by phase percentage</p> <p>For this example, we'll add a <code>phase_%</code> column to our locomotion data (representing 0-100% of each step) and then bin this phase data to calculate averages.</p> <pre><code># First, let's create sample phase data\n# In a real dataset, this might come from a separate phase-normalized data file or be calculated.\ndf_with_phase = df_locomotion.copy()\nfor step in df_locomotion['step_id'].unique():\n    step_mask = df_locomotion['step_id'] == step\n    num_points = step_mask.sum()\n    df_with_phase.loc[step_mask, 'phase_%'] = np.linspace(0, 100, num_points)\n\n# Now let's use phase bins to group data points at similar phases across different steps\nphase_bins = np.linspace(0, 100, 101)  # 101 bins for 0-100% (e.g., 0, 1, ..., 100)\nlabels = phase_bins[:-1]  # Use 0, 1, ..., 99 as the labels for bins [0-1), [1-2), ..., [99-100]\n\n# Bin the data by phase percentage\ndf_with_phase['phase_bin'] = pd.cut(df_with_phase['phase_%'], bins=phase_bins, labels=labels, include_lowest=True)\n\n# Now we can get the average knee angle for each phase bin across all steps\nphase_averages = df_with_phase.groupby('phase_bin', observed=False)['knee_flexion_angle_rad'].mean()\n\nprint(\"\\nAverage knee flexion angle by phase (first 5 phases):\")\nprint(phase_averages.head(5))\n\n# We can also compare different tasks by phase\n# First, merge df_with_phase (which has phase_bin) with df_tasks to get task_name\n# Using an inner join to ensure we only consider data points that have both phase and task information\ndf_with_phase_and_task = pd.merge(df_with_phase, df_tasks, on=['step_id', 'task_id', 'subject_id'], how='inner')\n\nphase_by_task = {}\nfor task in df_with_phase_and_task['task_name'].unique():\n    if pd.notnull(task):  # Skip NaN values if any (though inner join should prevent them here)\n        task_data = df_with_phase_and_task[df_with_phase_and_task['task_name'] == task]\n        phase_by_task[task] = task_data.groupby('phase_bin', observed=False)['knee_flexion_angle_rad'].mean()\n\nprint(\"\\nPhase-based knee flexion angle by task (first 3 phases):\")\nfor task, data in phase_by_task.items():\n    print(f\"Task: {task}\")\n    print(data.head(3))\n</code></pre> <p>Note: The standardized data format may also provide data already indexed by phase (e.g., in Parquet files), typically with 150 equally spaced points per gait cycle. Working with such pre-processed phase-indexed data can simplify these types of analyses.</p>"},{"location":"tutorials/python/getting_started_python/#5-basic-plotting","title":"5. Basic Plotting","text":"<p>Visualizing your data is a crucial step. Matplotlib is a widely used library for plotting in Python. The test script saves plots to files rather than displaying them interactively.</p> <p>Example 5.1: Plotting a time-series feature for a specific task</p> <p>Let's plot the <code>knee_flexion_angle_rad</code> over time for the 'incline_walking' task and save it to a file.</p> <pre><code># Using df_incline_walking from section 3\nif not df_incline_walking.empty:\n    plt.figure(figsize=(10, 4))\n    plt.plot(df_incline_walking['time_s'], df_incline_walking['knee_flexion_angle_rad'], marker='o', linestyle='-')\n    plt.xlabel('Time (s)')\n    plt.ylabel('Knee Flexion Angle (rad)')\n    plt.title('Knee Flexion Angle during Incline Walking')\n    plt.grid(True)\n    plt.savefig('knee_angle_incline.png') # Save the plot\n    print(\"\\nPlot saved as 'knee_angle_incline.png'\")\nelse:\n    print(\"\\nNo data available for 'incline_walking' task to plot.\")\n\n# Example 5.2: Comparing average feature values across tasks (Bar Plot)\n# Using phase_by_task from section 4\nif phase_by_task: # Check if the dictionary is not empty\n    plt.figure(figsize=(8, 5))\n    # Calculate the mean of the phase-averaged data for each task for the bar plot\n    task_means = {task: data.mean() for task, data in phase_by_task.items() if not data.empty}\n\n    if task_means: # Ensure there are means to plot\n        plt.bar(list(task_means.keys()), list(task_means.values()))\n        plt.xlabel('Task Name')\n        plt.ylabel('Average Knee Flexion Angle (rad)')\n        plt.title('Average Knee Flexion Angle by Task (mean of phase averages)')\n        plt.xticks(rotation=45, ha=\"right\")\n        plt.tight_layout() # Adjust layout to prevent labels from overlapping\n        plt.savefig('knee_angle_by_task.png') # Save the plot\n        print(\"Plot saved as 'knee_angle_by_task.png'\")\n    else:\n        print(\"\\nNo averaged data means available to plot by task.\")\nelse:\n    print(\"\\nNo phase_by_task data available to plot.\")\n</code></pre>"},{"location":"tutorials/python/getting_started_python/#6-calculating-derived-metrics","title":"6. Calculating Derived Metrics","text":"<p>Often, you'll need to compute new metrics from your existing data.</p> <p>Example 6.1: Calculate Knee Angle Range of Motion (RoM) per step</p> <p>Let's calculate the knee angle RoM for each step in the 'level_walking' task. RoM can be defined as (max value - min value) of the angle within each step. We use <code>df_with_phase_and_task</code> from Section 4 as it contains the necessary columns.</p> <pre><code># Using df_with_phase_and_task from section 4, which includes 'task_name'\n# Filter for level_walking data\ndf_level_walking = df_with_phase_and_task[df_with_phase_and_task['task_name'] == 'level_walking']\n\nif not df_level_walking.empty:\n    # Group by step_id and then calculate RoM for knee_flexion_angle_rad\n    knee_rom_per_step = df_level_walking.groupby('step_id')['knee_flexion_angle_rad'].apply(lambda x: x.max() - x.min())\n    knee_rom_per_step = knee_rom_per_step.rename('knee_flexion_angle_rom_rad')\n\n    print(\"\\nKnee Flexion Angle ROM per step during 'level_walking':\")\n    print(knee_rom_per_step)\n\n    # You can merge this back into your task-specific dataframe or the combined dataframe if needed\n    # df_level_walking = pd.merge(df_level_walking, knee_rom_per_step, on='step_id', how='left')\nelse:\n    print(\"\\nNo data available for 'level_walking' task to calculate RoM.\")\n\n# Final message similar to the test script\nprint(\"\\nPython tutorial operations completed (mimicking test script structure).\")\n</code></pre>"},{"location":"tutorials/python/getting_started_python/#conclusion","title":"Conclusion","text":"<p>This tutorial covered basic operations for handling standardized locomotion data in Python: *   Loading data with Pandas. *   Joining different data sources using <code>pd.merge()</code>. *   Filtering data based on task information or other criteria. *   Analyzing data using phase-based normalization and averaging. *   Creating basic plots and saving them using Matplotlib. *   Calculating derived metrics like Range of Motion.</p> <p>These examples provide a starting point. Depending on the complexity of your data and analyses, you might explore more advanced Pandas functionalities, time-series analysis libraries, or specific biomechanics-focused Python packages.</p> <p>Refer to the Pandas documentation for more comprehensive information on its capabilities. Consult your dataset's specific metadata and the Units &amp; Conventions documentation for details on column names, units, and conventions.</p>"},{"location":"tutorials/python/library_tutorial_python/","title":"Python Library Tutorial for Locomotion Data Analysis","text":"<p>This tutorial demonstrates how to use the LocomotionData library for efficient analysis of standardized locomotion data. The library provides a high-level interface for common operations like loading data, filtering, phase-based analysis, validation, and visualization.</p>"},{"location":"tutorials/python/library_tutorial_python/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have the required packages: <pre><code>pip install pandas numpy matplotlib pyarrow seaborn\n</code></pre></p>"},{"location":"tutorials/python/library_tutorial_python/#0-setup-and-import","title":"0. Setup and Import","text":"<pre><code>import sys\nimport os\n\n# Add the library path (adjust as needed)\nsys.path.append('../../../source/lib/python')\n\n# Import the library\nfrom locomotion_analysis import LocomotionData\nimport pandas as pd\nimport numpy as np\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#1-loading-data","title":"1. Loading Data","text":"<p>The <code>LocomotionData</code> class can load both parquet and CSV files:</p> <pre><code># Load phase-indexed parquet data (recommended)\nloco = LocomotionData('path/to/gtech_2023_phase.parquet')\n\n# Or load CSV data\n# loco = LocomotionData('path/to/data.csv', file_type='csv')\n\n# View basic information\nprint(f\"Loaded {len(loco.df)} rows\")\nprint(f\"Subjects: {', '.join(loco.get_subjects()[:5])}...\")\nprint(f\"Tasks: {', '.join(loco.get_tasks())}\")\nprint(f\"Features: {len(loco.features)} biomechanical features\")\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#2-basic-data-exploration","title":"2. Basic Data Exploration","text":"<pre><code># Get available subjects and tasks\nsubjects = loco.get_subjects()\ntasks = loco.get_tasks()\n\nprint(f\"Available subjects: {subjects}\")\nprint(f\"Available tasks: {tasks}\")\n\n# Show available features\nprint(\"\\nBiomechanical features:\")\nfor feature in loco.features[:10]:  # Show first 10\n    print(f\"  - {feature}\")\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#3-efficient-3d-data-access","title":"3. Efficient 3D Data Access","text":"<p>The core strength of the library is converting phase-indexed data into 3D arrays for efficient analysis:</p> <pre><code># Get 3D array for a specific subject-task\nsubject = subjects[0]\ntask = 'normal_walk'\n\n# Extract all features\ndata_3d, feature_names = loco.get_cycles(subject, task)\n\nif data_3d is not None:\n    print(f\"Data shape: {data_3d.shape}\")  # (n_cycles, 150, n_features)\n    print(f\"Found {data_3d.shape[0]} gait cycles\")\n    print(f\"Features extracted: {len(feature_names)}\")\nelse:\n    print(\"No data found for this subject-task combination\")\n\n# Extract specific features only\nangle_features = ['hip_flexion_angle_right_rad', 'knee_flexion_angle_right_rad', 'ankle_flexion_angle_right_rad']\nangle_data, angle_names = loco.get_cycles(subject, task, angle_features)\nprint(f\"Angle data shape: {angle_data.shape}\")\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#4-data-validation","title":"4. Data Validation","text":"<p>Automatically validate cycles based on biomechanical constraints:</p> <pre><code># Validate all cycles\nvalid_mask = loco.validate_cycles(subject, task)\nprint(f\"Valid cycles: {np.sum(valid_mask)}/{len(valid_mask)}\")\n\n# Get details on invalid cycles\ninvalid_indices = np.where(~valid_mask)[0]\nif len(invalid_indices) &gt; 0:\n    print(f\"Invalid cycle indices: {invalid_indices}\")\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#5-statistical-analysis","title":"5. Statistical Analysis","text":""},{"location":"tutorials/python/library_tutorial_python/#mean-and-standard-deviation-patterns","title":"Mean and Standard Deviation Patterns","text":"<pre><code># Get mean patterns for each feature\nmean_patterns = loco.get_mean_patterns(subject, task, angle_features)\nstd_patterns = loco.get_std_patterns(subject, task, angle_features)\n\n# Display mean pattern for knee angle\nif 'knee_flexion_angle_right_rad' in mean_patterns:\n    knee_mean = mean_patterns['knee_flexion_angle_right_rad']\n    print(f\"Knee angle: mean = {np.mean(knee_mean):.3f} rad, \"\n          f\"peak = {np.max(knee_mean):.3f} rad\")\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#range-of-motion-rom-analysis","title":"Range of Motion (ROM) Analysis","text":"<pre><code># Calculate ROM per cycle\nrom_per_cycle = loco.calculate_rom(subject, task, angle_features, by_cycle=True)\n\n# Calculate overall ROM\nrom_overall = loco.calculate_rom(subject, task, angle_features, by_cycle=False)\n\n# Display results\nfor feature in angle_features:\n    if feature in rom_per_cycle:\n        rom_cycles = rom_per_cycle[feature]\n        rom_total = rom_overall[feature]\n        print(f\"{feature}:\")\n        print(f\"  ROM per cycle: {np.mean(rom_cycles):.3f} \u00b1 {np.std(rom_cycles):.3f} rad\")\n        print(f\"  Overall ROM: {rom_total:.3f} rad\")\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#summary-statistics","title":"Summary Statistics","text":"<pre><code># Get comprehensive summary statistics\nsummary = loco.get_summary_statistics(subject, task, angle_features)\nprint(\"\\nSummary Statistics:\")\nprint(summary)\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#6-outlier-detection","title":"6. Outlier Detection","text":"<pre><code># Find outlier cycles\noutlier_indices = loco.find_outlier_cycles(subject, task, angle_features, threshold=2.0)\nprint(f\"Outlier cycles (&gt;2 std): {outlier_indices}\")\n\n# Find outlier cycles with stricter threshold\nstrict_outliers = loco.find_outlier_cycles(subject, task, angle_features, threshold=1.5)\nprint(f\"Outlier cycles (&gt;1.5 std): {strict_outliers}\")\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#7-data-merging","title":"7. Data Merging","text":"<p>If you have additional task information, you can merge it with the locomotion data:</p> <pre><code># Create example task data\ntask_data = pd.DataFrame({\n    'subject': [subject, subject],\n    'task': ['normal_walk', 'incline_walk'],\n    'speed_m_s': [1.2, 1.0],\n    'incline_deg': [0, 5]\n})\n\n# Merge with locomotion data\nmerged_df = loco.merge_with_task_data(task_data, how='inner')\nprint(f\"Merged data shape: {merged_df.shape}\")\nprint(f\"New columns: {set(merged_df.columns) - set(loco.df.columns)}\")\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#8-visualization","title":"8. Visualization","text":"<p>The library provides comprehensive plotting utilities for phase-normalized locomotion data with three main plot types.</p>"},{"location":"tutorials/python/library_tutorial_python/#phase-pattern-plotting","title":"Phase Pattern Plotting","text":"<p>The library offers three plotting styles for phase-normalized data:</p> <pre><code># 1. Spaghetti plots - show all individual cycles\nloco.plot_phase_patterns(subject, task, angle_features, \n                        plot_type='spaghetti', \n                        save_path='spaghetti_plot.png')\n\n# 2. Mean \u00b1 standard deviation plots with shaded confidence bands\nloco.plot_phase_patterns(subject, task, angle_features, \n                        plot_type='mean',\n                        save_path='mean_patterns.png')\n\n# 3. Combined plots - both individual cycles and mean pattern overlay\nloco.plot_phase_patterns(subject, task, angle_features, \n                        plot_type='both', \n                        save_path='phase_patterns.png')\n</code></pre> <p>Plot Features: - Gray lines: Valid cycles passing biomechanical validation - Red lines: Invalid cycles failing validation criteria - Blue line: Mean pattern across valid cycles only - Blue shaded area: \u00b11 standard deviation (in 'mean' mode) - Automatic layout: Intelligent subplot arrangement (up to 3 columns)</p>"},{"location":"tutorials/python/library_tutorial_python/#task-comparison-plots","title":"Task Comparison Plots","text":"<p>Compare mean patterns across different tasks for the same subject:</p> <pre><code># Compare multiple tasks for the same subject\navailable_tasks = ['normal_walk', 'incline_walk', 'decline_walk']\n# Filter to only available tasks in dataset\nvalid_tasks = [task for task in available_tasks if task in loco.get_tasks()]\n\nif len(valid_tasks) &gt; 1:\n    loco.plot_task_comparison(subject, valid_tasks, angle_features,\n                             save_path='task_comparison.png')\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#time-series-plotting","title":"Time Series Plotting","text":"<p>For time-indexed data analysis:</p> <pre><code># Plot time series data (useful for time-indexed datasets)\nif 'time_s' in loco.df.columns:\n    loco.plot_time_series(subject, task, angle_features,\n                         time_col='time_s', \n                         save_path='time_series.png')\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#custom-plotting-with-raw-data","title":"Custom Plotting with Raw Data","text":"<p>Access underlying 3D arrays for advanced custom visualizations:</p> <pre><code>import matplotlib.pyplot as plt\n\n# Get 3D data arrays\ndata_3d, feature_names = loco.get_cycles(subject, task, angle_features)\nvalid_mask = loco.validate_cycles(subject, task, angle_features)\n\n# Create custom percentile plot\nfig, axes = plt.subplots(1, len(feature_names), figsize=(15, 4))\nphase_x = np.linspace(0, 100, 150)\n\nfor i, feature in enumerate(feature_names):\n    feat_data = data_3d[:, :, i]\n    valid_data = feat_data[valid_mask, :]\n\n    # Calculate percentiles\n    p25 = np.percentile(valid_data, 25, axis=0)\n    p50 = np.percentile(valid_data, 50, axis=0)  # Median\n    p75 = np.percentile(valid_data, 75, axis=0)\n\n    # Plot with custom styling\n    axes[i].fill_between(phase_x, p25, p75, alpha=0.3, \n                        color='lightblue', label='IQR (25-75%)')\n    axes[i].plot(phase_x, p50, 'navy', linewidth=2, label='Median')\n\n    axes[i].set_xlabel('Gait Cycle (%)')\n    axes[i].set_ylabel(feature.replace('_', ' '))\n    axes[i].set_title(feature, fontsize=10)\n    axes[i].legend()\n    axes[i].grid(True, alpha=0.3)\n    axes[i].set_xlim([0, 100])\n\nplt.tight_layout()\nplt.savefig('custom_percentile_plot.png', dpi=300, bbox_inches='tight')\nplt.show()\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#9-advanced-analysis-example","title":"9. Advanced Analysis Example","text":"<p>Here's a complete workflow for analyzing gait variability:</p> <pre><code>def analyze_gait_variability(loco, subject, task, features):\n    \"\"\"Comprehensive gait variability analysis.\"\"\"\n\n    print(f\"\\n=== Gait Variability Analysis: {subject} - {task} ===\")\n\n    # 1. Get data and validate\n    data_3d, feature_names = loco.get_cycles(subject, task, features)\n    if data_3d is None:\n        print(\"No data found\")\n        return\n\n    valid_mask = loco.validate_cycles(subject, task, features)\n    n_valid = np.sum(valid_mask)\n    n_total = len(valid_mask)\n\n    print(f\"Valid cycles: {n_valid}/{n_total} ({n_valid/n_total*100:.1f}%)\")\n\n    # 2. Calculate metrics for valid cycles only\n    valid_data = data_3d[valid_mask, :, :]\n\n    # 3. Analyze each feature\n    results = {}\n    for i, feature in enumerate(feature_names):\n        feat_data = valid_data[:, :, i]\n\n        # Mean pattern\n        mean_pattern = np.mean(feat_data, axis=0)\n\n        # Cycle-to-cycle variability (CV)\n        cycle_means = np.mean(feat_data, axis=1)\n        cv = np.std(cycle_means) / np.mean(cycle_means) * 100\n\n        # Step-to-step variability at each phase\n        phase_cv = np.std(feat_data, axis=0) / np.mean(feat_data, axis=0) * 100\n        mean_phase_cv = np.mean(phase_cv)\n\n        # Range of motion\n        rom_values = np.max(feat_data, axis=1) - np.min(feat_data, axis=1)\n        rom_cv = np.std(rom_values) / np.mean(rom_values) * 100\n\n        results[feature] = {\n            'cycle_cv': cv,\n            'phase_cv': mean_phase_cv,\n            'rom_cv': rom_cv,\n            'mean_rom': np.mean(rom_values)\n        }\n\n        print(f\"\\n{feature}:\")\n        print(f\"  Cycle-to-cycle CV: {cv:.1f}%\")\n        print(f\"  Phase-to-phase CV: {mean_phase_cv:.1f}%\")\n        print(f\"  ROM CV: {rom_cv:.1f}%\")\n        print(f\"  Mean ROM: {np.mean(rom_values):.3f} rad\")\n\n    # 4. Find most variable feature\n    cvs = [results[f]['cycle_cv'] for f in feature_names]\n    most_variable = feature_names[np.argmax(cvs)]\n    print(f\"\\nMost variable feature: {most_variable} (CV = {max(cvs):.1f}%)\")\n\n    return results\n\n# Run the analysis\nfeatures_to_analyze = ['hip_flexion_angle_right_rad', 'knee_flexion_angle_right_rad', 'ankle_flexion_angle_right_rad']\nvariability_results = analyze_gait_variability(loco, subject, task, features_to_analyze)\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#10-batch-processing-multiple-subjects","title":"10. Batch Processing Multiple Subjects","text":"<pre><code>def batch_process_subjects(loco, task, features, max_subjects=5):\n    \"\"\"Process multiple subjects and compare results.\"\"\"\n\n    subjects = loco.get_subjects()[:max_subjects]  # Limit for demo\n    results = {}\n\n    print(f\"\\n=== Batch Processing {len(subjects)} subjects for {task} ===\")\n\n    for subject in subjects:\n        print(f\"\\nProcessing {subject}...\")\n\n        # Get data\n        data_3d, _ = loco.get_cycles(subject, task, features)\n        if data_3d is None:\n            print(f\"  No data for {subject}\")\n            continue\n\n        # Validate and get statistics\n        valid_mask = loco.validate_cycles(subject, task, features)\n        mean_patterns = loco.get_mean_patterns(subject, task, features)\n        rom_data = loco.calculate_rom(subject, task, features, by_cycle=False)\n\n        results[subject] = {\n            'n_cycles': data_3d.shape[0],\n            'n_valid': np.sum(valid_mask),\n            'mean_patterns': mean_patterns,\n            'rom_data': rom_data\n        }\n\n        print(f\"  Cycles: {data_3d.shape[0]} (valid: {np.sum(valid_mask)})\")\n\n    # Compare ROM across subjects\n    print(f\"\\n=== ROM Comparison ===\")\n    for feature in features:\n        print(f\"\\n{feature}:\")\n        for subject in results:\n            if feature in results[subject]['rom_data']:\n                rom = results[subject]['rom_data'][feature]\n                print(f\"  {subject}: {rom:.3f} rad\")\n\n    return results\n\n# Run batch processing\nbatch_results = batch_process_subjects(loco, 'normal_walk', angle_features)\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#11-export-results","title":"11. Export Results","text":"<pre><code># Export summary statistics to CSV\nsummary_stats = loco.get_summary_statistics(subject, task)\nsummary_stats.to_csv('summary_statistics.csv')\nprint(\"Summary statistics saved to summary_statistics.csv\")\n\n# Export ROM data\nrom_data = loco.calculate_rom(subject, task, by_cycle=True)\nrom_df = pd.DataFrame(rom_data)\nrom_df.to_csv('rom_per_cycle.csv', index=False)\nprint(\"ROM data saved to rom_per_cycle.csv\")\n</code></pre>"},{"location":"tutorials/python/library_tutorial_python/#conclusion","title":"Conclusion","text":"<p>This tutorial covered the main features of the LocomotionData library:</p> <ul> <li>Efficient data loading from parquet or CSV files</li> <li>3D array operations for fast cycle-based analysis</li> <li>Automatic validation based on biomechanical constraints</li> <li>Statistical analysis including mean patterns, ROM, and variability</li> <li>Visualization with phase patterns and task comparisons</li> <li>Data merging with task information</li> <li>Batch processing for multiple subjects</li> </ul> <p>The library provides a powerful, efficient interface for analyzing standardized locomotion data while maintaining the flexibility to access underlying data structures when needed.</p> <p>For more advanced usage, see the source code in <code>source/lib/python/locomotion_analysis.py</code> which includes additional methods and customization options.</p>"},{"location":"user_guide/working_with_data/","title":"Working with Data","text":"<p>Advanced techniques for analyzing standardized locomotion datasets efficiently and effectively.</p>"},{"location":"user_guide/working_with_data/#memory-efficient-data-loading","title":"Memory-Efficient Data Loading","text":"<p>Large datasets require careful memory management:</p> PythonMATLAB <pre><code>import pandas as pd\nimport numpy as np\n\n# For large datasets, load specific columns only\ncolumns_of_interest = [\n    'subject', 'task', 'step', 'phase_percent',\n    'knee_flexion_angle_ipsi_rad', 'hip_flexion_angle_ipsi_rad'\n]\n\ndata = pd.read_parquet('large_dataset.parquet', columns=columns_of_interest)\n\n# Use chunked processing for very large datasets\ndef process_in_chunks(filepath, chunk_size=10000):\n    \"\"\"Process large dataset in manageable chunks.\"\"\"\n    results = []\n\n    # Read parquet in chunks (requires pyarrow)\n    parquet_file = pd.read_parquet(filepath, engine='pyarrow')\n\n    for i in range(0, len(parquet_file), chunk_size):\n        chunk = parquet_file.iloc[i:i+chunk_size]\n\n        # Process chunk\n        processed_chunk = chunk.groupby('phase_percent')['knee_flexion_angle_ipsi_rad'].mean()\n        results.append(processed_chunk)\n\n        print(f\"Processed chunk {i//chunk_size + 1}\")\n\n    # Combine results\n    return pd.concat(results).groupby(level=0).mean()\n\n# Use efficient data types\ndef optimize_dtypes(df):\n    \"\"\"Optimize dataframe memory usage.\"\"\"\n    for col in df.columns:\n        if df[col].dtype == 'object':\n            # Convert string columns to category if appropriate\n            if df[col].nunique() / len(df) &lt; 0.5:\n                df[col] = df[col].astype('category')\n        elif df[col].dtype == 'float64':\n            # Downcast float precision if possible\n            if (df[col] &gt;= np.finfo(np.float32).min).all() and \\\n               (df[col] &lt;= np.finfo(np.float32).max).all():\n                df[col] = df[col].astype(np.float32)\n\n    return df\n</code></pre> <pre><code>% For large datasets, use efficient reading strategies\n\n% Read only specific variables\nopts = detectImportOptions('large_dataset.parquet');\nvars_to_read = {'subject', 'task', 'step', 'phase_percent', ...\n                'knee_flexion_angle_ipsi_rad', 'hip_flexion_angle_ipsi_rad'};\nopts = setvaropts(opts, setdiff(opts.VariableNames, vars_to_read), 'Type', 'char');\n\ndata = readtable('large_dataset.parquet', opts);\n\n% Process in chunks for very large files\nfunction result = processInChunks(filepath, chunkSize)\n    % Process large dataset in manageable chunks\n    info = parquetinfo(filepath);\n    totalRows = info.NumRows;\n\n    results = {};\n    chunkCount = 1;\n\n    for startRow = 1:chunkSize:totalRows\n        endRow = min(startRow + chunkSize - 1, totalRows);\n\n        % Read chunk\n        chunk = parquetread(filepath, 'RowIndices', startRow:endRow);\n\n        % Process chunk\n        processedChunk = groupsummary(chunk, 'phase_percent', 'mean', 'knee_flexion_angle_ipsi_rad');\n        results{chunkCount} = processedChunk;\n\n        fprintf('Processed chunk %d\\n', chunkCount);\n        chunkCount = chunkCount + 1;\n    end\n\n    % Combine results\n    combined = vertcat(results{:});\n    result = groupsummary(combined, 'phase_percent', 'mean', 'mean_knee_flexion_angle_ipsi_rad');\nend\n\n% Optimize memory usage\nfunction optimizedData = optimizeTable(data)\n    % Convert string columns to categorical where appropriate\n    for i = 1:width(data)\n        if iscell(data{:,i}) || isstring(data{:,i})\n            uniqueRatio = height(unique(data(:,i))) / height(data);\n            if uniqueRatio &lt; 0.5\n                data{:,i} = categorical(data{:,i});\n            end\n        end\n    end\n    optimizedData = data;\nend\n</code></pre>"},{"location":"user_guide/working_with_data/#advanced-filtering-and-selection","title":"Advanced Filtering and Selection","text":"<p>Complex data filtering for specific research questions:</p> PythonMATLAB <pre><code># Complex filtering examples\n\n# 1. Multiple condition filtering\nfiltered_data = data[\n    (data['task'].isin(['level_walking', 'incline_walking'])) &amp;\n    (data['subject'].str.startswith('SUB')) &amp;\n    (data['phase_percent'].between(0, 60))  # Stance phase only\n]\n\n# 2. Statistical outlier removal\ndef remove_outliers(group, column, n_std=3):\n    \"\"\"Remove statistical outliers from a group.\"\"\"\n    mean_val = group[column].mean()\n    std_val = group[column].std()\n\n    outlier_mask = np.abs(group[column] - mean_val) &gt; n_std * std_val\n    return group[~outlier_mask]\n\n# Apply outlier removal by subject and task\nclean_data = data.groupby(['subject', 'task']).apply(\n    lambda x: remove_outliers(x, 'knee_flexion_angle_ipsi_rad')\n).reset_index(drop=True)\n\n# 3. Dynamic phase selection\ndef select_gait_events(data, event_phase_ranges):\n    \"\"\"Select specific gait events based on phase ranges.\"\"\"\n    selected_data = pd.DataFrame()\n\n    for event_name, (start_phase, end_phase) in event_phase_ranges.items():\n        event_data = data[\n            (data['phase_percent'] &gt;= start_phase) &amp; \n            (data['phase_percent'] &lt;= end_phase)\n        ].copy()\n        event_data['gait_event'] = event_name\n        selected_data = pd.concat([selected_data, event_data])\n\n    return selected_data\n\n# Example: Select key gait events\ngait_events = {\n    'heel_strike': (0, 5),\n    'mid_stance': (10, 30),\n    'toe_off': (55, 65),\n    'mid_swing': (70, 85)\n}\n\nevent_data = select_gait_events(data, gait_events)\n\n# 4. Quality-based filtering\ndef filter_by_quality(data, quality_criteria):\n    \"\"\"Filter data based on multiple quality criteria.\"\"\"\n    quality_mask = pd.Series(True, index=data.index)\n\n    for criterion, (column, min_val, max_val) in quality_criteria.items():\n        if column in data.columns:\n            quality_mask &amp;= data[column].between(min_val, max_val)\n\n    return data[quality_mask]\n\n# Example quality criteria\nquality_criteria = {\n    'knee_range': ('knee_flexion_angle_ipsi_rad', np.radians(-10), np.radians(120)),\n    'hip_range': ('hip_flexion_angle_ipsi_rad', np.radians(-30), np.radians(90)),\n    'phase_completeness': ('phase_percent', 0, 100)\n}\n\nhigh_quality_data = filter_by_quality(data, quality_criteria)\n</code></pre> <pre><code>% Complex filtering examples\n\n% 1. Multiple condition filtering\ntask_mask = ismember(data.task, {'level_walking', 'incline_walking'});\nsubject_mask = startsWith(data.subject, 'SUB');\nphase_mask = data.phase_percent &gt;= 0 &amp; data.phase_percent &lt;= 60;\n\nfiltered_data = data(task_mask &amp; subject_mask &amp; phase_mask, :);\n\n% 2. Statistical outlier removal\nfunction clean_data = removeOutliers(data, column, n_std)\n    if nargin &lt; 3\n        n_std = 3;\n    end\n\n    % Group by subject and task\n    [groups, subjects, tasks] = findgroups(data.subject, data.task);\n\n    outlier_mask = false(height(data), 1);\n\n    for i = 1:max(groups)\n        group_mask = groups == i;\n        group_data = data.(column)(group_mask);\n\n        mean_val = mean(group_data);\n        std_val = std(group_data);\n\n        group_outliers = abs(group_data - mean_val) &gt; n_std * std_val;\n        outlier_mask(group_mask) = group_outliers;\n    end\n\n    clean_data = data(~outlier_mask, :);\nend\n\nclean_data = removeOutliers(data, 'knee_flexion_angle_ipsi_rad');\n\n% 3. Dynamic phase selection\nfunction event_data = selectGaitEvents(data, event_ranges)\n    event_data = table();\n\n    event_names = fieldnames(event_ranges);\n    for i = 1:length(event_names)\n        event_name = event_names{i};\n        phase_range = event_ranges.(event_name);\n\n        event_mask = data.phase_percent &gt;= phase_range(1) &amp; ...\n                    data.phase_percent &lt;= phase_range(2);\n\n        temp_data = data(event_mask, :);\n        temp_data.gait_event = repmat({event_name}, height(temp_data), 1);\n\n        event_data = [event_data; temp_data];\n    end\nend\n\n% Example: Select key gait events\ngait_events.heel_strike = [0, 5];\ngait_events.mid_stance = [10, 30];\ngait_events.toe_off = [55, 65];\ngait_events.mid_swing = [70, 85];\n\nevent_data = selectGaitEvents(data, gait_events);\n\n% 4. Quality-based filtering\nfunction high_quality_data = filterByQuality(data, quality_criteria)\n    quality_mask = true(height(data), 1);\n\n    field_names = fieldnames(quality_criteria);\n    for i = 1:length(field_names)\n        criterion = field_names{i};\n        column = quality_criteria.(criterion).column;\n        min_val = quality_criteria.(criterion).min_val;\n        max_val = quality_criteria.(criterion).max_val;\n\n        if any(strcmp(data.Properties.VariableNames, column))\n            quality_mask = quality_mask &amp; ...\n                (data.(column) &gt;= min_val) &amp; (data.(column) &lt;= max_val);\n        end\n    end\n\n    high_quality_data = data(quality_mask, :);\nend\n\n% Example quality criteria\nquality_criteria.knee_range.column = 'knee_flexion_angle_ipsi_rad';\nquality_criteria.knee_range.min_val = deg2rad(-10);\nquality_criteria.knee_range.max_val = deg2rad(120);\n\nquality_criteria.hip_range.column = 'hip_flexion_angle_ipsi_rad';\nquality_criteria.hip_range.min_val = deg2rad(-30);\nquality_criteria.hip_range.max_val = deg2rad(90);\n\nhigh_quality_data = filterByQuality(data, quality_criteria);\n</code></pre>"},{"location":"user_guide/working_with_data/#time-series-analysis","title":"Time Series Analysis","text":"<p>Advanced techniques for temporal analysis:</p> PythonMATLAB <pre><code>from scipy import signal\nfrom scipy.fft import fft, fftfreq\n\n# 1. Smoothing and filtering\ndef smooth_gait_data(data, method='savgol', **kwargs):\n    \"\"\"Apply smoothing to gait data.\"\"\"\n    if method == 'savgol':\n        window_length = kwargs.get('window_length', 15)\n        polyorder = kwargs.get('polyorder', 3)\n        return signal.savgol_filter(data, window_length, polyorder)\n\n    elif method == 'gaussian':\n        sigma = kwargs.get('sigma', 2)\n        return scipy.ndimage.gaussian_filter1d(data, sigma)\n\n    elif method == 'moving_average':\n        window = kwargs.get('window', 10)\n        return data.rolling(window=window, center=True).mean()\n\n# Apply smoothing to each gait cycle\nsmoothed_data = data.copy()\nfor (subject, task, step), group in data.groupby(['subject', 'task', 'step']):\n    mask = (data['subject'] == subject) &amp; (data['task'] == task) &amp; (data['step'] == step)\n\n    smoothed_knee = smooth_gait_data(\n        group['knee_flexion_angle_ipsi_rad'].values,\n        method='savgol', window_length=15, polyorder=3\n    )\n\n    smoothed_data.loc[mask, 'knee_flexion_angle_ipsi_rad_smooth'] = smoothed_knee\n\n# 2. Gait cycle variability analysis\ndef calculate_variability_metrics(data, variable):\n    \"\"\"Calculate various measures of gait variability.\"\"\"\n    cycles = []\n\n    for (subject, task, step), group in data.groupby(['subject', 'task', 'step']):\n        cycle_data = group.sort_values('phase_percent')[variable].values\n        cycles.append(cycle_data)\n\n    cycles_array = np.array(cycles)\n\n    # Calculate metrics\n    metrics = {\n        'mean_pattern': np.mean(cycles_array, axis=0),\n        'std_pattern': np.std(cycles_array, axis=0),\n        'cv_pattern': np.std(cycles_array, axis=0) / np.abs(np.mean(cycles_array, axis=0)),\n        'coefficient_of_variation': np.mean(np.std(cycles_array, axis=0) / np.abs(np.mean(cycles_array, axis=0))),\n        'range_of_motion_variability': np.std([np.ptp(cycle) for cycle in cycles]),\n        'peak_timing_variability': np.std([np.argmax(cycle) for cycle in cycles])\n    }\n\n    return metrics\n\n# Calculate variability for knee angle\nknee_variability = calculate_variability_metrics(data, 'knee_flexion_angle_ipsi_rad')\n\n# 3. Frequency domain analysis\ndef analyze_frequency_content(cycle_data, sampling_rate=150):\n    \"\"\"Analyze frequency content of gait cycles.\"\"\"\n    # Apply FFT to each cycle\n    fft_results = []\n\n    for cycle in cycle_data:\n        fft_result = fft(cycle)\n        fft_results.append(np.abs(fft_result))\n\n    # Average frequency spectrum\n    avg_spectrum = np.mean(fft_results, axis=0)\n    freqs = fftfreq(len(cycle_data[0]), 1/sampling_rate)\n\n    # Find dominant frequencies\n    positive_freqs = freqs[:len(freqs)//2]\n    positive_spectrum = avg_spectrum[:len(avg_spectrum)//2]\n\n    dominant_freq_idx = np.argmax(positive_spectrum[1:]) + 1  # Skip DC component\n    dominant_frequency = positive_freqs[dominant_freq_idx]\n\n    return {\n        'frequencies': positive_freqs,\n        'spectrum': positive_spectrum,\n        'dominant_frequency': dominant_frequency,\n        'spectral_centroid': np.sum(positive_freqs * positive_spectrum) / np.sum(positive_spectrum)\n    }\n\n# 4. Cross-correlation analysis\ndef calculate_joint_coordination(data, joint1_var, joint2_var):\n    \"\"\"Calculate coordination between joints using cross-correlation.\"\"\"\n    coordination_results = []\n\n    for (subject, task, step), group in data.groupby(['subject', 'task', 'step']):\n        joint1_data = group.sort_values('phase_percent')[joint1_var].values\n        joint2_data = group.sort_values('phase_percent')[joint2_var].values\n\n        # Calculate cross-correlation\n        correlation = signal.correlate(joint1_data, joint2_data, mode='full')\n        lags = signal.correlation_lags(len(joint1_data), len(joint2_data), mode='full')\n\n        # Find peak correlation and lag\n        max_corr_idx = np.argmax(np.abs(correlation))\n        max_correlation = correlation[max_corr_idx]\n        lag_at_max_corr = lags[max_corr_idx]\n\n        coordination_results.append({\n            'subject': subject,\n            'task': task,\n            'step': step,\n            'max_correlation': max_correlation,\n            'lag_at_max_correlation': lag_at_max_corr,\n            'phase_lag_percent': (lag_at_max_corr / len(joint1_data)) * 100\n        })\n\n    return pd.DataFrame(coordination_results)\n\n# Example: Hip-knee coordination\nhip_knee_coord = calculate_joint_coordination(\n    data, 'hip_flexion_angle_ipsi_rad', 'knee_flexion_angle_ipsi_rad'\n)\n</code></pre> <pre><code>% Time series analysis functions\n\n% 1. Smoothing and filtering\nfunction smoothed_data = smoothGaitData(data, method, varargin)\n    switch method\n        case 'savgol'\n            p = inputParser;\n            addParameter(p, 'WindowLength', 15, @isnumeric);\n            addParameter(p, 'PolynomialOrder', 3, @isnumeric);\n            parse(p, varargin{:});\n\n            smoothed_data = sgolayfilt(data, p.Results.PolynomialOrder, p.Results.WindowLength);\n\n        case 'gaussian'\n            p = inputParser;\n            addParameter(p, 'Sigma', 2, @isnumeric);\n            parse(p, varargin{:});\n\n            % Create Gaussian kernel\n            kernel_size = ceil(6 * p.Results.Sigma);\n            x = -kernel_size:kernel_size;\n            kernel = exp(-x.^2 / (2 * p.Results.Sigma^2));\n            kernel = kernel / sum(kernel);\n\n            smoothed_data = conv(data, kernel, 'same');\n\n        case 'moving_average'\n            p = inputParser;\n            addParameter(p, 'Window', 10, @isnumeric);\n            parse(p, varargin{:});\n\n            smoothed_data = movmean(data, p.Results.Window);\n    end\nend\n\n% Apply smoothing to dataset\nsmoothed_table = data;\n[groups, subjects, tasks, steps] = findgroups(data.subject, data.task, data.step);\n\nsmoothed_knee = splitapply(@(x) smoothGaitData(x, 'savgol', 'WindowLength', 15), ...\n    data.knee_flexion_angle_ipsi_rad, groups);\n\n% Reconstruct smoothed data\nsmoothed_table.knee_flexion_angle_ipsi_rad_smooth = smoothed_knee;\n\n% 2. Gait cycle variability analysis\nfunction metrics = calculateVariabilityMetrics(data, variable)\n    [groups, ~] = findgroups(data.subject, data.task, data.step);\n    cycles = splitapply(@(phase, var) var(phase == sort(unique(phase))), ...\n        data.phase_percent, data.(variable), groups);\n\n    cycles_matrix = cell2mat(cycles');\n\n    metrics.mean_pattern = mean(cycles_matrix, 1);\n    metrics.std_pattern = std(cycles_matrix, 0, 1);\n    metrics.cv_pattern = std(cycles_matrix, 0, 1) ./ abs(mean(cycles_matrix, 1));\n    metrics.coefficient_of_variation = mean(metrics.cv_pattern);\n    metrics.range_of_motion_variability = std(range(cycles_matrix, 2));\n\n    % Peak timing variability\n    [~, peak_indices] = max(cycles_matrix, [], 2);\n    metrics.peak_timing_variability = std(peak_indices);\nend\n\n% 3. Frequency domain analysis\nfunction freq_analysis = analyzeFrequencyContent(cycle_data, sampling_rate)\n    if nargin &lt; 2\n        sampling_rate = 150;\n    end\n\n    % Apply FFT to each cycle\n    fft_results = zeros(size(cycle_data));\n    for i = 1:size(cycle_data, 1)\n        fft_results(i, :) = abs(fft(cycle_data(i, :)));\n    end\n\n    % Average frequency spectrum\n    avg_spectrum = mean(fft_results, 1);\n    freqs = 0:(sampling_rate/length(avg_spectrum)):(sampling_rate/2);\n\n    % Keep positive frequencies only\n    n_pos = floor(length(avg_spectrum)/2) + 1;\n    positive_spectrum = avg_spectrum(1:n_pos);\n    positive_freqs = freqs(1:n_pos);\n\n    % Find dominant frequency (skip DC component)\n    [~, dominant_idx] = max(positive_spectrum(2:end));\n    dominant_idx = dominant_idx + 1;\n\n    freq_analysis.frequencies = positive_freqs;\n    freq_analysis.spectrum = positive_spectrum;\n    freq_analysis.dominant_frequency = positive_freqs(dominant_idx);\n    freq_analysis.spectral_centroid = sum(positive_freqs .* positive_spectrum) / sum(positive_spectrum);\nend\n\n% 4. Cross-correlation analysis\nfunction coord_results = calculateJointCoordination(data, joint1_var, joint2_var)\n    [groups, subjects, tasks, steps] = findgroups(data.subject, data.task, data.step);\n\n    coord_data = table();\n    coord_data.subject = subjects;\n    coord_data.task = tasks;\n    coord_data.step = steps;\n\n    % Calculate coordination metrics for each cycle\n    max_correlations = splitapply(@(j1, j2) calculateCrossCorr(j1, j2), ...\n        data.(joint1_var), data.(joint2_var), groups);\n\n    coord_data.max_correlation = max_correlations;\n    coord_results = coord_data;\nend\n\nfunction max_corr = calculateCrossCorr(joint1_data, joint2_data)\n    % Sort by phase\n    [joint1_sorted, sort_idx] = sort(joint1_data);\n    joint2_sorted = joint2_data(sort_idx);\n\n    % Calculate cross-correlation\n    [correlation, lags] = xcorr(joint1_sorted, joint2_sorted);\n\n    % Find maximum correlation\n    [max_corr, ~] = max(abs(correlation));\nend\n</code></pre>"},{"location":"user_guide/working_with_data/#advanced-visualization","title":"Advanced Visualization","text":"<p>Create publication-quality figures:</p> Python <pre><code>import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib.patches import Rectangle\nimport matplotlib.patches as mpatches\n\n# Set publication style\nplt.style.use(['seaborn-v0_8-paper', 'seaborn-v0_8-colorblind'])\n\n# 1. Multi-panel comparison figure\ndef create_publication_figure(data, save_path='publication_figure.png'):\n    \"\"\"Create publication-ready multi-panel figure.\"\"\"\n    fig = plt.figure(figsize=(12, 10))\n    gs = fig.add_gridspec(3, 3, hspace=0.4, wspace=0.4)\n\n    # Panel A: Average patterns by task\n    ax1 = fig.add_subplot(gs[0, :2])\n\n    colors = plt.cm.Set2(np.linspace(0, 1, len(data['task'].unique())))\n\n    for i, task in enumerate(data['task'].unique()):\n        task_data = data[data['task'] == task]\n\n        # Calculate mean and SEM\n        mean_pattern = task_data.groupby('phase_percent')['knee_flexion_angle_ipsi_rad'].mean()\n        sem_pattern = task_data.groupby('phase_percent')['knee_flexion_angle_ipsi_rad'].sem()\n\n        phase = mean_pattern.index\n        mean_deg = np.degrees(mean_pattern.values)\n        sem_deg = np.degrees(sem_pattern.values)\n\n        # Plot mean with error band\n        ax1.plot(phase, mean_deg, color=colors[i], linewidth=2, \n                label=task.replace('_', ' ').title())\n        ax1.fill_between(phase, mean_deg - sem_deg, mean_deg + sem_deg, \n                       color=colors[i], alpha=0.2)\n\n    ax1.set_xlabel('Gait Cycle (%)')\n    ax1.set_ylabel('Knee Flexion Angle (\u00b0)')\n    ax1.set_title('A. Average Gait Patterns by Task', fontweight='bold')\n    ax1.legend(frameon=True, fancybox=True, shadow=True)\n    ax1.grid(True, alpha=0.3)\n\n    # Add gait phase annotations\n    ax1.axvspan(0, 60, alpha=0.1, color='blue', label='Stance')\n    ax1.axvspan(60, 100, alpha=0.1, color='red', label='Swing')\n\n    # Panel B: Variability comparison\n    ax2 = fig.add_subplot(gs[0, 2])\n\n    # Calculate coefficient of variation for each task\n    cv_data = []\n    for task in data['task'].unique():\n        task_data = data[data['task'] == task]\n        cv_by_cycle = task_data.groupby(['subject', 'step'])['knee_flexion_angle_ipsi_rad'].apply(\n            lambda x: np.std(x) / np.abs(np.mean(x)) if np.mean(x) != 0 else 0\n        )\n        cv_data.extend([(task, cv) for cv in cv_by_cycle])\n\n    cv_df = pd.DataFrame(cv_data, columns=['Task', 'CV'])\n\n    box_plot = ax2.boxplot([cv_df[cv_df['Task'] == task]['CV'].values \n                           for task in data['task'].unique()],\n                          labels=[task.replace('_', '\\n') for task in data['task'].unique()],\n                          patch_artist=True)\n\n    for patch, color in zip(box_plot['boxes'], colors):\n        patch.set_facecolor(color)\n        patch.set_alpha(0.7)\n\n    ax2.set_ylabel('Coefficient of Variation')\n    ax2.set_title('B. Gait Variability', fontweight='bold')\n    ax2.grid(True, alpha=0.3)\n\n    # Panel C: Joint coordination\n    ax3 = fig.add_subplot(gs[1, :])\n\n    # Create coordination plot (hip vs knee)\n    for i, task in enumerate(data['task'].unique()):\n        task_data = data[data['task'] == task]\n\n        # Sample one representative cycle\n        sample_cycle = task_data[task_data['step'] == 1]\n        if len(sample_cycle) &gt; 0:\n            hip_angle = np.degrees(sample_cycle['hip_flexion_angle_ipsi_rad'])\n            knee_angle = np.degrees(sample_cycle['knee_flexion_angle_ipsi_rad'])\n\n            ax3.plot(hip_angle, knee_angle, color=colors[i], linewidth=2,\n                    alpha=0.8, label=task.replace('_', ' ').title())\n\n            # Mark start and end points\n            ax3.scatter(hip_angle.iloc[0], knee_angle.iloc[0], \n                       color=colors[i], s=50, marker='o', zorder=5)\n            ax3.scatter(hip_angle.iloc[-1], knee_angle.iloc[-1], \n                       color=colors[i], s=50, marker='s', zorder=5)\n\n    ax3.set_xlabel('Hip Flexion Angle (\u00b0)')\n    ax3.set_ylabel('Knee Flexion Angle (\u00b0)')\n    ax3.set_title('C. Hip-Knee Coordination Patterns', fontweight='bold')\n    ax3.legend()\n    ax3.grid(True, alpha=0.3)\n\n    # Panel D: Statistical comparison\n    ax4 = fig.add_subplot(gs[2, :2])\n\n    # Create violin plot for peak knee flexion\n    peak_data = []\n    for task in data['task'].unique():\n        task_data = data[data['task'] == task]\n        peaks = task_data.groupby(['subject', 'step'])['knee_flexion_angle_ipsi_rad'].max()\n        peak_data.extend([(task, np.degrees(peak)) for peak in peaks])\n\n    peak_df = pd.DataFrame(peak_data, columns=['Task', 'Peak_Knee'])\n\n    violin_parts = ax4.violinplot([peak_df[peak_df['Task'] == task]['Peak_Knee'].values \n                                  for task in data['task'].unique()],\n                                 positions=range(len(data['task'].unique())),\n                                 showmeans=True, showmedians=True)\n\n    for i, pc in enumerate(violin_parts['bodies']):\n        pc.set_facecolor(colors[i])\n        pc.set_alpha(0.7)\n\n    ax4.set_xticks(range(len(data['task'].unique())))\n    ax4.set_xticklabels([task.replace('_', '\\n') for task in data['task'].unique()])\n    ax4.set_ylabel('Peak Knee Flexion (\u00b0)')\n    ax4.set_title('D. Peak Flexion Distribution', fontweight='bold')\n    ax4.grid(True, alpha=0.3)\n\n    # Panel E: Quality metrics\n    ax5 = fig.add_subplot(gs[2, 2])\n\n    # Calculate quality metrics\n    cycle_counts = data.groupby(['subject', 'task', 'step']).size()\n    complete_cycles = (cycle_counts == 150).sum()\n    total_cycles = len(cycle_counts)\n\n    missing_data = data.isnull().sum().sum()\n    total_points = data.size\n\n    outliers = np.abs(data['knee_flexion_angle_ipsi_rad'] - \n                     data['knee_flexion_angle_ipsi_rad'].mean()) &gt; \\\n              3 * data['knee_flexion_angle_ipsi_rad'].std()\n    outlier_count = outliers.sum()\n\n    quality_metrics = [\n        ('Complete\\nCycles', (complete_cycles/total_cycles)*100),\n        ('Data\\nCompleteness', ((total_points-missing_data)/total_points)*100),\n        ('Inlier\\nData', ((len(data)-outlier_count)/len(data))*100)\n    ]\n\n    labels, values = zip(*quality_metrics)\n    bars = ax5.bar(labels, values, color=['green', 'blue', 'orange'], alpha=0.7)\n\n    ax5.set_ylabel('Quality Score (%)')\n    ax5.set_title('E. Data Quality', fontweight='bold')\n    ax5.set_ylim(0, 105)\n\n    # Add percentage labels on bars\n    for bar, value in zip(bars, values):\n        ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold')\n\n    # Add overall figure title and save\n    fig.suptitle('Comprehensive Gait Analysis', fontsize=16, fontweight='bold')\n\n    plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')\n    plt.show()\n\n    return fig\n\n# Create the publication figure\nfig = create_publication_figure(data)\n</code></pre>"},{"location":"user_guide/working_with_data/#export-and-integration","title":"Export and Integration","text":"<p>Prepare data for external analysis tools:</p> Python <pre><code># Export to various formats for different analysis tools\n\n# 1. Export for statistical software (R, SPSS, SAS)\ndef export_for_statistics(data, output_dir='statistical_exports'):\n    \"\"\"Export data in formats suitable for statistical analysis.\"\"\"\n    import os\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Create cycle-level summary for statistical analysis\n    cycle_summary = data.groupby(['subject', 'task', 'step']).agg({\n        'knee_flexion_angle_ipsi_rad': ['min', 'max', 'mean', 'std'],\n        'hip_flexion_angle_ipsi_rad': ['min', 'max', 'mean', 'std'],\n        'ankle_flexion_angle_ipsi_rad': ['min', 'max', 'mean', 'std']\n    }).round(6)\n\n    # Flatten column names\n    cycle_summary.columns = ['_'.join(col).strip() for col in cycle_summary.columns]\n    cycle_summary = cycle_summary.reset_index()\n\n    # Add derived variables\n    cycle_summary['knee_rom'] = (cycle_summary['knee_flexion_angle_ipsi_rad_max'] - \n                                cycle_summary['knee_flexion_angle_ipsi_rad_min'])\n\n    # Export formats\n    cycle_summary.to_csv(f'{output_dir}/cycle_summary.csv', index=False)\n    cycle_summary.to_excel(f'{output_dir}/cycle_summary.xlsx', index=False)\n\n    # For R\n    cycle_summary.to_csv(f'{output_dir}/data_for_R.csv', index=False)\n\n    # For SPSS (with variable labels)\n    import json\n    variable_labels = {\n        'subject': 'Subject ID',\n        'task': 'Locomotion Task',\n        'step': 'Gait Cycle Number',\n        'knee_flexion_angle_ipsi_rad_mean': 'Mean Knee Flexion Angle (rad)',\n        'knee_rom': 'Knee Range of Motion (rad)'\n    }\n\n    with open(f'{output_dir}/variable_labels.json', 'w') as f:\n        json.dump(variable_labels, f, indent=2)\n\n    print(f\"Statistical exports saved to '{output_dir}/'\")\n\n# 2. Export for machine learning\ndef export_for_ml(data, output_dir='ml_exports', test_size=0.2):\n    \"\"\"Export data formatted for machine learning applications.\"\"\"\n    import os\n    from sklearn.model_selection import train_test_split\n    from sklearn.preprocessing import LabelEncoder, StandardScaler\n\n    os.makedirs(output_dir, exist_ok=True)\n\n    # Create feature matrix (each row is one gait cycle)\n    features = []\n    labels = []\n    metadata = []\n\n    for (subject, task, step), group in data.groupby(['subject', 'task', 'step']):\n        if len(group) == 150:  # Only complete cycles\n            # Features: time series of joint angles\n            cycle_features = np.concatenate([\n                group['knee_flexion_angle_ipsi_rad'].values,\n                group['hip_flexion_angle_ipsi_rad'].values,\n                group['ankle_flexion_angle_ipsi_rad'].values\n            ])\n\n            features.append(cycle_features)\n            labels.append(task)\n            metadata.append({'subject': subject, 'task': task, 'step': step})\n\n    # Convert to arrays\n    X = np.array(features)\n    y = np.array(labels)\n\n    # Encode labels\n    le = LabelEncoder()\n    y_encoded = le.fit_transform(y)\n\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y_encoded, test_size=test_size, stratify=y_encoded, random_state=42\n    )\n\n    # Save datasets\n    np.save(f'{output_dir}/X_train.npy', X_train)\n    np.save(f'{output_dir}/X_test.npy', X_test)\n    np.save(f'{output_dir}/y_train.npy', y_train)\n    np.save(f'{output_dir}/y_test.npy', y_test)\n\n    # Save label encoder and metadata\n    import pickle\n    with open(f'{output_dir}/label_encoder.pkl', 'wb') as f:\n        pickle.dump(le, f)\n\n    with open(f'{output_dir}/metadata.json', 'w') as f:\n        json.dump({\n            'feature_names': ['knee_angle', 'hip_angle', 'ankle_angle'],\n            'feature_length': 150,\n            'total_features': X.shape[1],\n            'classes': le.classes_.tolist(),\n            'train_samples': len(X_train),\n            'test_samples': len(X_test)\n        }, f, indent=2)\n\n    print(f\"ML exports saved to '{output_dir}/'\")\n    print(f\"Feature matrix shape: {X.shape}\")\n    print(f\"Classes: {le.classes_}\")\n\n# 3. Export for biomechanical software (OpenSim, Visual3D)\ndef export_for_biomech_software(data, output_dir='biomech_exports'):\n    \"\"\"Export data for biomechanical analysis software.\"\"\"\n    import os\n    os.makedirs(output_dir, exist_ok=True)\n\n    # OpenSim compatible format\n    opensim_data = data.copy()\n    opensim_data['time'] = opensim_data['phase_percent'] / 100  # Normalize to 0-1\n\n    # Rename columns to OpenSim convention\n    column_mapping = {\n        'knee_flexion_angle_ipsi_rad': 'knee_angle_r',\n        'hip_flexion_angle_ipsi_rad': 'hip_flexion_r', \n        'ankle_flexion_angle_ipsi_rad': 'ankle_angle_r'\n    }\n\n    opensim_data = opensim_data.rename(columns=column_mapping)\n\n    # Save by task and subject\n    for task in opensim_data['task'].unique():\n        task_data = opensim_data[opensim_data['task'] == task]\n\n        for subject in task_data['subject'].unique():\n            subject_data = task_data[task_data['subject'] == subject]\n\n            # Create OpenSim-style .sto file\n            filename = f'{output_dir}/{subject}_{task}_kinematics.sto'\n\n            with open(filename, 'w') as f:\n                # Write header\n                f.write('Coordinates\\n')\n                f.write('version=1\\n')\n                f.write(f'nRows={len(subject_data)}\\n')\n                f.write('nColumns=5\\n')  # time + 4 angles\n                f.write('inDegrees=no\\n')\n                f.write('endheader\\n')\n\n                # Write column headers\n                f.write('time\\tknee_angle_r\\thip_flexion_r\\tankle_angle_r\\n')\n\n                # Write data\n                for _, row in subject_data.iterrows():\n                    f.write(f\"{row['time']:.6f}\\t{row['knee_angle_r']:.6f}\\t\"\n                           f\"{row['hip_flexion_r']:.6f}\\t{row['ankle_angle_r']:.6f}\\n\")\n\n    print(f\"Biomechanical software exports saved to '{output_dir}/'\")\n\n# Run exports\nexport_for_statistics(data)\nexport_for_ml(data)\nexport_for_biomech_software(data)\n</code></pre>"},{"location":"user_guide/working_with_data/#performance-optimization-tips","title":"Performance Optimization Tips","text":"<ol> <li>Memory Management: Use appropriate data types and chunked processing</li> <li>Vectorization: Prefer pandas/numpy operations over loops</li> <li>Indexing: Set appropriate indexes for faster groupby operations</li> <li>Caching: Cache expensive computations using <code>functools.lru_cache</code></li> <li>Parallel Processing: Use <code>multiprocessing</code> for independent computations</li> </ol>"},{"location":"user_guide/working_with_data/#next-steps","title":"Next Steps","text":"<ul> <li>Validation Reports - Understanding quality assessment</li> <li>Troubleshooting - Common issues and solutions</li> <li>API Reference - Complete function documentation</li> </ul> <p>These advanced techniques enable sophisticated analysis of standardized locomotion data. For specific use cases, consult the API Reference or Tutorials.</p>"}]}