{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NZtcDwhoFEn",
        "outputId": "29169b27-8230-426c-d8e9-bd1a66795bcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/locodata_Gtech/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1UsTvz4oJsi",
        "outputId": "fe5181e8-f3e2-45ee-8c13-69704aad81f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/locodata_Gtech\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import re"
      ],
      "metadata": {
        "id": "VuvimHHToGW7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "# User configuration section\n",
        "\n",
        "# This is the base path to the dataset. If you extracted the dataset to the\n",
        "# same folder as this file, you don't need to change this\n",
        "base_path = './rawdata'\n",
        "\n",
        "# This is the list of data types that we want to save. The options are:\n",
        "# 'Activity_Flag', 'GroundFrame_GRFs', 'Joint_Angle', 'Joint_Moments',\n",
        "# 'Joint_Powers', 'Joint_Velocities', 'Raw_EMGs', 'Real_IMUs', 'Virtual_IMUs',\n",
        "# 'Virtual_Insoles', 'Link_Angle',\n",
        "# Currently the only standardized names are\n",
        "# 'Joint_Angle', 'Joint_Velocities', 'Joint_Moments', 'Link_Angle'\n",
        "data_to_save = ['Joint_Moments', 'Joint_Angle',\n",
        "                'Joint_Velocities', 'Link_Angle', 'Link_Velocities',\"GroundFrame_GRFs\"]\n",
        "\n",
        "###############################################################################\n",
        "# Don't modify anything below this line\n",
        "\n",
        "# These are used to convert the activity names to a shorter version\n",
        "short_activity_names = ['ball_toss', 'curb_down', 'curb_up', 'cutting',\n",
        "                        'dynamic_walk', 'incline_walk', 'jump', 'lift_weight',\n",
        "                        'lunges', 'meander', 'normal_walk', 'obstacle_walk',\n",
        "                        'poses', 'push', 'side_shuffle', 'sit_to_stand',\n",
        "                        'squats', 'stairs', 'step_ups', 'tire_run',\n",
        "                        'tug_of_war', 'turn_and_step', 'twister',\n",
        "                        'walk_backward', 'weighted_walk']\n",
        "\n",
        "standard_column_names = {\n",
        "\n",
        "    # Joint Angle\n",
        "    'hip_flexion_r':'hip_angle_s_r',\n",
        "    'hip_adduction_r':'hip_angle_f_r',\n",
        "    'hip_rotation_r':'hip_angle_t_r',\n",
        "    'knee_angle_r':'knee_angle_s_r',\n",
        "    'ankle_angle_r':'ankle_angle_s_r',\n",
        "    'subtalar_angle_r':'ankle_angle_f_r',\n",
        "\n",
        "    'hip_flexion_l':'hip_angle_s_l',\n",
        "    'hip_adduction_l':'hip_angle_f_l',\n",
        "    'hip_rotation_l':'hip_angle_t_l',\n",
        "    'knee_angle_l':'knee_angle_s_l',\n",
        "    'ankle_angle_l':'ankle_angle_s_l',\n",
        "    'subtalar_angle_l':'ankle_angle_f_l',\n",
        "\n",
        "    # Joint Velocities\n",
        "    'hip_flexion_velocity_r': 'hip_vel_s_r',\n",
        "    'hip_adduction_velocity_r': 'hip_vel_f_r',\n",
        "    'hip_rotation_velocity_r': 'hip_vel_t_r',\n",
        "    'knee_velocity_r': 'knee_vel_s_r',\n",
        "    'ankle_velocity_r': 'ankle_vel_s_r',\n",
        "    'subtalar_velocity_r': 'ankle_vel_f_r',\n",
        "\n",
        "    'hip_flexion_velocity_l': 'hip_vel_s_l',\n",
        "    'hip_adduction_velocity_l': 'hip_vel_f_l',\n",
        "    'hip_rotation_velocity_l': 'hip_vel_t_l',\n",
        "    'knee_velocity_l': 'knee_vel_s_l',\n",
        "    'ankle_velocity_l': 'ankle_vel_s_l',\n",
        "    'subtalar_velocity_l': 'ankle_vel_f_l',\n",
        "\n",
        "    # Joint Moments\n",
        "    'hip_flexion_r_moment': 'hip_torque_s_r',\n",
        "    'hip_adduction_r_moment': 'hip_torque_f_r',\n",
        "    'hip_rotation_r_moment': 'hip_torque_t_r',\n",
        "    'knee_angle_r_moment': 'knee_torque_s_r',\n",
        "    'ankle_angle_r_moment': 'ankle_torque_s_r',\n",
        "    'subtalar_angle_r_moment': 'ankle_torque_f_r',\n",
        "\n",
        "    'hip_flexion_l_moment': 'hip_torque_s_l',\n",
        "    'hip_adduction_l_moment': 'hip_torque_f_l',\n",
        "    'hip_rotation_l_moment': 'hip_torque_t_l',\n",
        "    'knee_angle_l_moment': 'knee_torque_s_l',\n",
        "    'ankle_angle_l_moment': 'ankle_torque_s_l',\n",
        "    'subtalar_angle_l_moment': 'ankle_torque_f_l',\n",
        "\n",
        "    # Link Angle\n",
        "    'pelvis_Y':'pelvis_angle_f',\n",
        "    'pelvis_Z':'pelvis_angle_s',\n",
        "    'pelvis_X':'pelvis_angle_t',\n",
        "    'torso_Y':'torso_angle_f',\n",
        "    'torso_Z':'torso_angle_s',\n",
        "    'torso_X':'torso_angle_t',\n",
        "\n",
        "    'femur_r_Y':'thigh_angle_f_r',\n",
        "    'femur_r_Z':'thigh_angle_s_r',\n",
        "    'femur_r_X':'thigh_angle_t_r',\n",
        "    'tibia_r_Y':'shank_angle_f_r',\n",
        "    'tibia_r_Z':'shank_angle_s_r',\n",
        "    'tibia_r_X':'shank_angle_t_r',\n",
        "    'talus_r_Y':'talus_angle_f_r',\n",
        "    'talus_r_Z':'talus_angle_s_r',\n",
        "    'talus_r_X':'talus_angle_t_r',\n",
        "    'calcn_r_Y':'foot_angle_f_r',\n",
        "    'calcn_r_Z':'foot_angle_s_r',\n",
        "    'calcn_r_X':'foot_angle_t_r',\n",
        "    'toes_r_Y':'toes_angle_f_r',\n",
        "    'toes_r_Z':'toes_angle_s_r',\n",
        "    'toes_r_X':'toes_angle_t_r',\n",
        "\n",
        "    'femur_l_Y':'thigh_angle_f_l',\n",
        "    'femur_l_Z':'thigh_angle_s_l',\n",
        "    'femur_l_X':'thigh_angle_t_l',\n",
        "    'tibia_l_Y':'shank_angle_f_l',\n",
        "    'tibia_l_Z':'shank_angle_s_l',\n",
        "    'tibia_l_X':'shank_angle_t_l',\n",
        "    'talus_l_Y':'talus_angle_f_l',\n",
        "    'talus_l_Z':'talus_angle_s_l',\n",
        "    'talus_l_X':'talus_angle_t_l',\n",
        "    'calcn_l_Y':'foot_angle_f_l',\n",
        "    'calcn_l_Z':'foot_angle_s_l',\n",
        "    'calcn_l_X':'foot_angle_t_l',\n",
        "    'toes_l_Y':'toes_angle_f_l',\n",
        "    'toes_l_Z':'toes_angle_s_l',\n",
        "    'toes_l_X':'toes_angle_t_l',\n",
        "\n",
        "    # Link Velocities\n",
        "    'pelvis_vel_Y':'pelvis_vel_f',\n",
        "    'pelvis_vel_Z':'pelvis_vel_s',\n",
        "    'pelvis_vel_X':'pelvis_vel_t',\n",
        "    'torso_vel_Y':'torso_vel_f',\n",
        "    'torso_vel_Z':'torso_vel_s',\n",
        "    'torso_vel_X':'torso_vel_t',\n",
        "    'femur_r_vel_Y':'thigh_vel_f_r',\n",
        "    'femur_r_vel_Z':'thigh_vel_s_r',\n",
        "    'femur_r_vel_X':'thigh_vel_t_r',\n",
        "    'tibia_r_vel_Y':'shank_vel_f_r',\n",
        "    'tibia_r_vel_Z':'shank_vel_s_r',\n",
        "    'tibia_r_vel_X':'shank_vel_t_r',\n",
        "    'talus_r_vel_Y':'talus_vel_f_r',\n",
        "    'talus_r_vel_Z':'talus_vel_s_r',\n",
        "    'talus_r_vel_X':'talus_vel_t_r',\n",
        "    'calcn_r_vel_Y':'foot_vel_f_r',\n",
        "    'calcn_r_vel_Z':'foot_vel_s_r',\n",
        "    'calcn_r_vel_X':'foot_vel_t_r',\n",
        "    'toes_r_vel_Y':'toes_vel_f_r',\n",
        "    'toes_r_vel_Z':'toes_vel_s_r',\n",
        "    'toes_r_vel_X':'toes_vel_t_r',\n",
        "\n",
        "    'femur_l_vel_Y':'thigh_vel_f_l',\n",
        "    'femur_l_vel_Z':'thigh_vel_s_l',\n",
        "    'femur_l_vel_X':'thigh_vel_t_l',\n",
        "    'tibia_l_vel_Y':'shank_vel_f_l',\n",
        "    'tibia_l_vel_Z':'shank_vel_s_l',\n",
        "    'tibia_l_vel_X':'shank_vel_t_l',\n",
        "    'talus_l_vel_Y':'talus_vel_f_l',\n",
        "    'talus_l_vel_Z':'talus_vel_s_l',\n",
        "    'talus_l_vel_X':'talus_vel_t_l',\n",
        "    'calcn_l_vel_Y':'foot_vel_f_l',\n",
        "    'calcn_l_vel_Z':'foot_vel_s_l',\n",
        "    'calcn_l_vel_X':'foot_vel_t_l',\n",
        "    'toes_l_vel_Y':'toes_vel_f_l',\n",
        "    'toes_l_vel_Z':'toes_vel_s_l',\n",
        "    'toes_l_vel_X':'toes_vel_t_l',\n",
        "\n",
        "    #GRF\n",
        "    # From z*x=y coordinate to x*y=z\n",
        "\n",
        "    \"RForceX\": \"GRF_x_r\",\n",
        "    \"RForceY_Vertical\": \"GRF_z_r\",\n",
        "    \"RForceZ\": \"GRF_y_r\",\n",
        "    \"RCOPX\": \"COP_x_r\",\n",
        "    \"RCOPY_Vertical\": \"COP_z_r\",\n",
        "    \"RCOPZ\": \"COP_y_r\",\n",
        "    \"LForceX\": \"GRF_x_l\",\n",
        "    \"LForceY_Vertical\": \"GRF_z_l\",\n",
        "    \"LForceZ\": \"GRF_y_l\",\n",
        "    \"LCOPX\": \"COP_x_l\",\n",
        "    \"LCOPY_Vertical\": \"COP_z_l\",\n",
        "    \"LCOPZ\": \"COP_y_l\",\n",
        "}\n",
        "\n",
        "\n",
        "# Create a function that will fix joint angle conventions. In the dataset the\n",
        "cols_to_flip_signs = [\n",
        "     # Flip knee torques\n",
        "    # 'knee_torque_s_r','knee_torque_s_l',\n",
        "    # From z*x=y coordinate to x*y=z\n",
        "    \"COP_x_r\",\n",
        "    \"COP_x_l\",\n",
        "    \"COP_y_r\",\n",
        "    \"COP_y_l\",\n",
        "    \"GRF_x_r\",\n",
        "    \"GRF_x_l\",\n",
        "    \"GRF_y_r\",\n",
        "    \"GRF_y_l\"\n",
        "]"
      ],
      "metadata": {
        "id": "ZZJ9qYj0oKZB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This function is meant to convert the dataset to a pandas dataframe\n",
        "'''\n",
        "# First, get a list of all the files that are available in the dataset\n",
        "# Then we will filter down to the files that we are interested in saving,\n",
        "# and then append them to a dataframe\n",
        "file_list = []\n",
        "# Get the subject folders\n",
        "subject_dirs = os.listdir(base_path)\n",
        "pattern = re.compile(r'^[^a-zA-Z]')\n",
        "\n",
        "# Use list comprehension to filter out strings that start with non-letter characters\n",
        "subject_dirs = [string for string in subject_dirs if not pattern.match(string)]\n",
        "print(subject_dirs)\n",
        "\n",
        "\n",
        "# Remove the Subject_masses.csv file\n",
        "try:\n",
        "    subject_dirs.remove('Subject_masses.csv')\n",
        "\n",
        "except ValueError:\n",
        "    pass\n",
        "\n",
        "# Remove pycache\n",
        "try:\n",
        "\n",
        "    subject_dirs.remove('__pycache__')\n",
        "except ValueError:\n",
        "    pass\n",
        "\n",
        "# (1) Create a list of all the files that we want to potentially save\n",
        "for subject in tqdm(subject_dirs):\n",
        "    # Loop through the activity folders\n",
        "    for activity in os.listdir(os.path.join(base_path, subject, \"CSV_Data\")):\n",
        "        # Loop through the files\n",
        "        for file in os.listdir(os.path.join(base_path, subject,\n",
        "                                            \"CSV_Data\", activity)):\n",
        "            # Append the file to the list\n",
        "            file_list.append((subject, activity, file))\n",
        "\n",
        "# Create an dictionary to store the dataframes for a subject and activity\n",
        "# The keys will be a tuple of (subject, activity). This will be used to\n",
        "# concatenate the dataframes later\n",
        "dataframes = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFPw3vs8odMJ",
        "outputId": "6493f0e9-8e67-4aa0-9340-c60d6aa33c77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AB01', 'AB02', 'AB03', 'AB05', 'AB06', 'AB07', 'AB08', 'AB09', 'AB10', 'AB11', 'AB12', 'AB13']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:42<00:00,  3.53s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (2) Loop through the files and decide if we want to keep it. If we do\n",
        "    # keep it, append it to the dictionary\n",
        "print(\"Start picking\\n\")\n",
        "for file_wrap in tqdm(file_list):\n",
        "    subject, activity, file_name=file_wrap\n",
        "    # Get the data unit (moment_filt, angle, velocity, etc)\n",
        "    data_unit = file_name.split('.')[0]\n",
        "\n",
        "    # If the data type is not in the list of data to save, skip it\n",
        "    if data_unit not in data_to_save:\n",
        "        continue\n",
        "\n",
        "    # Show the progress on the same line\n",
        "    #print(f'Processing {subject} {activity} {data_unit}'+' '*20, end='\\r')\n",
        "\n",
        "    # Get the file path\n",
        "    file_path = os.path.join(base_path, subject, \"CSV_Data\", activity, file_name)\n",
        "\n",
        "    # Read the file into a dataframe\n",
        "    df = pd.read_csv(file_path, header=0)\n",
        "\n",
        "    # Add the subject and activity to the dictionary\n",
        "    if (subject, activity) not in dataframes.keys():\n",
        "        dataframes[(subject, activity)] = []\n",
        "\n",
        "    # Add the dataframe to the dictionary\n",
        "    dataframes[(subject, activity)].append((data_unit,df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_530k-uaoeH_",
        "outputId": "38ff8951-51b0-4fcf-d454-6016388a1e4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start picking\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4880/4880 [12:10<00:00,  6.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (3) For all the (subject, activity) tuples, horizontally concatenate the\n",
        "# dataframes. Additionally add the global angles if they are in the\n",
        "# data_to_save list (assuming they have been calculated with\n",
        "# convert_gtech_nc_rotm_to_eul_csv.m)\n",
        "print(\"Start processing \\n\")\n",
        "#Create an empty dataframe\n",
        "df_total = pd.DataFrame()\n",
        "\n",
        "\n",
        "\n",
        "# Log for missing data\n",
        "missing_log= open(\"_datamissing.txt\", \"w\")\n",
        "print(\"hhh\")\n",
        "\n",
        "# Loop through the keys\n",
        "for key_num, key in tqdm(enumerate(dataframes.keys())):\n",
        "\n",
        "  # Show percentage of completion in the same line\n",
        "  #print(f'Processing {key_num+1}/{len(dataframes.keys())}'+' '*30,      end='\\r')\n",
        "\n",
        "  # Verify that we have all the data types that we want\n",
        "  # assert len(dataframes[key]) == len(data_to_save), \\\n",
        "  #     print(f'Missing data for {key}')\n",
        "\n",
        "  #Report data missing in the log, instead of breaking\n",
        "  if len(dataframes[key]) != len(data_to_save):\n",
        "        missing_log.write(f'Missing data for {key}\\n')\n",
        "\n",
        "\n",
        "  # Get the subject and activity\n",
        "  subject = key[0]\n",
        "  activity = key[1]\n",
        "\n",
        "  # Create an empty dataframe to concatenate the data units\n",
        "  _,df =  dataframes[key][0]\n",
        "\n",
        "  # Merge all the dataframes\n",
        "  for data_type,sub_df in dataframes[key][1:]:\n",
        "      df = pd.merge(df, sub_df, on='time')\n",
        "\n",
        "  # Add the activity and subject columns\n",
        "  df['task_info'] = activity\n",
        "  df['subject'] = 'Gtech_2023_' + subject\n",
        "\n",
        "  # Add the activity short name\n",
        "  for short_activity_name in short_activity_names:\n",
        "      if short_activity_name in activity:\n",
        "          df['task'] = short_activity_name\n",
        "          break\n",
        "\n",
        "  # Concatenate the different subject/activities with the rest of the\n",
        "  # dataset\n",
        "  df_total = pd.concat([df_total, df],\n",
        "                        ignore_index=True,\n",
        "                        axis=0)\n",
        "missing_log.close()\n",
        "\n",
        "print(\"Processing done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGpL0V7Qomv-",
        "outputId": "415d6f2f-6a8f-4924-f9cf-dc2b87918a14"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start processing \n",
            "\n",
            "hhh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "488it [05:04,  1.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing done\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (4) Update the column names to the standardized names and flip the signs\n",
        "# of the joint angles and torques\n",
        "\n",
        "df_total.rename(columns=standard_column_names, inplace=True)\n",
        "\n",
        "\n",
        "df_total[cols_to_flip_signs] = df_total[cols_to_flip_signs] * -1\n"
      ],
      "metadata": {
        "id": "Jz9X9hlzon5O"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (5) Save the dataframe\n",
        "\n",
        "print(df_total.columns)\n",
        "df_total.to_parquet('gtech_2023_time.parquet')\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_oCihclosyK",
        "outputId": "b10ac224-3b73-4917-b179-7bceee3f2ab4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['time', 'GRF_x_r', 'GRF_z_r', 'GRF_y_r', 'COP_x_r', 'COP_z_r',\n",
            "       'COP_y_r', 'GRF_x_l', 'GRF_z_l', 'GRF_y_l', 'COP_x_l', 'COP_z_l',\n",
            "       'COP_y_l', 'hip_angle_s_r', 'hip_angle_f_r', 'hip_angle_t_r',\n",
            "       'knee_angle_s_r', 'ankle_angle_s_r', 'ankle_angle_f_r', 'hip_angle_s_l',\n",
            "       'hip_angle_f_l', 'hip_angle_t_l', 'knee_angle_s_l', 'ankle_angle_s_l',\n",
            "       'ankle_angle_f_l', 'hip_torque_s_r', 'hip_torque_f_r', 'hip_torque_t_r',\n",
            "       'hip_torque_s_l', 'hip_torque_f_l', 'hip_torque_t_l', 'knee_torque_s_r',\n",
            "       'knee_torque_s_l', 'ankle_torque_s_r', 'ankle_torque_f_r',\n",
            "       'ankle_torque_s_l', 'ankle_torque_f_l', 'hip_vel_s_r', 'hip_vel_f_r',\n",
            "       'hip_vel_t_r', 'knee_vel_s_r', 'ankle_vel_s_r', 'ankle_vel_f_r',\n",
            "       'hip_vel_s_l', 'hip_vel_f_l', 'hip_vel_t_l', 'knee_vel_s_l',\n",
            "       'ankle_vel_s_l', 'ankle_vel_f_l', 'task_info', 'subject', 'task'],\n",
            "      dtype='object')\n",
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "df = pd.read_parquet('gtech_2023_time.parquet')"
      ],
      "metadata": {
        "id": "aAlGbiQGuEqS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUUQN_KKuQ3v",
        "outputId": "7f85d1c1-0694-4ff2-e91e-b442dd11ca2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           time  GRF_x_r  GRF_z_r  GRF_y_r  COP_x_r   COP_z_r  COP_y_r  \\\n",
            "0         0.000  49.5148  392.192 -3.88129  2.25599  0.010184  2.22944   \n",
            "1         0.005  49.3837  392.100 -3.80472  2.25605  0.010185  2.22913   \n",
            "2         0.010  49.2617  391.966 -3.70034  2.25613  0.010186  2.22878   \n",
            "3         0.015  49.1611  391.804 -3.57638  2.25624  0.010187  2.22839   \n",
            "4         0.020  49.0886  391.639 -3.44562  2.25637  0.010188  2.22800   \n",
            "...         ...      ...      ...      ...      ...       ...      ...   \n",
            "6397782  32.485      NaN      NaN      NaN      NaN       NaN      NaN   \n",
            "6397783  32.490      NaN      NaN      NaN      NaN       NaN      NaN   \n",
            "6397784  32.495      NaN      NaN      NaN      NaN       NaN      NaN   \n",
            "6397785  32.500      NaN      NaN      NaN      NaN       NaN      NaN   \n",
            "6397786  32.505  -0.0000    0.000 -0.00000 -0.00000  0.000000 -0.00000   \n",
            "\n",
            "          GRF_x_l   GRF_z_l   GRF_y_l  ...  ankle_vel_f_r  hip_vel_s_l  \\\n",
            "0        -53.1987  385.2510   4.63867  ...       5.322452    -6.427812   \n",
            "1        -53.1554  385.0160   4.57002  ...       5.301622    -6.371977   \n",
            "2        -53.1131  384.7630   4.49598  ...       5.238688    -6.212236   \n",
            "3        -53.0736  384.5120   4.42434  ...       5.134936    -5.959264   \n",
            "4        -53.0359  384.2750   4.36156  ...       4.994284    -5.620188   \n",
            "...           ...       ...       ...  ...            ...          ...   \n",
            "6397782 -108.1998  781.8361  41.64908  ...      52.169025   -24.017240   \n",
            "6397783 -109.3594  786.9982  42.84845  ...      46.532116   -20.544475   \n",
            "6397784 -110.0617  790.0313  43.54063  ...      40.687959   -17.298475   \n",
            "6397785 -110.3947  791.4223  43.85922  ...      34.828868   -14.311043   \n",
            "6397786 -110.5044  791.8597  43.96323  ...      31.919027   -12.885604   \n",
            "\n",
            "         hip_vel_f_l  hip_vel_t_l  knee_vel_s_l  ankle_vel_s_l  ankle_vel_f_l  \\\n",
            "0           4.982984     0.630205      1.231691      -2.872754      -1.568582   \n",
            "1           4.950053     0.622311      1.211863      -2.859841      -1.566732   \n",
            "2           4.852761     0.599090      1.165015      -2.821274      -1.556696   \n",
            "3           4.694381     0.561134      1.105082      -2.758124      -1.534228   \n",
            "4           4.479231     0.508909      1.034923      -2.672475      -1.499914   \n",
            "...              ...          ...           ...            ...            ...   \n",
            "6397782    10.482643     4.342330      2.949895      17.425928       8.659025   \n",
            "6397783     9.267000     3.767529      2.271663      15.021632       7.703864   \n",
            "6397784     8.045794     3.213370      1.716426      12.733030       6.728688   \n",
            "6397785     6.848969     2.689856      1.270176      10.594441       5.759437   \n",
            "6397786     6.260322     2.436922      1.072514       9.566644       5.279536   \n",
            "\n",
            "               task_info          subject           task  \n",
            "0            ball_toss_1  Gtech_2023_AB01      ball_toss  \n",
            "1            ball_toss_1  Gtech_2023_AB01      ball_toss  \n",
            "2            ball_toss_1  Gtech_2023_AB01      ball_toss  \n",
            "3            ball_toss_1  Gtech_2023_AB01      ball_toss  \n",
            "4            ball_toss_1  Gtech_2023_AB01      ball_toss  \n",
            "...                  ...              ...            ...  \n",
            "6397782  weighted_walk_1  Gtech_2023_AB13  weighted_walk  \n",
            "6397783  weighted_walk_1  Gtech_2023_AB13  weighted_walk  \n",
            "6397784  weighted_walk_1  Gtech_2023_AB13  weighted_walk  \n",
            "6397785  weighted_walk_1  Gtech_2023_AB13  weighted_walk  \n",
            "6397786  weighted_walk_1  Gtech_2023_AB13  weighted_walk  \n",
            "\n",
            "[6397787 rows x 52 columns]\n"
          ]
        }
      ]
    }
  ]
}