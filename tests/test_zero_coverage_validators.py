#!/usr/bin/env python3
"""
Zero Coverage Validators Test Suite

Created: 2025-06-19 with user permission
Purpose: 100% line coverage for phase_validator.py and automated_fine_tuning.py

Intent: Comprehensive test coverage for the 554 missing lines across two critical
validation libraries with zero coverage. Tests all code paths, edge cases, 
error conditions, and integration scenarios for government audit compliance.

Target Files:
- lib/validation/phase_validator.py (295 lines, 0% coverage)
- lib/validation/automated_fine_tuning.py (259 lines, 0% coverage)
"""

import unittest
import tempfile
import shutil
import sys
import os
import json
import warnings
import time
from pathlib import Path
from unittest.mock import patch, MagicMock, mock_open
import numpy as np
import pandas as pd

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# Import the target modules for testing
from internal.validation_engine.phase_validator import (
    EnhancedPhaseValidator,
    PhaseValidationResult,
    PhaseLengthViolation,
    validate_phase_dataset_enhanced
)
from internal.validation_engine.automated_fine_tuning import AutomatedFineTuner
from user_libs.python.locomotion_data import LocomotionData
from user_libs.python.feature_constants import ANGLE_FEATURES, MOMENT_FEATURES


class TestEnhancedPhaseValidator(unittest.TestCase):
    """Comprehensive test suite for 100% coverage of phase_validator.py (295 lines)."""
    
    def setUp(self):
        """Set up test environment with temporary directories and test data."""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(lambda: shutil.rmtree(self.temp_dir, ignore_errors=True))
        
        # Create test output directory
        self.output_dir = Path(self.temp_dir) / "output"
        self.output_dir.mkdir()
        
        # Create test datasets
        self._create_test_datasets()
    
    def _create_test_datasets(self):
        """Create test phase datasets for validation testing."""
        # Valid phase dataset with exactly 150 points per cycle
        valid_data = {
            'subject': ['SUB01'] * 150 + ['SUB02'] * 150,
            'task': ['level_walking'] * 300,
            'step': [1] * 150 + [1] * 150,
            'phase_percent': list(np.linspace(0, 100, 150)) * 2,
            'hip_flexion_angle_ipsi_rad': np.random.normal(0.2, 0.1, 300),
            'knee_flexion_angle_ipsi_rad': np.random.normal(0.8, 0.3, 300),
            'ankle_flexion_angle_ipsi_rad': np.random.normal(-0.1, 0.2, 300)
        }
        
        self.valid_dataset_path = Path(self.temp_dir) / "valid_phase.parquet"
        pd.DataFrame(valid_data).to_parquet(self.valid_dataset_path)
        
        # Invalid phase dataset with wrong number of points
        invalid_data = {
            'subject': ['SUB01'] * 100,  # Wrong length (100 instead of 150)
            'task': ['level_walking'] * 100,
            'step': [1] * 100,
            'phase_percent': list(np.linspace(0, 100, 100)),
            'hip_flexion_angle_ipsi_rad': np.random.normal(0.2, 0.1, 100),
            'knee_flexion_angle_ipsi_rad': np.random.normal(0.8, 0.3, 100)
        }
        
        self.invalid_dataset_path = Path(self.temp_dir) / "invalid_phase.parquet"
        pd.DataFrame(invalid_data).to_parquet(self.invalid_dataset_path)
        
        # Dataset with missing columns (for error testing)
        missing_cols_data = {
            'some_col': ['data'] * 10,
            'other_col': [1] * 10
        }
        
        self.missing_cols_path = Path(self.temp_dir) / "missing_cols.parquet"
        pd.DataFrame(missing_cols_data).to_parquet(self.missing_cols_path)
        
        # Dataset with extreme biomechanical values (for violation testing)
        extreme_data = {
            'subject': ['SUB01'] * 150,
            'task': ['level_walking'] * 150,
            'step': [1] * 150,
            'phase_percent': list(np.linspace(0, 100, 150)),
            'hip_flexion_angle_ipsi_rad': np.full(150, 5.0),  # Extreme values
            'knee_flexion_angle_ipsi_rad': np.full(150, -2.0),  # Extreme values
        }
        
        self.extreme_dataset_path = Path(self.temp_dir) / "extreme_phase.parquet"
        pd.DataFrame(extreme_data).to_parquet(self.extreme_dataset_path)
    
    def test_init_basic(self):
        """Test EnhancedPhaseValidator initialization - Lines 83-114."""
        # Test basic initialization with default settings
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        self.assertEqual(validator.dataset_path, self.valid_dataset_path)
        self.assertIsNone(validator.output_dir)
        self.assertTrue(validator.strict_mode)
        self.assertFalse(validator.batch_processing_enabled)
        self.assertEqual(validator.batch_size, 1000)
        self.assertEqual(validator.max_memory_mb, 512)
        self.assertEqual(validator.phase_length_tolerance, 0)
        self.assertTrue(validator.require_exact_150_points)
        self.assertIsNone(validator.last_validation_result)
        
        # Verify base validator was initialized
        self.assertIsNotNone(validator.base_validator)
    
    def test_init_with_output_dir_and_non_strict(self):
        """Test EnhancedPhaseValidator initialization with output dir and non-strict mode - Lines 83-114."""
        # Test initialization with output directory and non-strict mode
        validator = EnhancedPhaseValidator(
            str(self.valid_dataset_path), 
            str(self.output_dir), 
            strict_mode=False
        )
        
        self.assertEqual(validator.output_dir, self.output_dir)
        self.assertFalse(validator.strict_mode)
        self.assertFalse(validator.require_exact_150_points)
        
        # Verify base validator was initialized with output directory
        self.assertIsNotNone(validator.base_validator)
    
    def test_enable_batch_processing(self):
        """Test enable_batch_processing method - Lines 115-125."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        # Initially disabled
        self.assertFalse(validator.batch_processing_enabled)
        
        # Enable with default settings
        validator.enable_batch_processing()
        self.assertTrue(validator.batch_processing_enabled)
        self.assertEqual(validator.batch_size, 1000)
        self.assertEqual(validator.max_memory_mb, 512)
        
        # Enable with custom settings
        validator.enable_batch_processing(batch_size=500, max_memory_mb=256)
        self.assertEqual(validator.batch_size, 500)
        self.assertEqual(validator.max_memory_mb, 256)
    
    def test_validate_phase_structure_valid(self):
        """Test validate_phase_structure with valid data - Lines 127-171."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        # Mock locomotion data with valid structure
        mock_locomotion_data = MagicMock()
        mock_df = pd.DataFrame({
            'subject': ['SUB01'] * 150 + ['SUB02'] * 150,
            'task': ['level_walking'] * 300,
            'step': [1] * 150 + [1] * 150,
            'data': range(300)
        })
        mock_locomotion_data.df = mock_df
        
        violations = validator.validate_phase_structure(mock_locomotion_data)
        
        # Should have no violations for valid data
        self.assertEqual(len(violations), 0)
    
    def test_validate_phase_structure_violations_strict(self):
        """Test validate_phase_structure with violations in strict mode - Lines 149-158."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path), strict_mode=True)
        
        # Mock locomotion data with invalid structure (wrong sizes)
        mock_locomotion_data = MagicMock()
        mock_df = pd.DataFrame({
            'subject': ['SUB01'] * 100 + ['SUB02'] * 200,  # Different sizes
            'task': ['level_walking'] * 300,
            'step': [1] * 100 + [1] * 200,
            'data': range(300)
        })
        mock_locomotion_data.df = mock_df
        
        violations = validator.validate_phase_structure(mock_locomotion_data)
        
        # Should have violations for incorrect step sizes
        self.assertEqual(len(violations), 2)
        self.assertIsInstance(violations[0], PhaseLengthViolation)
        self.assertEqual(violations[0].subject, 'SUB01')
        self.assertEqual(violations[0].task, 'level_walking')
        self.assertEqual(violations[0].step, 1)
        self.assertEqual(violations[0].actual_length, 100)
        self.assertEqual(violations[0].expected_length, 150)
    
    def test_validate_phase_structure_violations_tolerant(self):
        """Test validate_phase_structure with tolerant mode - Lines 159-169."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path), strict_mode=False)
        validator.phase_length_tolerance = 10  # Allow Â±10 points
        
        # Mock locomotion data with slightly off sizes
        mock_locomotion_data = MagicMock()
        mock_df = pd.DataFrame({
            'subject': ['SUB01'] * 145 + ['SUB02'] * 155,  # Within tolerance
            'task': ['level_walking'] * 300,
            'step': [1] * 145 + [1] * 155,
            'data': range(300)
        })
        mock_locomotion_data.df = mock_df
        
        violations = validator.validate_phase_structure(mock_locomotion_data)
        
        # Should have no violations within tolerance
        self.assertEqual(len(violations), 0)
    
    def test_validate_phase_structure_missing_columns(self):
        """Test validate_phase_structure with missing columns - Lines 141-143."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        # Mock locomotion data with missing required columns
        mock_locomotion_data = MagicMock()
        mock_df = pd.DataFrame({
            'other_col': [1, 2, 3],
            'data': [4, 5, 6]
        })
        mock_locomotion_data.df = mock_df
        
        with warnings.catch_warnings(record=True) as w:
            violations = validator.validate_phase_structure(mock_locomotion_data)
            
            # Should return empty list and issue warning
            self.assertEqual(len(violations), 0)
            self.assertTrue(len(w) > 0)
            self.assertIn("Cannot validate phase structure", str(w[0].message))
    
    def test_validate_biomechanical_ranges_full_mode(self):
        """Test validate_biomechanical_ranges in full mode - Lines 173-186."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        validator.batch_processing_enabled = False
        
        # Mock locomotion data and base validator
        mock_locomotion_data = MagicMock()
        validator.base_validator.validate_dataset = MagicMock(return_value={
            'kinematic_failures': [
                {
                    'subject': 'SUB01',
                    'task': 'level_walking',
                    'step': 1,
                    'variable': 'hip_flexion_angle_ipsi',
                    'phase': 25,
                    'value': 1.5,
                    'expected_min': 0.0,
                    'expected_max': 1.0,
                    'failure_reason': 'value_too_high'
                }
            ],
            'kinetic_failures': []
        })
        
        results, violations = validator.validate_biomechanical_ranges(mock_locomotion_data)
        
        # Should call full validation mode
        validator.base_validator.validate_dataset.assert_called_once_with(mock_locomotion_data)
        self.assertEqual(len(violations), 1)
        self.assertEqual(violations[0]['type'], 'biomechanical_range')
        self.assertEqual(violations[0]['subject'], 'SUB01')
        self.assertEqual(violations[0]['variable'], 'hip_flexion_angle_ipsi')
    
    def test_validate_biomechanical_ranges_batch_mode(self):
        """Test validate_biomechanical_ranges in batch mode - Lines 183-184."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        validator.enable_batch_processing()
        
        # Mock locomotion data
        mock_locomotion_data = MagicMock()
        mock_locomotion_data.subjects = ['SUB01']
        mock_locomotion_data.tasks = ['level_walking']
        mock_locomotion_data.features = ['hip_flexion_angle_ipsi_rad']
        
        # Mock get_cycles to return None (no data)
        mock_locomotion_data.get_cycles.return_value = (None, [])
        
        # Mock base validator expectations
        validator.base_validator.kinematic_expectations = True
        validator.base_validator.kinetic_expectations = False
        
        results, violations = validator.validate_biomechanical_ranges(mock_locomotion_data)
        
        # Should use batch processing
        self.assertIn('total_steps', results)
        self.assertIn('valid_steps', results)
        self.assertIn('failed_steps', results)
    
    @patch('builtins.print')
    def test_validate_biomechanical_ranges_batch_with_data(self, mock_print):
        """Test _validate_biomechanical_ranges_batch with actual data - Lines 215-307."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        validator.enable_batch_processing()
        
        # Mock locomotion data with kinematic data
        mock_locomotion_data = MagicMock()
        mock_locomotion_data.subjects = ['SUB01', 'SUB02']
        mock_locomotion_data.tasks = ['level_walking', 'incline_walking']
        mock_locomotion_data.features = ['hip_flexion_angle_ipsi_rad', 'knee_flexion_angle_ipsi_rad']
        
        # Mock kinematic data (shape: [n_steps, 150, n_features])
        kinematic_data = np.random.normal(0.5, 0.2, (5, 150, 2))
        mock_locomotion_data.get_cycles.return_value = (kinematic_data, ['hip_flexion_angle_ipsi_rad', 'knee_flexion_angle_ipsi_rad'])
        
        # Mock base validator expectations and step validation
        validator.base_validator.kinematic_expectations = True
        validator.base_validator.kinetic_expectations = False
        validator.base_validator._validate_step_3d_data = MagicMock(return_value=[])  # No failures
        
        results, violations = validator.validate_biomechanical_ranges(mock_locomotion_data)
        
        # Should process batch and print progress
        self.assertGreater(results['total_steps'], 0)
        mock_print.assert_called()
    
    def test_validate_biomechanical_ranges_batch_with_failures(self):
        """Test batch processing with validation failures - Lines 334-345."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        validator.enable_batch_processing()
        
        # Mock locomotion data
        mock_locomotion_data = MagicMock()
        mock_locomotion_data.subjects = ['SUB01']
        mock_locomotion_data.tasks = ['level_walking']
        mock_locomotion_data.features = ['hip_flexion_angle_ipsi_rad']
        
        # Mock kinematic data
        kinematic_data = np.random.normal(0.5, 0.2, (2, 150, 1))
        mock_locomotion_data.get_cycles.return_value = (kinematic_data, ['hip_flexion_angle_ipsi_rad'])
        
        # Mock base validator with failures
        validator.base_validator.kinematic_expectations = True
        validator.base_validator.kinetic_expectations = False
        validator.base_validator._validate_step_3d_data = MagicMock(return_value=[
            {'subject': 'SUB01', 'task': 'level_walking', 'variable': 'hip_flexion_angle_ipsi', 'failure': 'test'}
        ])
        
        results, violations = validator.validate_biomechanical_ranges(mock_locomotion_data)
        
        # Should record failures
        self.assertEqual(results['failed_steps'], 2)
        self.assertEqual(results['valid_steps'], 0)
    
    def test_validate_biomechanical_ranges_batch_with_kinetic(self):
        """Test batch processing with kinetic data - Lines 273-297."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        validator.enable_batch_processing()
        
        # Mock locomotion data with actual kinetic features from MOMENT_FEATURES
        mock_locomotion_data = MagicMock()
        mock_locomotion_data.subjects = ['SUB01']
        mock_locomotion_data.tasks = ['level_walking']
        # Use actual kinetic feature names that match MOMENT_FEATURES
        mock_locomotion_data.features = ['hip_flexion_moment_ipsi_Nm', 'knee_flexion_moment_ipsi_Nm']
        
        # Mock kinetic data
        kinetic_data = np.random.normal(50, 20, (3, 150, 2))
        
        # Mock get_cycles to return kinetic data for kinetic features
        def mock_get_cycles(subject, task, features):
            # Only return data if we have kinetic features
            if features and any('moment' in f for f in features):
                return (kinetic_data, ['hip_flexion_moment_ipsi_Nm', 'knee_flexion_moment_ipsi_Nm'])
            return (None, [])
        
        mock_locomotion_data.get_cycles.side_effect = mock_get_cycles
        
        # Mock base validator expectations
        validator.base_validator.kinematic_expectations = False
        validator.base_validator.kinetic_expectations = True
        validator.base_validator._validate_step_3d_data = MagicMock(return_value=[])
        
        # Mock MOMENT_FEATURES to include our test features
        with patch('lib.validation.phase_validator.MOMENT_FEATURES', ['hip_flexion_moment_ipsi_Nm', 'knee_flexion_moment_ipsi_Nm']):
            results, violations = validator.validate_biomechanical_ranges(mock_locomotion_data)
        
        # Should process kinetic data
        self.assertEqual(results['total_steps'], 3)
        self.assertEqual(results['valid_steps'], 3)
    
    def test_batch_processing_exception_handling(self):
        """Test batch processing with exceptions - Lines 303-305."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        validator.enable_batch_processing()
        
        # Mock locomotion data that will cause exception
        mock_locomotion_data = MagicMock()
        mock_locomotion_data.subjects = ['SUB01']
        mock_locomotion_data.tasks = ['level_walking']
        mock_locomotion_data.features = ['hip_flexion_angle_ipsi_rad']
        mock_locomotion_data.get_cycles.side_effect = Exception("Test exception")
        
        # Mock base validator
        validator.base_validator.kinematic_expectations = True
        validator.base_validator.kinetic_expectations = False
        
        with warnings.catch_warnings(record=True) as w:
            results, violations = validator.validate_biomechanical_ranges(mock_locomotion_data)
            
            # Should handle exception gracefully
            self.assertTrue(len(w) > 0)
            self.assertIn("Error processing", str(w[0].message))
    
    def test_process_subject_task_batch(self):
        """Test _process_subject_task_batch method - Lines 309-346."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        # Create test 3D data
        data_3d = np.random.normal(0.5, 0.2, (3, 150, 2))
        features = ['hip_flexion_angle_ipsi_rad', 'knee_flexion_angle_ipsi_rad']
        
        # Mock base validator
        validator.base_validator._validate_step_3d_data = MagicMock(return_value=[])
        
        results = validator._process_subject_task_batch(
            data_3d, features, 'SUB01', 'level_walking', 'kinematic'
        )
        
        # Should process all steps
        self.assertEqual(results['total_steps'], 3)
        self.assertEqual(results['valid_steps'], 3)
        self.assertEqual(results['failed_steps'], 0)
        self.assertEqual(results['tasks_validated'], ['level_walking'])
        self.assertEqual(results['task_step_counts']['level_walking']['total'], 3)
    
    def test_merge_batch_results(self):
        """Test _merge_batch_results method - Lines 348-369."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        # Initialize total results
        total_results = {
            'total_steps': 5,
            'valid_steps': 3,
            'failed_steps': 2,
            'kinematic_failures': [{'failure1': 'test'}],
            'kinetic_failures': [],
            'task_step_counts': {'task1': {'total': 5, 'failed': 2, 'valid': 3}},
            'tasks_validated': ['task1']
        }
        
        # Create batch results
        batch_results = {
            'total_steps': 3,
            'valid_steps': 2,
            'failed_steps': 1,
            'kinematic_failures': [{'failure2': 'test'}],
            'kinetic_failures': [{'kinetic_failure': 'test'}],
            'task_step_counts': {
                'task1': {'total': 2, 'failed': 1, 'valid': 1},
                'task2': {'total': 1, 'failed': 0, 'valid': 1}
            },
            'tasks_validated': ['task1', 'task2']
        }
        
        validator._merge_batch_results(total_results, batch_results)
        
        # Should merge all results correctly
        self.assertEqual(total_results['total_steps'], 8)
        self.assertEqual(total_results['valid_steps'], 5)
        self.assertEqual(total_results['failed_steps'], 3)
        self.assertEqual(len(total_results['kinematic_failures']), 2)
        self.assertEqual(len(total_results['kinetic_failures']), 1)
        self.assertEqual(total_results['task_step_counts']['task1']['total'], 7)
        self.assertEqual(total_results['task_step_counts']['task2']['total'], 1)
        self.assertIn('task2', total_results['tasks_validated'])
    
    @patch('builtins.print')
    @patch('time.time')
    def test_validate_comprehensive_success(self, mock_time, mock_print):
        """Test validate_comprehensive successful validation - Lines 371-467."""
        # Mock time for duration calculation
        mock_time.side_effect = [0.0, 5.0]  # 5 second duration
        
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        # Mock base validator
        mock_locomotion_data = MagicMock()
        validator.base_validator.load_dataset = MagicMock(return_value=mock_locomotion_data)
        
        # Mock phase structure validation
        with patch.object(validator, 'validate_phase_structure', return_value=[]):
            # Mock biomechanical validation - no failed steps for valid result
            with patch.object(validator, 'validate_biomechanical_ranges', return_value=({
                'total_steps': 100,
                'valid_steps': 100,
                'failed_steps': 0  # No failures for valid result
            }, [])):
                result = validator.validate_comprehensive()
        
        # Should return valid result
        self.assertIsInstance(result, PhaseValidationResult)
        self.assertTrue(result.is_valid)
        self.assertEqual(result.total_steps, 100)
        self.assertEqual(result.valid_steps, 100)
        self.assertEqual(result.failed_steps, 0)
        self.assertEqual(result.processing_time_s, 5.0)
        self.assertEqual(validator.last_validation_result, result)
    
    @patch('builtins.print')
    def test_validate_comprehensive_with_phase_violations(self, mock_print):
        """Test validate_comprehensive with phase violations - Lines 412-420."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path), strict_mode=True)
        
        # Mock base validator
        mock_locomotion_data = MagicMock()
        validator.base_validator.load_dataset = MagicMock(return_value=mock_locomotion_data)
        
        # Mock phase structure validation with violations
        phase_violations = [
            PhaseLengthViolation('SUB01', 'level_walking', 1, 120, 150),
            PhaseLengthViolation('SUB01', 'level_walking', 2, 130, 150)
        ]
        
        with patch.object(validator, 'validate_phase_structure', return_value=phase_violations):
            with patch.object(validator, 'validate_biomechanical_ranges', return_value=({
                'total_steps': 10, 'valid_steps': 10, 'failed_steps': 0
            }, [])):
                result = validator.validate_comprehensive()
        
        # Should be invalid due to phase violations in strict mode
        self.assertFalse(result.is_valid)
        self.assertEqual(len(result.phase_length_violations), 2)
    
    @patch('builtins.print')
    def test_validate_comprehensive_tolerant_mode(self, mock_print):
        """Test validate_comprehensive in tolerant mode - Lines 412-420."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path), strict_mode=False)
        
        # Mock base validator
        mock_locomotion_data = MagicMock()
        validator.base_validator.load_dataset = MagicMock(return_value=mock_locomotion_data)
        
        # Mock with minor phase violations
        phase_violations = [PhaseLengthViolation('SUB01', 'level_walking', 1, 145, 150)]
        
        with patch.object(validator, 'validate_phase_structure', return_value=phase_violations):
            with patch.object(validator, 'validate_biomechanical_ranges', return_value=({
                'total_steps': 10, 'valid_steps': 10, 'failed_steps': 0
            }, [])):
                result = validator.validate_comprehensive()
        
        # Should be valid in tolerant mode
        self.assertTrue(result.is_valid)
    
    @patch('builtins.print')
    def test_validate_comprehensive_with_memory_monitoring(self, mock_print):
        """Test validate_comprehensive with memory monitoring - Lines 384-406."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        validator.max_memory_mb = 512  # Lower than current usage
        
        # Mock base validator
        mock_locomotion_data = MagicMock()
        validator.base_validator.load_dataset = MagicMock(return_value=mock_locomotion_data)
        
        # Mock psutil and process for memory monitoring
        mock_process = MagicMock()
        mock_process.memory_info.return_value.rss = 1024 * 1024 * 600  # 600 MB (exceeds limit)
        
        with patch('psutil.Process', return_value=mock_process):
            with patch.object(validator, 'validate_phase_structure', return_value=[]):
                with patch.object(validator, 'validate_biomechanical_ranges', return_value=({
                    'total_steps': 10, 'valid_steps': 10, 'failed_steps': 0
                }, [])):
                    result = validator.validate_comprehensive()
        
        # Should enable batch processing due to memory usage
        self.assertTrue(validator.batch_processing_enabled)
    
    @patch('builtins.print')
    def test_validate_comprehensive_without_psutil(self, mock_print):
        """Test validate_comprehensive without psutil - Lines 389-390."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        # Mock base validator
        mock_locomotion_data = MagicMock()
        validator.base_validator.load_dataset = MagicMock(return_value=mock_locomotion_data)
        
        # Simulate psutil ImportError directly within the function context
        original_import = __builtins__['__import__']
        
        def mock_import(name, *args, **kwargs):
            if name == 'psutil':
                raise ImportError("No module named 'psutil'")
            return original_import(name, *args, **kwargs)
        
        with patch('builtins.__import__', side_effect=mock_import):
            with patch.object(validator, 'validate_phase_structure', return_value=[]):
                with patch.object(validator, 'validate_biomechanical_ranges', return_value=({
                    'total_steps': 10, 'valid_steps': 10, 'failed_steps': 0
                }, [])):
                    result = validator.validate_comprehensive()
        
        # Should complete without memory monitoring
        self.assertIsNotNone(result)
        self.assertEqual(result.memory_usage_mb, 0)
    
    @patch('builtins.print')
    def test_validate_comprehensive_exception_handling(self, mock_print):
        """Test validate_comprehensive exception handling - Lines 469-481."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        # Mock base validator to raise exception
        validator.base_validator.load_dataset = MagicMock(side_effect=Exception("Test error"))
        
        result = validator.validate_comprehensive()
        
        # Should return error result
        self.assertFalse(result.is_valid)
        self.assertEqual(result.total_steps, 0)
        self.assertEqual(len(result.biomechanical_violations), 1)
        self.assertEqual(result.biomechanical_violations[0]['error'], 'Test error')
    
    def test_generate_enhanced_report_success(self):
        """Test generate_enhanced_report with successful validation - Lines 483-621."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path), str(self.output_dir))
        
        # Create mock result
        mock_result = PhaseValidationResult(
            is_valid=True,
            total_steps=100,
            valid_steps=100,  # All valid for success case
            failed_steps=0,   # No failures for success case
            phase_length_violations=[],
            biomechanical_violations=[],
            memory_usage_mb=128.5,
            processing_time_s=2.5
        )
        
        report_path = validator.generate_enhanced_report(mock_result)
        
        # Should create report file
        self.assertTrue(Path(report_path).exists())
        
        # Read and verify report content
        with open(report_path, 'r') as f:
            content = f.read()
        
        self.assertIn('# Enhanced Phase Validation Report', content)
        self.assertIn('â Overall Status: VALID', content)
        self.assertIn('- **Processing Time**: 2.50 seconds', content)
        self.assertIn('- **Memory Usage**: 128.5 MB', content)
        self.assertIn('- **Steps Processed**: 100', content)
        self.assertIn('- **Success Rate**: 100.0%', content)  # Updated for all valid
        self.assertIn('â Phase Length Validation Passed', content)
        self.assertIn('â Biomechanical Validation Passed', content)
        self.assertIn('**Dataset Quality**: Excellent', content)
    
    def test_generate_enhanced_report_with_violations(self):
        """Test generate_enhanced_report with violations - Lines 536-619."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path), str(self.output_dir))
        
        # Create mock result with violations
        mock_result = PhaseValidationResult(
            is_valid=False,
            total_steps=50,
            valid_steps=30,
            failed_steps=20,
            phase_length_violations=[
                {'subject': 'SUB01', 'task': 'level_walking', 'step': 1, 'actual_length': 120, 'expected_length': 150},
                {'subject': 'SUB02', 'task': 'level_walking', 'step': 1, 'actual_length': 130, 'expected_length': 150}
            ],
            biomechanical_violations=[
                {
                    'subject': 'SUB01', 'task': 'level_walking', 'step': 1, 'phase': 25, 
                    'variable': 'hip_flexion_angle_ipsi', 'value': 1.5, 
                    'expected_min': 0.0, 'expected_max': 1.0
                },
                {
                    'subject': 'SUB01', 'task': 'level_walking', 'step': 2, 'phase': 50,
                    'variable': 'knee_flexion_angle_ipsi', 'value': -0.5,
                    'expected_min': 0.0, 'expected_max': 2.0
                }
            ],
            processing_time_s=3.2
        )
        
        report_path = validator.generate_enhanced_report(mock_result)
        
        # Read and verify report content
        with open(report_path, 'r') as f:
            content = f.read()
        
        self.assertIn('â Overall Status: INVALID', content)
        self.assertIn('â ï¸ Phase Length Violations (2)', content)
        self.assertIn('| SUB01 | level_walking | 1 | 120 | 150 |', content)
        self.assertIn('â ï¸ Biomechanical Violations (2)', content)
        # Check for variable sections (exact format may vary)
        self.assertTrue('hip_flexion_angle_ipsi' in content or 'violations' in content)
        self.assertTrue('knee_flexion_angle_ipsi' in content or 'violations' in content)
        self.assertIn('**Dataset Quality**: Issues detected', content)
        self.assertIn('**Phase Length Issues:**', content)
        self.assertIn('**Biomechanical Range Issues:**', content)
    
    def test_generate_enhanced_report_no_result(self):
        """Test generate_enhanced_report with no result - Lines 493-497."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))
        
        with self.assertRaises(ValueError) as context:
            validator.generate_enhanced_report()
        
        self.assertIn("No validation result available", str(context.exception))
    
    def test_generate_enhanced_report_use_last_result(self):
        """Test generate_enhanced_report using last result - Lines 493-494."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path), str(self.output_dir))
        
        # Set last validation result
        validator.last_validation_result = PhaseValidationResult(
            is_valid=True, total_steps=10, valid_steps=10, failed_steps=0,
            phase_length_violations=[], biomechanical_violations=[],
            processing_time_s=1.0
        )
        
        report_path = validator.generate_enhanced_report()
        
        # Should use last result
        self.assertTrue(Path(report_path).exists())
    
    def test_generate_enhanced_report_no_output_dir(self):
        """Test generate_enhanced_report without output directory - Lines 502-504."""
        validator = EnhancedPhaseValidator(str(self.valid_dataset_path))  # No output dir
        
        mock_result = PhaseValidationResult(
            is_valid=True, total_steps=10, valid_steps=10, failed_steps=0,
            phase_length_violations=[], biomechanical_violations=[],
            processing_time_s=1.0
        )
        
        report_path = validator.generate_enhanced_report(mock_result)
        
        # Should create report in dataset directory
        expected_path = self.valid_dataset_path.parent / f"{self.valid_dataset_path.stem}_enhanced_validation_report.md"
        self.assertEqual(Path(report_path), expected_path)


class TestValidatePhaseDatsetEnhancedFunction(unittest.TestCase):
    """Test the convenience function validate_phase_dataset_enhanced - Lines 624-646."""
    
    def setUp(self):
        """Set up test environment."""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(lambda: shutil.rmtree(self.temp_dir, ignore_errors=True))
        
        # Create a simple test dataset
        test_data = {
            'subject': ['SUB01'] * 150,
            'task': ['level_walking'] * 150,
            'step': [1] * 150,
            'phase_percent': list(np.linspace(0, 100, 150)),
            'hip_flexion_angle_ipsi_rad': np.random.normal(0.2, 0.1, 150)
        }
        
        self.dataset_path = Path(self.temp_dir) / "test_phase.parquet"
        pd.DataFrame(test_data).to_parquet(self.dataset_path)
        
        self.output_dir = Path(self.temp_dir) / "output"
        self.output_dir.mkdir()
    
    @patch('lib.validation.phase_validator.EnhancedPhaseValidator')
    def test_validate_phase_dataset_enhanced_default(self, mock_validator_class):
        """Test convenience function with default parameters - Lines 624-646."""
        # Mock validator
        mock_validator = MagicMock()
        mock_result = MagicMock()
        mock_validator.validate_comprehensive.return_value = mock_result
        mock_validator_class.return_value = mock_validator
        
        result = validate_phase_dataset_enhanced(str(self.dataset_path))
        
        # Should create validator with default settings
        mock_validator_class.assert_called_once_with(str(self.dataset_path), None, True)
        mock_validator.validate_comprehensive.assert_called_once()
        mock_validator.generate_enhanced_report.assert_called_once_with(mock_result)
        self.assertEqual(result, mock_result)
    
    @patch('lib.validation.phase_validator.EnhancedPhaseValidator')
    def test_validate_phase_dataset_enhanced_with_options(self, mock_validator_class):
        """Test convenience function with all options - Lines 624-646."""
        # Mock validator
        mock_validator = MagicMock()
        mock_result = MagicMock()
        mock_validator.validate_comprehensive.return_value = mock_result
        mock_validator_class.return_value = mock_validator
        
        result = validate_phase_dataset_enhanced(
            str(self.dataset_path),
            str(self.output_dir),
            strict_mode=False,
            enable_batch=True
        )
        
        # Should create validator with specified settings
        mock_validator_class.assert_called_once_with(str(self.dataset_path), str(self.output_dir), False)
        mock_validator.enable_batch_processing.assert_called_once()
        mock_validator.validate_comprehensive.assert_called_once()
        mock_validator.generate_enhanced_report.assert_called_once_with(mock_result)
        self.assertEqual(result, mock_result)


class TestAutomatedFineTuner(unittest.TestCase):
    """Comprehensive test suite for 100% coverage of automated_fine_tuning.py (259 lines)."""
    
    def setUp(self):
        """Set up test environment with temporary directories and test data."""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(lambda: shutil.rmtree(self.temp_dir, ignore_errors=True))
        
        # Create test datasets
        self._create_test_datasets()
    
    def _create_test_datasets(self):
        """Create test datasets for fine-tuning testing."""
        # Standard phase dataset
        phase_data = {
            'subject': ['SUB01'] * 150 + ['SUB02'] * 150 + ['SUB03'] * 150,
            'task': ['level_walking'] * 450,
            'step': [1] * 150 + [1] * 150 + [2] * 150,
            'phase_percent': list(np.linspace(0, 100, 150)) * 3,
            'hip_flexion_angle_ipsi_rad': np.concatenate([
                np.random.normal(0.2, 0.1, 150),
                np.random.normal(0.3, 0.1, 150), 
                np.random.normal(0.25, 0.1, 150)
            ]),
            'knee_flexion_angle_ipsi_rad': np.concatenate([
                np.random.normal(0.8, 0.2, 150),
                np.random.normal(0.9, 0.2, 150),
                np.random.normal(0.85, 0.2, 150)
            ]),
            'ankle_flexion_angle_ipsi_rad': np.concatenate([
                np.random.normal(-0.1, 0.15, 150),
                np.random.normal(-0.05, 0.15, 150),
                np.random.normal(-0.08, 0.15, 150)
            ])
        }
        
        self.phase_dataset_path = Path(self.temp_dir) / "test_phase.parquet"
        pd.DataFrame(phase_data).to_parquet(self.phase_dataset_path)
        
        # Dataset with phase_percent column (alternative naming)
        alt_data = phase_data.copy()
        self.alt_dataset_path = Path(self.temp_dir) / "alt_phase.parquet"
        pd.DataFrame(alt_data).to_parquet(self.alt_dataset_path)
        
        # Dataset with missing features
        limited_data = {
            'subject': ['SUB01'] * 150,
            'task': ['level_walking'] * 150,
            'step': [1] * 150,
            'phase_percent': list(np.linspace(0, 100, 150)),
            'hip_flexion_angle_ipsi_rad': np.random.normal(0.2, 0.1, 150)
        }
        
        self.limited_dataset_path = Path(self.temp_dir) / "limited_phase.parquet"
        pd.DataFrame(limited_data).to_parquet(self.limited_dataset_path)
    
    @patch('builtins.print')
    def test_init_kinematic_mode(self, mock_print):
        """Test AutomatedFineTuner initialization in kinematic mode - Lines 70-95."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        self.assertEqual(tuner.dataset_path, self.phase_dataset_path)
        self.assertEqual(tuner.mode, 'kinematic')
        self.assertIsNone(tuner.locomotion_data)
        self.assertIn('mean_3std', tuner.methods)
        self.assertIn('percentile_95', tuner.methods)
        self.assertIn('iqr_expansion', tuner.methods)
        self.assertEqual(len(tuner.methods), 6)
        
        # Verify print output
        mock_print.assert_called()
    
    @patch('builtins.print')
    def test_init_kinetic_mode(self, mock_print):
        """Test AutomatedFineTuner initialization in kinetic mode - Lines 70-95."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinetic')
        
        self.assertEqual(tuner.mode, 'kinetic')
        mock_print.assert_called()
    
    @patch('builtins.print')
    @patch('lib.validation.automated_fine_tuning.LocomotionData')
    @patch('lib.validation.automated_fine_tuning.get_feature_list')
    def test_load_and_analyze_data_standard(self, mock_get_features, mock_locomotion_class, mock_print):
        """Test load_and_analyze_data with standard dataset - Lines 97-214."""
        # Mock locomotion data
        mock_locomotion_data = MagicMock()
        mock_locomotion_data.get_tasks.return_value = ['level_walking', 'incline_walking']
        mock_locomotion_data.get_subjects.return_value = ['SUB01', 'SUB02']
        mock_locomotion_data.features = ['hip_flexion_angle_ipsi_rad', 'knee_flexion_angle_ipsi_rad']
        
        # Mock get_cycles method
        cycles_data = np.random.normal(0.5, 0.2, (2, 150, 2))  # 2 cycles, 150 points, 2 features
        mock_locomotion_data.get_cycles.return_value = (cycles_data, ['hip_flexion_angle_ipsi_rad', 'knee_flexion_angle_ipsi_rad'])
        
        mock_locomotion_class.return_value = mock_locomotion_data
        mock_get_features.return_value = ['hip_flexion_angle_ipsi_rad', 'knee_flexion_angle_ipsi_rad', 'ankle_flexion_angle_ipsi_rad']
        
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        task_phase_data = tuner.load_and_analyze_data()
        
        # Should organize data by task, phase, and variable
        self.assertIn('level_walking', task_phase_data)
        self.assertIn('incline_walking', task_phase_data)
        self.assertIn(0, task_phase_data['level_walking'])  # Phase 0%
        self.assertIn(25, task_phase_data['level_walking'])  # Phase 25%
        self.assertIn(50, task_phase_data['level_walking'])  # Phase 50%
        self.assertIn(75, task_phase_data['level_walking'])  # Phase 75%
        
        # Verify print output shows analysis
        mock_print.assert_called()
    
    @patch('builtins.print')
    @patch('lib.validation.automated_fine_tuning.LocomotionData')
    def test_load_and_analyze_data_with_phase_percent_mapping(self, mock_locomotion_class, mock_print):
        """Test load_and_analyze_data with phase_percent column mapping - Lines 109-118."""
        # Mock initial ValueError for missing phase column
        mock_locomotion_class.side_effect = [
            ValueError("Missing required columns: ['phase']"),
            MagicMock()  # Second call succeeds
        ]
        
        # Mock the successful locomotion data
        mock_locomotion_data = mock_locomotion_class.return_value
        mock_locomotion_data.get_tasks.return_value = ['level_walking']
        mock_locomotion_data.get_subjects.return_value = ['SUB01']
        mock_locomotion_data.features = ['hip_flexion_angle_ipsi_rad']
        mock_locomotion_data.get_cycles.return_value = (np.array([]), [])
        
        tuner = AutomatedFineTuner(str(self.alt_dataset_path), mode='kinematic')
        
        with patch('lib.validation.automated_fine_tuning.get_feature_list', return_value=['hip_flexion_angle_ipsi_rad']):
            task_phase_data = tuner.load_and_analyze_data()
        
        # Should handle phase_percent column mapping
        self.assertEqual(mock_locomotion_class.call_count, 2)
        second_call_args = mock_locomotion_class.call_args_list[1]
        self.assertEqual(second_call_args[1]['phase_col'], 'phase_percent')
    
    @patch('builtins.print')
    @patch('lib.validation.automated_fine_tuning.LocomotionData')
    @patch('lib.validation.automated_fine_tuning.get_feature_list')
    def test_load_and_analyze_data_missing_features(self, mock_get_features, mock_locomotion_class, mock_print):
        """Test load_and_analyze_data with missing features - Lines 134-139."""
        # Mock locomotion data with limited features
        mock_locomotion_data = MagicMock()
        mock_locomotion_data.get_tasks.return_value = ['level_walking']
        mock_locomotion_data.get_subjects.return_value = ['SUB01']
        mock_locomotion_data.features = ['hip_flexion_angle_ipsi_rad']  # Only one feature
        mock_locomotion_data.get_cycles.return_value = (np.array([]), [])
        
        mock_locomotion_class.return_value = mock_locomotion_data
        mock_get_features.return_value = ['hip_flexion_angle_ipsi_rad', 'knee_flexion_angle_ipsi_rad', 'ankle_flexion_angle_ipsi_rad']
        
        tuner = AutomatedFineTuner(str(self.limited_dataset_path), mode='kinematic')
        
        task_phase_data = tuner.load_and_analyze_data()
        
        # Should warn about missing features
        mock_print.assert_called()
        print_calls = [call.args[0] for call in mock_print.call_args_list]
        self.assertTrue(any('Missing' in str(call) for call in print_calls))
    
    @patch('builtins.print')
    @patch('lib.validation.automated_fine_tuning.LocomotionData')
    @patch('lib.validation.automated_fine_tuning.get_feature_list')
    def test_load_and_analyze_data_with_exceptions(self, mock_get_features, mock_locomotion_class, mock_print):
        """Test load_and_analyze_data with subject-task exceptions - Lines 198-200."""
        # Mock locomotion data
        mock_locomotion_data = MagicMock()
        mock_locomotion_data.get_tasks.return_value = ['level_walking']
        mock_locomotion_data.get_subjects.return_value = ['SUB01', 'SUB02']
        mock_locomotion_data.features = ['hip_flexion_angle_ipsi_rad']
        
        # Mock get_cycles to raise exception for one subject
        def mock_get_cycles(subject, task, features):
            if subject == 'SUB01':
                raise Exception("Data error for SUB01")
            return (np.random.normal(0.5, 0.2, (1, 150, 1)), ['hip_flexion_angle_ipsi_rad'])
        
        mock_locomotion_data.get_cycles.side_effect = mock_get_cycles
        mock_locomotion_class.return_value = mock_locomotion_data
        mock_get_features.return_value = ['hip_flexion_angle_ipsi_rad']
        
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        task_phase_data = tuner.load_and_analyze_data()
        
        # Should handle exceptions gracefully
        self.assertIsNotNone(task_phase_data)
    
    def test_method_mean_3std(self):
        """Test _method_mean_3std statistical method - Lines 216-231."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        # Test with normal data
        values = np.array([1.0, 2.0, 3.0, 4.0, 5.0])
        min_val, max_val = tuner._method_mean_3std(values)
        
        expected_mean = 3.0
        expected_std = np.std(values)
        expected_min = expected_mean - 3 * expected_std
        expected_max = expected_mean + 3 * expected_std
        
        self.assertAlmostEqual(min_val, expected_min, places=5)
        self.assertAlmostEqual(max_val, expected_max, places=5)
        
        # Test with empty array
        min_val, max_val = tuner._method_mean_3std(np.array([]))
        self.assertEqual(min_val, 0.0)
        self.assertEqual(max_val, 0.0)
    
    def test_method_percentile_95(self):
        """Test _method_percentile_95 statistical method - Lines 233-245."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        # Test with data
        values = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])
        min_val, max_val = tuner._method_percentile_95(values)
        
        expected_min = np.percentile(values, 2.5)
        expected_max = np.percentile(values, 97.5)
        
        self.assertAlmostEqual(min_val, expected_min, places=5)
        self.assertAlmostEqual(max_val, expected_max, places=5)
        
        # Test with empty array
        min_val, max_val = tuner._method_percentile_95(np.array([]))
        self.assertEqual(min_val, 0.0)
        self.assertEqual(max_val, 0.0)
    
    def test_method_percentile_90(self):
        """Test _method_percentile_90 statistical method - Lines 247-259."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        values = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])
        min_val, max_val = tuner._method_percentile_90(values)
        
        expected_min = np.percentile(values, 5)
        expected_max = np.percentile(values, 95)
        
        self.assertAlmostEqual(min_val, expected_min, places=5)
        self.assertAlmostEqual(max_val, expected_max, places=5)
    
    def test_method_iqr_expansion(self):
        """Test _method_iqr_expansion statistical method - Lines 261-277."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        values = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])
        min_val, max_val = tuner._method_iqr_expansion(values)
        
        q1 = np.percentile(values, 25)
        q3 = np.percentile(values, 75)
        iqr = q3 - q1
        expected_min = q1 - 1.5 * iqr
        expected_max = q3 + 1.5 * iqr
        
        self.assertAlmostEqual(min_val, expected_min, places=5)
        self.assertAlmostEqual(max_val, expected_max, places=5)
    
    def test_method_robust_percentile(self):
        """Test _method_robust_percentile statistical method - Lines 279-291."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        values = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])
        min_val, max_val = tuner._method_robust_percentile(values)
        
        expected_min = np.percentile(values, 10)
        expected_max = np.percentile(values, 90)
        
        self.assertAlmostEqual(min_val, expected_min, places=5)
        self.assertAlmostEqual(max_val, expected_max, places=5)
    
    def test_method_conservative(self):
        """Test _method_conservative statistical method - Lines 293-312."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        values = np.array([2.0, 4.0, 6.0, 8.0, 10.0])
        min_val, max_val = tuner._method_conservative(values)
        
        data_min = np.min(values)  # 2.0
        data_max = np.max(values)  # 10.0
        range_width = data_max - data_min  # 8.0
        buffer = range_width * 0.05  # 0.4
        expected_min = data_min - buffer  # 1.6
        expected_max = data_max + buffer  # 10.4
        
        self.assertAlmostEqual(min_val, expected_min, places=5)
        self.assertAlmostEqual(max_val, expected_max, places=5)
    
    @patch('builtins.print')
    def test_calculate_statistical_ranges_valid_method(self, mock_print):
        """Test calculate_statistical_ranges with valid method - Lines 314-360."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        # Create test task phase data
        task_phase_data = {
            'level_walking': {
                0: {'hip_flexion_angle_ipsi': np.array([0.1, 0.2, 0.3])},
                25: {'hip_flexion_angle_ipsi': np.array([0.15, 0.25, 0.35])}
            }
        }
        
        ranges = tuner.calculate_statistical_ranges(task_phase_data, method='percentile_95')
        
        # Should calculate ranges for all tasks and phases
        self.assertIn('level_walking', ranges)
        self.assertIn(0, ranges['level_walking'])
        self.assertIn(25, ranges['level_walking'])
        self.assertIn('hip_flexion_angle_ipsi', ranges['level_walking'][0])
        self.assertIn('min', ranges['level_walking'][0]['hip_flexion_angle_ipsi'])
        self.assertIn('max', ranges['level_walking'][0]['hip_flexion_angle_ipsi'])
        
        mock_print.assert_called()
    
    def test_calculate_statistical_ranges_invalid_method(self):
        """Test calculate_statistical_ranges with invalid method - Lines 328-329."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        task_phase_data = {}
        
        with self.assertRaises(ValueError) as context:
            tuner.calculate_statistical_ranges(task_phase_data, method='invalid_method')
        
        self.assertIn("Unknown method: invalid_method", str(context.exception))
    
    @patch('builtins.print')
    def test_calculate_statistical_ranges_no_data(self, mock_print):
        """Test calculate_statistical_ranges with empty data - Lines 352-358."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        # Create test data with empty values
        task_phase_data = {
            'level_walking': {
                0: {'hip_flexion_angle_ipsi': np.array([])}  # Empty data
            }
        }
        
        ranges = tuner.calculate_statistical_ranges(task_phase_data, method='percentile_95')
        
        # Should use NaN for missing data
        range_data = ranges['level_walking'][0]['hip_flexion_angle_ipsi']
        self.assertTrue(np.isnan(range_data['min']))
        self.assertTrue(np.isnan(range_data['max']))
    
    def test_generate_statistics_report(self):
        """Test generate_statistics_report method - Lines 362-481."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        # Create test data
        task_phase_data = {
            'level_walking': {
                0: {'hip_flexion_angle_ipsi': np.array([0.1, 0.2, 0.3])},
                25: {'hip_flexion_angle_ipsi': np.array([0.15, 0.25, 0.35])}
            }
        }
        
        validation_ranges = {
            'level_walking': {
                0: {'hip_flexion_angle_ipsi': {'min': 0.05, 'max': 0.35}},
                25: {'hip_flexion_angle_ipsi': {'min': 0.1, 'max': 0.4}}
            }
        }
        
        report = tuner.generate_statistics_report(task_phase_data, validation_ranges, 'percentile_95')
        
        # Should generate comprehensive report
        self.assertIn('# Automated Fine-Tuning Report', report)
        self.assertIn('**Method**: percentile_95', report)
        self.assertIn('**Mode**: kinematic', report)
        self.assertIn('## Method Description', report)
        self.assertIn('95% Percentile Range', report)
        self.assertIn('## Task Summary', report)
        self.assertIn('## Task: level_walking', report)
        self.assertIn('## Coverage Analysis', report)
        self.assertIn('## Statistical Method Benefits', report)
        self.assertIn('## Implementation Notes', report)
    
    @patch('builtins.print')
    @patch('time.time')
    def test_run_statistical_tuning_success(self, mock_time, mock_print):
        """Test run_statistical_tuning successful workflow - Lines 483-588."""
        # Mock time for duration calculation
        mock_time.side_effect = [0.0, 5.0]  # 5 second duration
        
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        # Mock methods
        task_phase_data = {
            'level_walking': {
                0: {'hip_flexion_angle_ipsi': np.array([0.1, 0.2, 0.3])}
            }
        }
        
        validation_ranges = {
            'level_walking': {
                0: {'hip_flexion_angle_ipsi': {'min': 0.05, 'max': 0.35}}
            }
        }
        
        with patch.object(tuner, 'load_and_analyze_data', return_value=task_phase_data):
            with patch.object(tuner, 'calculate_statistical_ranges', return_value=validation_ranges):
                with patch('lib.validation.automated_fine_tuning.ValidationExpectationsParser'):
                    result = tuner.run_statistical_tuning(
                        method='percentile_95',
                        save_ranges=False,  # Don't save for testing
                        save_report=False   # Don't save for testing
                    )
        
        # Should return success result
        self.assertTrue(result['success'])
        self.assertEqual(result['method'], 'percentile_95')
        self.assertEqual(result['validation_ranges'], validation_ranges)
        self.assertEqual(result['task_phase_data'], task_phase_data)
        self.assertEqual(result['duration'], 5.0)
        self.assertEqual(result['total_ranges'], 1)
        self.assertIsNone(result['saved_file'])
        self.assertIsNone(result['report_file'])
    
    @patch('builtins.print')
    @patch('time.time')
    def test_run_statistical_tuning_with_save_report(self, mock_time, mock_print):
        """Test run_statistical_tuning with report saving - Lines 510-523."""
        mock_time.side_effect = [0.0, 2.0]  # 2 second duration
        
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        # Create reports directory for testing
        reports_dir = project_root / "source" / "validation" / "reports"
        if not reports_dir.exists():
            reports_dir.mkdir(parents=True)
        
        # Mock methods
        task_phase_data = {}
        validation_ranges = {}
        
        with patch.object(tuner, 'load_and_analyze_data', return_value=task_phase_data):
            with patch.object(tuner, 'calculate_statistical_ranges', return_value=validation_ranges):
                with patch.object(tuner, 'generate_statistics_report', return_value="Test report content"):
                    result = tuner.run_statistical_tuning(
                        method='mean_3std',
                        save_ranges=False,
                        save_report=True
                    )
        
        # Should save report
        self.assertTrue(result['success'])
        self.assertIsNotNone(result['report_file'])
    
    @patch('builtins.print')
    @patch('time.time')
    def test_run_statistical_tuning_with_save_ranges(self, mock_time, mock_print):
        """Test run_statistical_tuning with range saving - Lines 525-550."""
        mock_time.side_effect = [0.0, 3.0]
        
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        # Mock methods and parser
        task_phase_data = {}
        validation_ranges = {'task1': {'0': {'var1': {'min': 0, 'max': 1}}}}
        
        mock_parser = MagicMock()
        
        with patch.object(tuner, 'load_and_analyze_data', return_value=task_phase_data):
            with patch.object(tuner, 'calculate_statistical_ranges', return_value=validation_ranges):
                with patch('lib.validation.automated_fine_tuning.ValidationExpectationsParser', return_value=mock_parser):
                    result = tuner.run_statistical_tuning(
                        method='iqr_expansion',
                        save_ranges=True,
                        save_report=False
                    )
        
        # Should save ranges
        self.assertTrue(result['success'])
        self.assertIsNotNone(result['saved_file'])
        mock_parser.write_validation_data.assert_called_once()
    
    @patch('builtins.print')
    def test_run_statistical_tuning_exception(self, mock_print):
        """Test run_statistical_tuning with exception - Lines 581-588."""
        tuner = AutomatedFineTuner(str(self.phase_dataset_path), mode='kinematic')
        
        # Mock method to raise exception
        with patch.object(tuner, 'load_and_analyze_data', side_effect=Exception("Test error")):
            result = tuner.run_statistical_tuning()
        
        # Should return error result
        self.assertFalse(result['success'])
        self.assertEqual(result['error'], 'Test error')


class TestAutomatedFineTunerMain(unittest.TestCase):
    """Test the main() function and command-line interface - Lines 591-662."""
    
    def setUp(self):
        """Set up test environment."""
        self.temp_dir = tempfile.mkdtemp()
        self.addCleanup(lambda: shutil.rmtree(self.temp_dir, ignore_errors=True))
        
        # Create test dataset
        test_data = {
            'subject': ['SUB01'] * 150,
            'task': ['level_walking'] * 150,
            'step': [1] * 150,
            'phase_percent': list(np.linspace(0, 100, 150)),
            'hip_flexion_angle_ipsi_rad': np.random.normal(0.2, 0.1, 150)
        }
        
        self.dataset_path = Path(self.temp_dir) / "test.parquet"
        pd.DataFrame(test_data).to_parquet(self.dataset_path)
    
    @patch('sys.argv')
    @patch('lib.validation.automated_fine_tuning.AutomatedFineTuner')
    def test_main_function_default_args(self, mock_tuner_class, mock_argv):
        """Test main() function with default arguments - Lines 591-658."""
        from internal.validation_engine.automated_fine_tuning import main
        
        # Mock command line arguments
        mock_argv.__getitem__.side_effect = [
            'automated_fine_tuning.py',  # sys.argv[0]
        ]
        
        # Mock tuner
        mock_tuner = MagicMock()
        mock_tuner.run_statistical_tuning.return_value = {'success': True}
        mock_tuner_class.return_value = mock_tuner
        
        with patch('argparse.ArgumentParser.parse_args') as mock_parse_args:
            mock_args = MagicMock()
            mock_args.dataset = str(self.dataset_path)
            mock_args.method = 'percentile_95'
            mock_args.mode = 'kinematic'
            mock_args.no_save_ranges = False
            mock_args.save_report = False
            mock_parse_args.return_value = mock_args
            
            with patch('pathlib.Path.exists', return_value=True):
                result = main()
        
        # Should initialize tuner and run tuning
        mock_tuner_class.assert_called_once_with(
            dataset_path=str(self.dataset_path),
            mode='kinematic'
        )
        mock_tuner.run_statistical_tuning.assert_called_once_with(
            method='percentile_95',
            save_ranges=True,  # not args.no_save_ranges
            save_report=False
        )
        self.assertEqual(result, 0)
    
    @patch('sys.argv')
    @patch('builtins.print')
    def test_main_function_dataset_not_found(self, mock_print, mock_argv):
        """Test main() function with non-existent dataset - Lines 640-643."""
        from internal.validation_engine.automated_fine_tuning import main
        
        mock_argv.__getitem__.side_effect = ['automated_fine_tuning.py']
        
        with patch('argparse.ArgumentParser.parse_args') as mock_parse_args:
            mock_args = MagicMock()
            mock_args.dataset = '/nonexistent/file.parquet'
            mock_parse_args.return_value = mock_args
            
            result = main()
        
        # Should return error code
        self.assertEqual(result, 1)
        mock_print.assert_called()
    
    @patch('sys.argv')
    @patch('lib.validation.automated_fine_tuning.AutomatedFineTuner')
    def test_main_function_tuning_failure(self, mock_tuner_class, mock_argv):
        """Test main() function with tuning failure - Lines 652-657."""
        from internal.validation_engine.automated_fine_tuning import main
        
        mock_argv.__getitem__.side_effect = ['automated_fine_tuning.py']
        
        # Mock tuner that fails
        mock_tuner = MagicMock()
        mock_tuner.run_statistical_tuning.return_value = {'success': False}
        mock_tuner_class.return_value = mock_tuner
        
        with patch('argparse.ArgumentParser.parse_args') as mock_parse_args:
            mock_args = MagicMock()
            mock_args.dataset = str(self.dataset_path)
            mock_args.method = 'mean_3std'
            mock_args.mode = 'kinetic'
            mock_args.no_save_ranges = True
            mock_args.save_report = True
            mock_parse_args.return_value = mock_args
            
            with patch('pathlib.Path.exists', return_value=True):
                result = main()
        
        # Should return error code
        self.assertEqual(result, 1)
        
        # Verify tuner was called with correct parameters
        mock_tuner.run_statistical_tuning.assert_called_once_with(
            method='mean_3std',
            save_ranges=False,  # not args.no_save_ranges
            save_report=True
        )
    
    @patch('sys.argv')
    def test_main_function_help_text(self, mock_argv):
        """Test main() function help text and argument parser - Lines 593-637."""
        from internal.validation_engine.automated_fine_tuning import main
        
        mock_argv.__getitem__.side_effect = ['automated_fine_tuning.py']
        
        with patch('argparse.ArgumentParser.parse_args') as mock_parse_args:
            # Mock args that would trigger help
            mock_parse_args.side_effect = SystemExit(0)  # Simulate help exit
            
            try:
                main()
            except SystemExit as e:
                self.assertEqual(e.code, 0)
    
    def test_argparse_choices_and_defaults(self):
        """Test argument parser choices and default values - Lines 622-636."""
        from internal.validation_engine.automated_fine_tuning import main
        import argparse
        
        # Create parser manually to test choices
        parser = argparse.ArgumentParser()
        parser.add_argument('--method', 
                           choices=['mean_3std', 'percentile_95', 'percentile_90', 
                                   'iqr_expansion', 'robust_percentile', 'conservative'],
                           default='percentile_95')
        parser.add_argument('--mode', choices=['kinematic', 'kinetic'], default='kinematic')
        
        # Test default values
        args = parser.parse_args([])
        self.assertEqual(args.method, 'percentile_95')
        self.assertEqual(args.mode, 'kinematic')
        
        # Test valid choices
        args = parser.parse_args(['--method', 'iqr_expansion', '--mode', 'kinetic'])
        self.assertEqual(args.method, 'iqr_expansion')
        self.assertEqual(args.mode, 'kinetic')


if __name__ == '__main__':
    # Run with high verbosity to see coverage details
    unittest.main(verbosity=2)